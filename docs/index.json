[{"categories":["生产工具"],"content":"IntelliJ IDEA 代码显示灰色，表示无任何引用，实际上是有引用。出现这种问题，非常不易于 DEBUG。\n解决方法：File -\u0026gt; Invalidate Caches \u0026hellip;\n勾选：\n Clear file system cache and Local History Ask before downloading new shared indexes  ","date":"2022-04-27","img":"","permalink":"/posts/ide-no-usages-found/","series":null,"tags":["JetBrains"],"title":"IDE 代码显示无引用 No Usages Found"},{"categories":["Go"],"content":"Go 中 map 是键值对的关联容器（Associative Container），可以存储不同类型的键值对，其中键的类型需要满足可比较（==）特性。\n基本操作 map 的基本操作如下：\n// 构造 m := make(map[key]value) // or m := map[key]value{} // 插入 m[k] = v // 查找 v = m[k] // 删除 delete(m, k) // 遍历 for k, v := range m // 长度 len(m) 简单实现 type element struct { k int64 v string } type map []element func (m map) Lookup(k int64) string { for _, e := range m { if e.k == k { return e.v } } return \u0026#34;\u0026#34; } 上述实现的 map 如果数据规模过大，查找元素的速率会变得很慢。由此，一个加快查找的思想是将多个元素划分到一个子集，即一个桶（bucket），根据 key 值查找到 bucket 的时间复杂度要到 O(1)，从而提前过滤了无关的数据。但为了避免同一个 bucket 存储过多数据，所以要找一个使类似 key 值达到均匀分布的哈希函数。一个好的哈希函数的标准应该是与 key 值的分布无关的，这样才能使用元素各均匀的分布。\n哈希函数 哈希函数的必须满足以下条件：\n 对于唯一确定的值，函数的输出也应该是唯一确定的，不存在同一值有两个不同的输出； 函数的输出值应该服从均匀分布； 计算速度快；  Go Map Go 的 map 结构如下：\n// hmap Go map 的头 type hmap struct { // key-value 的个数 \tcount int flags uint8 // \tB uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) \tnoverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details \thash0 uint32 // hash seed  // 指定 bucket 数组的起始地址 \tbuckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0.  // 用于 map 扩容 \toldbuckets unsafe.Pointer nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) \textra *mapextra // optional fields } // bmap 桶 type bmap struct { tophash [bucketCnt]uint8 } v := m[k] 编译成如下的代码：\nv := runtime.lookup(m, k) 由于 key 和 value 类型的不同，所以 lookup 的函数签名应该如下：\nfunc\u0026lt;K, V\u0026gt; lookup(m map[K]V, k K) V 显然，这是泛型的函数，但在 Go 1.18 前，Go 并没有泛型。所以 Go 在源码中使用 unsafe.Pointer 伪造了泛型。\ntype _type struct { size uintptr equal func(unsafe.Pointer, unsafe.Pointer) bool hash func(unsafe.Pinter, uintptr) uintptr } type mapType struct { key *_type value *_type } 即 key 和 value 在运行时都属于 _type 类型，并且 _type 类型实现了如 equal、hash 等方法。所以 lookup 的签名如下：\nfunc lookup(t *mapType, m *mapHeader, k unsafe.Pointer) unsafe.Pointer Map 扩容 当 map 中的键值对过多时（负载因子过大），map 会进行扩容。扩容要满足平均一个 bucket 中存在的键值对个数大于 6.5 个，步骤如下：\n 向系统申请原 bucket 数组所占内存两倍的内存； 将旧桶中的数据复制到新的桶； 操作新的桶；  在复制的过程中，操作 map 的性能损耗相对较高。\n与其它语言实现的 map 对比     C++ Java Python Go     \u0026amp;m[k] Yes No No No   遍历时修改 No No No Yes   自定义哈希函数（重载运算符 ==） Yes Yes Yes No   Adversary Safe No No No Yes    图 1 查找速度对比\nroadmap 总结  Go 的 map 是基于 hashmap 和 bucket 实现的； 哈希函数的作用是使 key 的哈希值尽可能均匀分布； 桶中键值对平均个数大于 6.5 时，会进行扩容； 在没有泛型机制下，Go 使用 unsafe.Pointer 模拟了泛型；  参考  视频 GopherCon 2016: Keith Randall - Inside the Map Implementation Maps in Golang ","date":"2022-04-27","img":"/images/go-map.png","permalink":"/posts/go-map-detail/","series":null,"tags":["map"],"title":"Go Map"},{"categories":["Go"],"content":"面试的时候问到了一个关于 go Slice 的问题，即为什么在 a[i:] 中 i 的取值可以是 a 的长度。平时开发中也是这么用的，但没太深入的了解，所以在这篇文章中对其进行一些探讨。\nslice 删除元素 Go 标准内置包没有提供太多操作 slice 的方法，所以如果要删除 slice 的元素通常都能找到以下的实现。\nfunc remove(slice []int, s int) []int { return append(slice[:s], slice[s+1:]...) } 这里就引发出一个疑问：当要删除最后一个元素时，s+1 不就等于 slice 的长度了，但程序为什么没有报 index out of range 错误。\n两种表达式的官方解释 官方对于 a[i] 和 a[low:high]有不同的定义，分别为索引表达式 和 slice 表示式，所以两者并非一个东西。\na[i] 表达式\n 下标的取值范围在 $0 \\le i \\lt len(a)$，如果超出了会报 out of range 运行时错误。\n a[low:high] 表示式\n 对于数组或字符串，下标的取值范围在 $0 \\le low \\le high \\le len(a)$，即下标可以取到数组的长度或字符串的长度。对于 slice 来说，下标的取值上限是 slice 的容量，显然 slice 的容量会大于等于其长度。\n package main import ( \u0026#34;fmt\u0026#34; ) func main() { ints := make([]int, 0) for i := 0; i \u0026lt; 3; i++ { ints = append(ints, i) } fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) fmt.Println(ints[3:4]) } length: 3, capacity: 4 [0] ints 的容量为 4，所以 ints[3:4] 符合定义。另外，扩容操作只有在使用 append 方法后才会执行，正常初始化的 slice 的长度与容量相同，如下：\npackage main import \u0026#34;fmt\u0026#34; func main() { ints := []int{1, 2, 3} fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) } length: 3, capacity: 3 值得注意的是，如果 a[low:high] 中的 high 缺省了会默认为 a 的长度，则 a[len(a):] 会变成 a[len(a):len(a)] ，而 len(a) - len(a) = 0，所以会取到一个空 [] 的 slice。\n猜想一 猜想：a[len(a):] 是不是读到了 slice 相邻内存上的数据，因为相邻内存上没有数据，所以才会返回 []。所以要先了解下 slice 容量的扩展方式，例子如下：\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { ints := make([]int, 0) for i := 0; i \u0026lt; 9; i++ { // sh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;ints)) \tfmt.Printf(\u0026#34;before adding a element [%d]\\n\u0026#34;, i) fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) ints = append(ints, i) fmt.Printf(\u0026#34;after adding a element [%d]\\n\u0026#34;, i) fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) fmt.Println() // slice 容量从 4 开始以 2 的倍数增加 \t} } before adding a element [0] length: 0, capacity: 0 after adding a element [0] length: 1, capacity: 1 before adding a element [1] length: 1, capacity: 1 after adding a element [1] length: 2, capacity: 2 before adding a element [2] length: 2, capacity: 2 after adding a element [2] length: 3, capacity: 4 before adding a element [3] length: 3, capacity: 4 after adding a element [3] length: 4, capacity: 4 before adding a element [4] length: 4, capacity: 4 after adding a element [4] length: 5, capacity: 8 before adding a element [5] length: 5, capacity: 8 after adding a element [5] length: 6, capacity: 8 before adding a element [6] length: 6, capacity: 8 after adding a element [6] length: 7, capacity: 8 before adding a element [7] length: 7, capacity: 8 after adding a element [7] length: 8, capacity: 8 before adding a element [8] length: 8, capacity: 8 after adding a element [8] length: 9, capacity: 16 从输出可以得知：\n 添加 int 0 后，长度为 1，容量为 1； 添加 int 1 后，长度为 2，容量为 2； 添加 int 2 后，长度为 3，容量为 4； 添加 int 4 后，长度为 5，容量为 8； 添加 int 8 后，长度为 9，容量为 16；  综上，slice 底层数组的扩展规则为容量以 2 的倍数增长。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { ints := make([]int, 0) ints = append(ints, 1, 2, 3) // slice 的长度为 3，容量为 3，取下标 3 的元素会越界 \t// fmt.Println(\u0026#34;try to get the 4th element\u0026#34;, ints[3])  // 取 slice 从下标 3 之后的元素，返回的是个 [] \tfmt.Println(\u0026#34;try to get the rest elements from the 4th element: \u0026#34;, ints[3:]) // sh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;ints)) \t// 打印 ints 的起始地址 \tfmt.Printf(\u0026#34;the start address of ints: %p\\n\u0026#34;, ints) // 第一次：打印 ints[3:] 的起始地址 \tfmt.Printf(\u0026#34;first the start address of ints[3:]: %p\\n\u0026#34;, ints[3:]) // 第二次：打印 ints[3:] 的起始地址 \tfmt.Printf(\u0026#34;second the start address of ints[3:]: %p\\n\u0026#34;, ints[3:]) // 打印 ints[2] 的地址 \tfmt.Printf(\u0026#34;the address of ints[2]: %p\\n\u0026#34;, \u0026amp;(ints[2])) fmt.Println() rest := ints[3:] sh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;rest)) fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, sh.Len, sh.Cap) } try to get the rest elements from the 4th element: [] the start address of ints: 0xc0000be090 first the start address of ints[3:]: 0xc0000be090 second the start address of ints[3:]: 0xc0000be090 the address of ints[2]: 0xc0000be0a0 ints 初始化为长度为 3、容量为 4 的 slice，对其进行取值操作，得到：\n ints[3:] 返回一个空的 slice []，同时其起始地址与 ints 起始地址相同； 多次调用 ints[3:] 始终返回相同的结果，且长度和容量均为 0；  显然，ints[3:] 并非取到了 ints 相邻内存中的值，所以猜想不成立。\n猜想二 猜想：当 len(a) \u0026lt; cap(a) 时，a[i:j] (i \u0026lt;= j, len(a) \u0026lt; j) 取到了已分配内存中的零值。\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { ints := make([]int, 0) for i := 0; i \u0026lt; 5; i++ { ints = append(ints, i) } fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) fmt.Println(ints[4:8]) } length: 5, capacity: 8 [4 0 0 0] 在上述代码中，ints 的长度为 5、容量为 8，ints[4:8] 中的下标值 8 符合小于等于容量的规定，语法有效。同时看到输出，也确实取到了已分配（未使用）内存中的值。\n参考   stackoverflow: Why go doesn\u0026rsquo;t report \u0026ldquo;slice bounds out of range\u0026rdquo; in this case?\n  stackoverflow: Why does go allow slicing from len(slice)?\n  官方 Index 表示式\n  官方 Slice 表达式\n  stackoverflow: Why does go allow slicing from len(slice)?\n ","date":"2022-04-26","img":"/images/go-slice.png","permalink":"/posts/go-slice-out-of-range/","series":null,"tags":["slice","stackoverflow","面试经"],"title":"Slice 什么时候报 Out of Range"},{"categories":["数据库"],"content":"小小的修改列的注释信息也能引发一些思考。\n正确的修改方式要带上原来列的定义，如：\nALTERTABLE`user`CHANGE`id``id`INT(11)COMMENT\u0026#39;id of user\u0026#39;;高票答案的几个回复：\n Note that altering a comment will cause a full resconstruction of the table. So you may choose to live without it on very big table.\n修改列注释会重构表 （对于大表慎用）\nThat is not (or no longer) true, as long as the column definition matches the existing definition exactly. Comments can be added without causing table reconstruction.\n如果和之前的列定义一致，修改列注释不会重构表\n Alter MySQL table to add comments on columns\n","date":"2022-04-25","img":"","permalink":"/doc-stackoverflow/mysql-modify-table-column-comment/","series":["Stackoverflow Magic"],"tags":["stackoverflow","MySQL"],"title":"MySQL 修改列的注释信息"},{"categories":["Go"],"content":"在 go.mod 文件中新增 replace 信息，内容如下：\nmodule github.com/userName/mainModule require \u0026#34;github.com/userName/otherModule\u0026#34; v0.0.0 replace \u0026#34;github.com/userName/otherModule\u0026#34; v0.0.0 =\u0026gt; \u0026#34;本地包路径\u0026#34; Accessing local packages within a go module (go 1.11)\n","date":"2022-04-25","img":"","permalink":"/doc-stackoverflow/go-use-local-module-in-development/","series":["Stackoverflow Magic"],"tags":["stackoverflow","go module"],"title":"Go Module 使用本地开发的包"},{"categories":["Go"],"content":"在 Windows 下，Go 的 os 标准库提供的 Rename 方法不能跨磁盘移动文件。下面通过问题重现，提供两种解决方案。\n问题重现 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { err := os.Rename(\u0026#34;D:\\\\black.txt\u0026#34;, \u0026#34;E:\\\\black-new.txt\u0026#34;) if err != nil { fmt.Println(err) } } 执行上面的代码后报错。\nrename D:\\black.txt E:\\black-new.txt: The system cannot move the file to a different disk drive. 从源码中可知，Windows 平台有专门实现的 file_windows.go ：\n// file_windows.go func rename(oldname, newname string) error { e := windows.Rename(fixLongPath(oldname), fixLongPath(newname)) if e != nil { return \u0026amp;LinkError{\u0026#34;rename\u0026#34;, oldname, newname, e} } return nil } // syscall_windows.go func Rename(oldpath, newpath string) error { from, err := syscall.UTF16PtrFromString(oldpath) if err != nil { return err } to, err := syscall.UTF16PtrFromString(newpath) if err != nil { return err } return MoveFileEx(from, to, MOVEFILE_REPLACE_EXISTING) } // zsyscall_windows.go func MoveFileEx(from *uint16, to *uint16, flags uint32) (err error) { r1, _, e1 := syscall.Syscall(procMoveFileExW.Addr(), 3, uintptr(unsafe.Pointer(from)), uintptr(unsafe.Pointer(to)), uintptr(flags)) if r1 == 0 { err = errnoErr(e1) } return } 可见，最终移的动操作是通过系统调用完成的，其中 Rename 方法调用了两次 syscall.UTF16PtrFromString 方法，返回了两个 *uint16 类型的值，再使用 MoveFileEx 方法完成移动。\nsyscall 查看 zsyscall_windows.go 提供的方法，还有一个 MoveFile 可以尝试，所以就有了以下代码：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;syscall\u0026#34; ) func main() { oldpath := \u0026#34;D:\\\\black.txt\u0026#34; newpath := \u0026#34;E:\\\\black-new.txt\u0026#34; from, _ := syscall.UTF16PtrFromString(oldpath) to, _ := syscall.UTF16PtrFromString(newpath) fmt.Println(*from, *to) err := syscall.MoveFile(from, to) if err != nil { panic(err) } } 68 69 移动操作是成功完成的。\nstackoverflow 同时在 stackoverflow 上，也有开发者提供了移动实现。该实现的过程是借助一个中间文件，比如要移动文件到 E 盘，则先在 E 盘创建一个目标文件（os.Create），再把源文件的内容写入到目标文件（os.Copy），最后删除源文件（os.Remove），代码如下：\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) func MoveFile(sourcePath, destPath string) error { inputFile, err := os.Open(sourcePath) if err != nil { return fmt.Errorf(\u0026#34;Couldn\u0026#39;t open source file: %s\u0026#34;, err) } outputFile, err := os.Create(destPath) if err != nil { inputFile.Close() return fmt.Errorf(\u0026#34;Couldn\u0026#39;t open dest file: %s\u0026#34;, err) } defer outputFile.Close() _, err = io.Copy(outputFile, inputFile) inputFile.Close() if err != nil { return fmt.Errorf(\u0026#34;Writing to output file failed: %s\u0026#34;, err) } // The copy was successful, so now delete the original file  err = os.Remove(sourcePath) if err != nil { return fmt.Errorf(\u0026#34;Failed removing original file: %s\u0026#34;, err) } return nil } 跨平台支持 如果希望应用能够在多个平台上正常运行，可以创建 file.go 和 file_windows.go，分别为不同平台要编译的源代码，也可以创建一个方法，在方法中对平台进行判断。\nfunc MoveFile(src string, dst string) error { if runtime.GOOS == \u0026#34;windows\u0026#34; { from, _ := syscall.UTF16PtrFromString(src) to, _ := syscall.UTF16PtrFromString(dst) return syscall.MoveFile(from, to) } else { return os.Rename(src, dst) } } 参考  stackoverflow: Move a file to a different drive with Go ","date":"2022-04-24","img":"","permalink":"/posts/go-file-rename-pit/","series":null,"tags":["file","I/O","Stackoverflow"],"title":"Windows 下移动文件的坑"},{"categories":["Go","Web"],"content":"从网络上下载文件是开发过程中常用的需求，常规流程是：（1）发送请求；（2）接收响应并读取响应体内容；（3）保存到本地文件。本文包含的两个例子分别来自于参考 [1] 和参考 [2]，在此基础上做了少量的修改。\n例 1 普通下载 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; ) func main() { fileUrl := \u0026#34;https://golangcode.com/logo.svg\u0026#34; filename := \u0026#34;logo.svg\u0026#34; resp, err := http.Get(fileUrl) if err != nil { panic(err) } defer resp.Body.Close() out, err := os.Create(filename) if err != nil { panic(err) } _, err = io.Copy(out, resp.Body) if err != nil { panic(err) } fmt.Println(\u0026#34;Downloaded: \u0026#34; + fileUrl) } 例 1 中使用了 io.Copy 方法将响应体内容复制到目标文件。io.Copy 是带缓冲的复制，可以避免在内存中堆积大量的数据，类似的方法还有 io.CopyBuffer。\nfunc Copy(dst Writer, src Reader) (written int64, err error) { return copyBuffer(dst, src, nil) } func CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) { if buf != nil \u0026amp;\u0026amp; len(buf) == 0 { panic(\u0026#34;empty buffer in CopyBuffer\u0026#34;) } return copyBuffer(dst, src, buf) } 例 2 带进度的下载 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/dustin/go-humanize\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) type Progress struct { total uint64 } func (p *Progress) Write(bs []byte) (n int, err error) { n = len(bs) p.total += uint64(n) p.Show() return n, nil } func (p Progress) Show() { fmt.Printf(\u0026#34;\\r%s\u0026#34;, strings.Repeat(\u0026#34; \u0026#34;, 35)) fmt.Printf(\u0026#34;\\rDownloading... %s complete\u0026#34;, humanize.Bytes(p.total)) } func main() { fileUrl := \u0026#34;https://golangcode.com/logo.svg\u0026#34; filename := \u0026#34;logo.svg\u0026#34; resp, err := http.Get(fileUrl) if err != nil { panic(err) } defer resp.Body.Close() out, err := os.Create(filename) if err != nil { panic(err) } defer out.Close() if _, err = io.Copy(out, io.TeeReader(resp.Body, \u0026amp;Progress{})); err != nil { panic(err) } } 与例 1 的不同之处在于 io.Copy 的第 2 参数换成了一个 io.teeReader 的对象。下面是 io.teeReader 的定义：\ntype teeReader struct { r Reader w Writer } func (t *teeReader) Read(p []byte) (n int, err error) { n, err = t.r.Read(p) if n \u0026gt; 0 { if n, err := t.w.Write(p[:n]); err != nil { return n, err } } return } teeReader 实现了 Reader 接口，而在 Read 方法中保留了原先读取数据的操作，新增了一个写数据的操作。Progress 实现了 Writer 接口，正好可以作为 teeReader 的 w 字段的值，所以在执行 Read 的过程中会调用 Progress.Write 方法，从而可以知道已经读取数据的大小。最后用 Progress.Show 方法将 total 字段的值输出到终端。\n参考  GolangCode: Download a File (from a URL) GolangCode: Download Large Files with Progress Reports ","date":"2022-04-24","img":"","permalink":"/posts/go-download-network-file/","series":null,"tags":["HTTP","I/O"],"title":"URL 下载网络文件"},{"categories":["Go","数据库","Web"],"content":"在 Web 开发中，常常需要对请求信息进行记录，形成日志以便于后期评估应用的性能。请求信息通常包含客户端地址、请求的 URL、请求时间及请求执行时间。在程序中，可以以同步或异步的方式完成这一需求。同步方式是指请求信息写入日志文件后才返回数据给客户端，异步方式则是在返回数据之前以新线程或进程完成对请求信息的记录。开源的日志包有：\n Zap：出自 Uber 团队，以高性能著称； Zerolog：以易用性著称，支持 7 种日志级别； Logrus：兼容标准日志包格式，也是本人常用的日志包； apex/log：受 Logrus 启发，简化操作后的 Logrus； Log15：日志可读性强；  5 个日志包的详细介绍可以看《5 种结构化 Go 日志包对比分析》这篇文章。\n在 Go 开发中，一个非常简单的办法就是启用一个 goroutine 将请求信息发送到目的地，目的地可以是（1）一个日志文件；（2）一个 channel 或其它的应用（如 Redis）。在第 2 种方法中，还需要另一个拉取日志信息的服务，这类方法的优势是可以提高主体应用的性能，缺点是增加了系统的复杂度。本文的重点落在两个方面，分别为：\n 解析请求，将信息发送到 Redis 服务器； 读取 Redis 服务器中的请求信息，持久化到日志文件；  所以在本次实现中，包含两个组件（app 组件和 micro-dumper 组件）分别完成上述两项功能。\napp 首先需要一个 Record 类型来描述请求信息，其结构如下：\n// Record Represent a set of a Request passing from the client type Record struct { RemoteAddr string URL string AccessTime int64 TimeExecuted int64 BodyBytesSent int64 } 在 Redis 端，我们也需要两种数据结构，分别为 Stream 和 List。Stream 可以用来保存请求的信息，而 List 则是用保存 Stream 中请求信息的 ID。\n 当前 Redis 不支持以位置索引的方式访问 Stream 中的信息。Stackoverflow\n 接着定义两种数据类型的键名：\nconst StreamKey = \u0026#34;api-request-log\u0026#34; const RecordIDsKey = \u0026#34;api-request-record-ids\u0026#34; 然后就是实现 Redis 的连接，用于访问 Redis 服务器。\nvar client *redis.Client var once sync.Once // Client return a redis client func Client() *redis.Client { once.Do(func() { // Maybe you should instantiate redis client by reading config file \tclient = redis.NewClient(\u0026amp;redis.Options{ Network: \u0026#34;tcp\u0026#34;, Addr: \u0026#34;localhost:6379\u0026#34;, DB: 0, }) }) return client } 这里使用单例设计模式，应用只需要维护一个 Redis 客户端即可。有了记录（请求信息）和 Redis 客户端，就应该将记录发送到 Redis 服务器。\n// SendRecord send a record to redis server, two things are done as follows: // 1. add a entry to the stream // 2. push a entry id to the list func SendRecord(record Record) { // add a entry by call .XAdd method \txaddCmd := Client().XAdd(context.Background(), \u0026amp;redis.XAddArgs{ Stream: StreamKey, ID: \u0026#34;*\u0026#34;, Values: map[string]interface{}{ \u0026#34;remote_addr\u0026#34;: record.RemoteAddr, \u0026#34;url\u0026#34;: record.URL, \u0026#34;access_time\u0026#34;: record.AccessTime, \u0026#34;time_executed\u0026#34;: record.TimeExecuted, \u0026#34;body_bytes_sent\u0026#34;: record.BodyBytesSent, }, }) if xaddCmd.Err() != nil { panic(xaddCmd.Err()) } recordID := xaddCmd.Val() // push the id to the list by call .LPush method \tlpushCmd := Client().LPush(context.Background(), RecordIDsKey, recordID) if lpushCmd.Err() != nil { panic(lpushCmd.Err()) } } 上述代码做了两件事情：\n 将记录添加到键为 StreamKey 的 Stream； 将记录 ID 添加到键为 RecordIDsKey 的 List；  最后，app 组件的主程序如下：\nimport ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;redislog\u0026#34; \u0026#34;time\u0026#34; ) type User struct { Name string `json:\u0026#34;name\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } // dataFromDB mock retrieving data from database func dataFromDB() []*User { return []*User{ { \u0026#34;xiaoming\u0026#34;, 12, }, { \u0026#34;xiaohong\u0026#34;, 13, }, { \u0026#34;xiaobei\u0026#34;, 14, }, } } // RedisLogger a gin.HandlerFunc wrapper // extract request information, assemble to a record, and send to Redis server via goroutine func RedisLogger(f gin.HandlerFunc) gin.HandlerFunc { return func(c *gin.Context) { record := redislog.Record{ RemoteAddr: c.Request.RemoteAddr, URL: c.Request.URL.RequestURI(), AccessTime: time.Now().Unix(), } f(c) record.TimeExecuted = time.Now().Unix() - record.AccessTime record.BodyBytesSent = int64(c.Writer.Size()) go redislog.SendRecord(record) } } func main() { engine := gin.Default() engine.GET(\u0026#34;api/users\u0026#34;, RedisLogger(func(c *gin.Context) { time.Sleep(time.Second * time.Duration(rand.Int63n(5))) c.JSON(http.StatusOK, gin.H{ \u0026#34;data\u0026#34;: dataFromDB(), }) })) engine.GET(\u0026#34;api/user/:name/age\u0026#34;, RedisLogger(func(c *gin.Context) { users := dataFromDB() name := c.Param(\u0026#34;name\u0026#34;) var user *User for _, u := range users { if u.Name == name { user = u } } var age interface{} if user == nil { age = \u0026#34;unknown\u0026#34; } else { age = user.Age } c.JSON(http.StatusOK, gin.H{ \u0026#34;age\u0026#34;: age, }) })) log.Fatalln(engine.Run(\u0026#34;:9090\u0026#34;)) } 上述代码定义了两个接口：/api/users 和 /api/user/:name/age，两个 gin.HandlerFunc 都被 RedisLogger 进行“包裹”。\nmirco-dumper micro-dumper 会周期性拉取 Stream 里的记录，如果存在并保存到日志文件，反之则等待下一刻执行。主要实现其实就一个 ReadRecord 方法：\n// ReadRecord read a record from redis, three things are done as follows: // 1. retrieve a entry id from the list // 2. retrieve a entry from the stream via the entry id // 3. after retrieving the entry, delete the entry from the stream func ReadRecord() (Record, bool) { // retrieve record id from the redis list \tlpopCmd := Client().LPop(context.Background(), RecordIDsKey) recordID := lpopCmd.Val() if recordID == \u0026#34;\u0026#34; { return Record{}, false } // read the record from the stream \txreadCmd := Client().XRead(context.Background(), \u0026amp;redis.XReadArgs{ Streams: []string{StreamKey, recordID}, Count: 1, Block: 0, }) if xreadCmd.Err() != nil { panic(xreadCmd.Err()) } // if read successfully, we should remove record from the stream \txdelCmd := Client().XDel(context.Background(), StreamKey, recordID) if xdelCmd.Err() != nil { panic(xdelCmd.Err()) } record := xreadCmd.Val()[0].Messages[0].Values accessTime, _ := strconv.ParseInt(record[\u0026#34;access_time\u0026#34;].(string), 10, 64) timeExecuted, _ := strconv.ParseInt(record[\u0026#34;time_executed\u0026#34;].(string), 10, 64) bodyBytesSent, _ := strconv.ParseInt(record[\u0026#34;body_bytes_sent\u0026#34;].(string), 10, 64) return Record{ RemoteAddr: record[\u0026#34;remote_addr\u0026#34;].(string), URL: record[\u0026#34;url\u0026#34;].(string), AccessTime: accessTime, TimeExecuted: timeExecuted, BodyBytesSent: bodyBytesSent, }, true } 读记录的逻辑如下：\n 从 List 中得到记录的 ID； 通过 ID 得到 Stream 中的记录； 记录获取完毕后，将该记录在 Stream 中删除；   LPOP 是左端弹出操作，在获取的同时，List 中已经不存在该 ID 了。\n 最后编写主程序：\nfunc main() { fmt.Println(\u0026#34;start to retrieve request record ...\u0026#34;) f, _ := os.Create(\u0026#34;./request.log\u0026#34;) for { time.Sleep(1) if record, found := redislog.ReadRecord(); found { _, err := f.WriteString(fmt.Sprintf(\u0026#34;remote addr: %s url: %s access time: %d time executed: %d body bytes sent: %d\\n\u0026#34;, record.RemoteAddr, record.URL, record.AccessTime, record.TimeExecuted, record.BodyBytesSent)) if err != nil { panic(err) } else { fmt.Println(\u0026#34;write a request record to log file\u0026#34;) } } } } 测试 运行 app 和 mirco-dumper：\n$ nohup go run app/main.go \u0026gt; app.out \u0026amp; $ nohup go run micro-dumper/main.go \u0026gt; micro-dumper.out \u0026amp; 使用 ab 测试工具发送大量请求：\n$ ab -n 1000 -c 10 http://localhost:9090/api/users $ ab -n 1000 -c 10 http://localhost:9090/api/user/xiaohong/age 查看日志：\nhead -10 request.log remote addr: [::1]:58644 url: /api/users access time: 1650716423 time executed: 0 body bytes sent: 96 remote addr: [::1]:58636 url: /api/users access time: 1650716423 time executed: 1 body bytes sent: 96 remote addr: [::1]:58666 url: /api/users access time: 1650716424 time executed: 0 body bytes sent: 96 remote addr: [::1]:58640 url: /api/users access time: 1650716423 time executed: 2 body bytes sent: 96 remote addr: [::1]:58658 url: /api/users access time: 1650716423 time executed: 2 body bytes sent: 96 remote addr: [::1]:58680 url: /api/users access time: 1650716425 time executed: 0 body bytes sent: 96 remote addr: [::1]:58648 url: /api/users access time: 1650716423 time executed: 3 body bytes sent: 96 remote addr: [::1]:58654 url: /api/users access time: 1650716423 time executed: 3 body bytes sent: 96 remote addr: [::1]:58682 url: /api/users access time: 1650716425 time executed: 1 body bytes sent: 96 remote addr: [::1]:58646 url: /api/users access time: 1650716423 time executed: 4 body bytes sent: 96 完整代码 redislog\n总结  ResponseWriter 接口定义了 Size 方法可以得到响应体中的字节数； 因为 Redis 保存的都是字符串形式，所以在 Go 代码中总是要做字符串转换； ","date":"2022-04-23","img":"/images/managing_activity_logs.jpg","permalink":"/posts/go-redis-request-log-dumper/","series":null,"tags":["Redis","logging","Gin"],"title":"Redis 的 List 和 Stream：异步记录请求信息"},{"categories":["Go"],"content":"首先贴上 Go 开发团队对 reflect 包的描述：\n Package reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types. The typical use is to take a value with static type interface{} and extract its dynamic type information by calling TypeOf, which returns a Type.\nA call to ValueOf returns a Value representing the run-time data. Zero takes a Type and returns a Value representing a zero value for that type.\n 从描述中，我们得到以下几点：\n reflect 包实现了运行时的反射机制，允许程序操作任意类型的对象； TypeOf 可以得到一个 interface{} 的具体类型，ValueOf 可以得到一个 interface{} 的具体值；  重要类型 reflect 包中定义了几种重要的、常用的类型，分别为：\n Kind； Value； SliceHeader； StringHeader； Method； StructField；  Kind Kind 类型用于修饰类型 Type，用于表示 Type 的种类，底层是用一个无符号整数表示：\ntype Kind uint; 其中修饰了的基础数据类型包括Bool、Int、Int32、Float32、Float64 等，引用数据类型包括Slice、Map、Chan、Interface、Func 等。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { var v1 int = 1 var v2 float32 = 1.0 v3 := struct { }{} v4 := func() {} PrintKind(v1) PrintKind(v2) PrintKind(v3) PrintKind(v4) } func PrintKind(v interface{}) { t := reflect.TypeOf(v) switch t.Kind() { case reflect.Int: fmt.Println(\u0026#34;int\u0026#34;) case reflect.Float32: fmt.Println(\u0026#34;float32\u0026#34;) case reflect.Struct: fmt.Println(\u0026#34;struct\u0026#34;) case reflect.Func: fmt.Println(\u0026#34;function\u0026#34;) // 其它的情况 ... \t} } int float32 struct function 如果只是单纯地打印类型 Type 的种类，直接调用 .String 方法即可。\nfunc PrintKind(v interface{}) { t := reflect.TypeOf(v) fmt.Println(t.String()) } int float32 struct {} func() Value Value 类型表示一个接口具体的值，类型的定义如下：\ntype Value struct { // 值的真实类型 \ttyp *rtype // 指向值的指针 \tptr unsafe.Pointer // 值的元数据信息 \t// flag 可以是多种情况的组合 \tflag } 在知道值类型的情况下，可以调用相应的函数获取其本身的值，即值的类型是 int，经过 ValueOf 返回 Value 类型的值就可以调用 Int 方法得到其值。但是，如果调用了不符合本身类型的方法会报错，这一类方法的开头都对值的类型做了类型判断。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { var v1 int = 1 fmt.Println(reflect.ValueOf(v1).Int()) var v2 float32 = 1.0 // fmt.Println(reflect.ValueOf(v2).Int()) 会报错 } func (v Value) Int() int64 { k := v.kind() p := v.ptr switch k { case Int: return int64(*(*int)(p)) case Int8: return int64(*(*int8)(p)) case Int16: return int64(*(*int16)(p)) case Int32: return int64(*(*int32)(p)) case Int64: return *(*int64)(p) } panic(\u0026amp;ValueError{\u0026#34;reflect.Value.Int\u0026#34;, v.kind()}) } func (f flag) mustBe(expected Kind) { // TODO(mvdan): use f.kind() again once mid-stack inlining gets better \tif Kind(f\u0026amp;flagKindMask) != expected { panic(\u0026amp;ValueError{methodName(), f.kind()}) } } SliceHeader SliceHeader 是 slice 运行时的底层实现，其结构如下：\ntype SliceHeader struct { // 指向底层数据的指针  // 无符号的整数表示内存中的地址 \tData uintptr // slice 的长度 \tLen int // slice 的容量 \tCap int } func main() { data := []int{1, 2, 3, 4, 5} // unsafe.Pointer 表示任意类型的指针 \tdataPointer := unsafe.Pointer(\u0026amp;data) sh1 := (*reflect.SliceHeader)(dataPointer) fmt.Printf(`SliceHeader { Data: %d Len: %d Cap: %d } `, sh1.Data, sh1.Len, sh1.Cap) for i := 0; i \u0026lt; sh1.Len; i++ { // slice 中各元素的地址 \taddr := uint(sh1.Data) + uint(unsafe.Sizeof(1)) * uint(i) // slice 中各元素的值 \tvalue := *(*int)(unsafe.Pointer(uintptr(addr))) fmt.Printf(\u0026#34;%dth element addr: 0x%x, value: %d\\n\u0026#34;, i, addr, value) } } SliceHeader { Data: 824634670792 Len: 5 Cap: 5 } 0th element addr: 0xc0000e7ec8, value: 1 1th element addr: 0xc0000e7ed0, value: 2 2th element addr: 0xc0000e7ed8, value: 3 3th element addr: 0xc0000e7ee0, value: 4 4th element addr: 0xc0000e7ee8, value: 5 上述代码构造了一个 SliceHeader 类型的变量 sh1，并逐一打印出各元素的地址和值：\n \u0026amp;data 得到了 slice 的指针，使用  unsafe.Pointer(\u0026amp;data) 强制转换变成 *ArbitraryType； 使用 (*reflect.SliceHeader)(dataPointer) 得到了一个指向 SliceHeader 的指针； fmt.Printf 打印变量中 3 个字段的信息； for 循环：先计算每一个元素的地址，再通过地址得到地址上的值，最后打印输出； 地址和值都需要进行一系列转换；  如 uintptr 不支持算法运算符，所以通过转换成 uint 类型进行计算； 值的获取则是先将 uint 转换成 uintptr，再通过 unsafe.Pointer 转换成可表示任意类型的指针，接着转成 *int 类型的指针，最后使用 * 取指针的值；    StringHeader StringHeader 是 string 运行时的底层实现，其结构如下：\ntype StringHeader struct { // 指向底层数据的指针  // 无符号的整数表示内存中的地址 \tData uintptr // 字符串的长度 \tLen int } func main() { data := []string{\u0026#34;1\u0026#34;, \u0026#34;22\u0026#34;, \u0026#34;333\u0026#34;, \u0026#34;4444\u0026#34;, \u0026#34;55555\u0026#34;} sh1 := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;data)) fmt.Printf(\u0026#34;string slice length: %d\\n\u0026#34;, sh1.Len) for i := 0; i \u0026lt; sh1.Len; i++ { // 计算第 i 个元素的地址 \taddr := uint(sh1.Data) + uint(i) * uint(unsafe.Sizeof(data[i])) // 转换成任意类型的指针 \tarbitraryPointer := unsafe.Pointer(uintptr(addr)) // 转换成字符串指针 \tstringPointer := (*string)(arbitraryPointer) value := *stringPointer fmt.Printf(\u0026#34;%dth value: %s\\n\u0026#34;, i, value) } } string slice length: 5 0th value: 1 1th value: 22 2th value: 333 3th value: 4444 4th value: 55555 StringHeader 的例子与 SliceHeader 类似，区别在于在指针转换时 StringHeader 使用了 *string。\nMethod Method 表示一个方法，可以使用 reflect 包动态的调用方法，传入的参数是一个 reflect.Value 的 slice，其返回值也是使用一个 reflect.Value 的 slice 表示。\ntype anyFunc func(int) int type A struct {} func (a A) AnyFunc() string { return \u0026#34;A\u0026#34; } func main() { var oneFunc anyFunc = func(i int) int { return i + 1 } // oneFunc 是一个函数指针 \tfmt.Printf(\u0026#34;1. pointer %p\\n\u0026#34;, oneFunc) // 函数类型的字符串表示 \tfmt.Printf(\u0026#34;2. %s\\n\u0026#34;, reflect.TypeOf(oneFunc).String()) // 函数指针 \tfmt.Printf(\u0026#34;3. %s\\n\u0026#34;, (reflect.ValueOf(\u0026amp;oneFunc)).Kind().String()) fmt.Println(\u0026#34;== call method by reflect package\u0026#34;) i := 1000 // reflect.Value 得到函数值 \t// .Call 调用函数 \t// []reflect.Value{reflect.ValueOf(i)} 是传入函数的参数 \tresult := reflect.ValueOf(oneFunc).Call([]reflect.Value{reflect.ValueOf(i)}) fmt.Println(result[0]) // 类型中的方法 \ta := A{} method := reflect.TypeOf(a).Method(0) fmt.Printf(`== basic information of A.AnyFunc Type: %s Name: %s PkgPath： %s Index: %d `, method.Type, method.Name, method.PkgPath, method.Index) // 调用类型中的方法 \tfmt.Println(\u0026#34;== call a.AnyFunc\u0026#34;) fmt.Println(reflect.ValueOf(a).Method(0).Call([]reflect.Value{})) } StructField StructField 表示一个结构的字段，StructField 还会保存字段的 Tag 信息（StructTag）。StructTag 的底层实现是 string：\ntype StructTag string type A struct { StringField string `json:\u0026#34;jsonStringField\u0026#34;` IntField int `json:\u0026#34;jsonIntField\u0026#34;` } func main() { a := A{ StringField: \u0026#34;simple string\u0026#34;, IntField: 100, } fmt.Printf(\u0026#34;number of struct fields: %d\\n\u0026#34;, reflect.TypeOf(a).NumField()) fmt.Println(\u0026#34;== get struct field value\u0026#34;) numField := reflect.TypeOf(a).NumField() for i := 0; i \u0026lt; numField; i++ { fmt.Printf(\u0026#34;%s: %v\\n\u0026#34;, reflect.TypeOf(a).Field(i).Name, reflect.ValueOf(a).Field(i)) } fmt.Println(\u0026#34;== get struct field tag\u0026#34;) for i := 0; i \u0026lt; numField; i++ { tag := reflect.TypeOf(a).Field(i).Tag fmt.Printf(\u0026#34;%s\u0026#39;s tag string: `%s`\\n\u0026#34;, reflect.TypeOf(a).Field(i).Name, tag) fmt.Printf(\u0026#34; json: %v\\n\u0026#34;, tag.Get(\u0026#34;json\u0026#34;)) } } 总结  reflect.ValueOf(值) 和 reflect.ValueOf(指针).Elem() 等价； unsafe.Pointer 提供了任意类型指针的访问；  参考  Go 标准库 reflect stackoverflow 动态调用对象的方法 ","date":"2022-04-21","img":"/images/golang-reflect.png","permalink":"/posts/go-set-value-via-reflect-package/","series":null,"tags":["reflect","反射"],"title":"Go 的反射包 Reflect"},{"categories":["数据库"],"content":"在 MySQL 5.5 之前，默认存储引擎为 MyISAM，之后版本的默认存储引擎为 InnoDB。\n选择一个合适的存储引擎至关重要。\n存储引擎 根据是否支持事务，MySQL 的存储引擎可以分为：\n 事务型； 非事务型；  表 1 为 MySQL 支持的所有存储引擎以及各存储引擎的基本介绍。\n表 1 不同的存储引擎\n   存储引擎 支持事务 特点 适用场景     InnoDB 是 1. 支持行锁、灾难恢复、多版本并发控制；\n2. 支持外键、字段约束； 1. 适用于绝大部分场景；   MyISAM 否 1. 读写速度快；\n2. 支持表锁；\n3. 支持 B 树索引、聚簇索引、全文搜索索引；\n4. 支持地理数据及其索引；\n5. 不支持哈希索引、外键、多版本并发控制；\n6. 存储限制为 256TB； 1. 读写频繁的应用；\n2. 数据仓库；   Memory 否 1. 内存数据库；\n2. 相较于 MyISAM，读写速度更快；\n3. 支持表锁；\n4. 非持久化数据；\n5. 不支持多版本并发控制； 1. 快存快取   CSV 否 1. 通用格式，易于集成；\n2. 不支持索引；\n3. 不支持分区；\n4. 表的所有字段都要设置 not null /   Merge 否 1. 底层使用 MyISAM 存储引擎；\n 1. 数据仓库\n   Archive 否 1. 插入数据后，数据会被压缩； 1. 存储历史数据；   Federated 否 1. 集群式管理 MySQL 实例；\n 1. 分布式环境；   Blackhole 否 1. 可以向表插入数据，但查询只会返回空结果；\n2. 支持所有的索引类型；\n3. 不支持分区； /   Example 否 啥也不是存储引擎 /    设置方法 以 InnoDB 为例，可通过以下 3 种方法设置表的存储引擎：\n my.cnf 配置项； SET STORAGE_ENGINE； 创建表时；  my.cnf 配置项 在 my.cnf 文件或其它引入的配置中，修改 [mysqld] 中的 default-storage-engine 的值，如：\n[mysqld] default-storage-engine = InnoDB SET STORAGE_ENGINE 在执行脚本文件前，先通过 SET 设置使用的存储引擎：\nSET STORAGE_ENGINE = InnoDB; 创建表时 在创建数据库表时，指定 ENGINE：\nCREATETABLEIFNOTEXISTStest_name(idint)ENGINE=InnoDB;总结  MySQL 支持多种不同的存储引擎，InnoDB 存储引擎适用于绝大多数场景，并且支持事务、多版本并发控制； 可以在 3 个层次上对存储引擎进行修改，即：  服务器层，my.cnf 配置项； 会话层，在当前会话中使用 SET 设置存储引擎； 脚本层，在创建或修改表时声明存储引擎；    参考  MySQL storage engines 官方文档 Alternative Storage Engines ","date":"2022-04-21","img":"","permalink":"/posts/mysql-set-storage-engine/","series":null,"tags":["MySQL","存储引擎"],"title":"MySQL 设置存储引擎的 3 种方法"},{"categories":["数据库"],"content":"存储过程是存储在数据库中并且已经提前编译好的 SQL 语句集合，它是应用中数据操作的部分逻辑实现。MySQL 5 版本引入了这一设计，存储过程包含 3 个部分：\n 名称； 参数列表； SQL 语句；  特性 存储过程包含了诸多特性，主要包括：\n 性能提升：存储过程是预先编译好、存储好的 SQL 语句集合，没有 SQL 词法/语法解析、编译的过程； 减少网络流量：客户端无须发送大量 SQL 语句到数据库，只需要提供存储过程名称和参数列表即可； 可重用：存储过程的逻辑一般都是常规周期性的逻辑操作，可重复使用； 安全性强：网络上传输的数据不包含具体的操作信息，可以为存储过程设置用户操作权限；  基本语法 在 MySQL 中，创建一个存储过程的语法如下：\nDELIMITER\u0026amp;\u0026amp;CREATEPROCEDUREprocedure_name[[IN|OUT|INOUT]parameter_namedatatype[,parameterdatatype])]BEGIN-- 定义变量 ... -- 执行逻辑 ... END\u0026amp;\u0026amp;DELIMITER;创建存储过程时，可以使用 DELIMITER 指定分隔符，这样就可以在存储过程依然使用冒号 ; 作为语句的分隔符。\nIN | OUT | INOUT 为参数的类型，分别表示：\n IN：参数只作为输入，存储过程内部不允许对其进行修改； OUT：参数只作为输出，存储过程内部可以对其修改，但没办法访问其初始值； INOUT：同时兼具 IN 和 OUT 类型参数的特性；  在终端执行存储过程的命令如下：\nCALLprocedure_name(参数列表); 使用 CALL 关键字执行存储过程； 如果有参数，需要在括号内指定，使用逗号分隔；  与 PostgreSQL 不同，MySQL 不支持下面语法：\nCREATEORREPLACEprocedureName;要想实现相同的效果，需编写如下语句：\nDROPPROCEDUREIFEXISTSprocedureName;...CREATEPROCEDUREprocedure_name......条件判断：\nDROPPROCEDUREIFEXISTSjudge_num;DELIMITER\u0026amp;\u0026amp;CREATEPROCEDUREjudge_num(innumint)BEGINifnum\u0026gt;10thenSELECT\u0026#39;X \u0026gt; 10\u0026#39;ASresult;elseifnum\u0026lt;0thenSELECT\u0026#39;X \u0026lt; 0\u0026#39;ASresult;elseSELECT\u0026#39;0 \u0026lt;= X \u0026lt;= 10\u0026#39;ASresult;endif;END\u0026amp;\u0026amp;DELIMITER;CALLjudge_num(20);示例 示例使用的数据来自 MySQL 的官方测试数据集，可直接通过 datacharmer/test_db 下载脚本和数据，数据库结构如下图：\n不带参数 DROPPROCEDUREIFEXISTSget_emps;DELIMITER\u0026amp;\u0026amp;CREATEPROCEDUREget_emps()BEGINSELECTemp_noFROMdept_empWHEREfrom_date\u0026gt;\u0026#39;1990-01-01\u0026#39;;END\u0026amp;\u0026amp;DELIMITER;CALLget_emps; 即使存储过程未使用参数，仍然需要使用括号 ()； 在执行时，不需要括号 ()；  带 IN 类型参数 DELIMITER\u0026amp;\u0026amp;CREATEPROCEDUREtotal_salary(inempnovarchar(5))BEGINSELECTsum(salary)FROMsalariesWHEREemp_no=empno;END\u0026amp;\u0026amp;DELIMITER;CALLtotal_salary(\u0026#39;10001\u0026#39;); IN 类型参数可以直接传入，可以不需要提前声明变量；  带 OUT 类型参数 显然，上一个例子更适合结合 OUT 类型参数。\nDROPPROCEDUREIFEXISTSout_total_salary;DELIMITER\u0026amp;\u0026amp;CREATEPROCEDUREout_total_salary(inempnovarchar(5),outtotalint)BEGINSELECTsum(salary)INTOtotalFROMsalariesWHEREemp_no=empno;END\u0026amp;\u0026amp;DELIMITER;SET@total=0;CALLout_total_salary(\u0026#39;10001\u0026#39;,@total);SELECT@total; SET 指定的变量是弱类型变量，可以任意赋值；  最佳实践 在 stackoverfolow 找到一个关于编写存储过程的最佳实践，其中要点未做尝试，留个记录便于反复查看。\n 调用存储过程时，使用全路径，减少查找存储过程的逻辑判断；  CALL employees.out_total_salary('10001', @total);   做好存储过程的权限管理； 使用变量记录存储过程中的关键信息，如错误信息 @@error、行数信息 @@rowcount 等； 使用一个 OUT 类型变量，用于标识存储过程是否执行成功，可以使用 int 类型参数，0 表示成功，非 0 表示失败；  其它 SHOW CREATE PROCEDURE 可以使用 SHOW CREATE PROCEDURE 显示存储过程的基本信息：\nmysql\u0026gt;SHOWCREATEPROCEDUREdept_emp_num\\G;***************************1.row***************************Procedure:dept_emp_numsql_mode:STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTIONCreateProcedure:CREATEDEFINER=`root`@`localhost`PROCEDURE`dept_emp_num`(indeptnovarchar(100),outnumint)BEGINSELECTcount(emp_no)INTOnumFROMdept_empWHEREdept_no=deptno;ENDcharacter_set_client:utf8mb4collation_connection:utf8mb4_0900_ai_ciDatabaseCollation:utf8mb4_0900_ai_ci1rowinset(0.00sec)information_schema.routines 表 information_schema.routines 表中存放了存储过程信息，如：\nmysql\u0026gt;SELECTroutine_name,created,sql_mode,sql_data_accessFROMinformation_schema.routinesWHEREroutine_type=\u0026#39;PROCEDURE\u0026#39;ANDroutine_name=\u0026#39;total_salary\u0026#39;\\G;***************************1.row***************************ROUTINE_NAME:total_salaryCREATED:2022-04-2009:49:57SQL_MODE:STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTIONSQL_DATA_ACCESS:CONTAINSSQL1rowinset(0.46sec)参考  Learn MySQL: The Basics of MySQL Stored Procedures What are the best practices in writing a sql stored procedure 存储过程 if 判断语句 ","date":"2022-04-19","img":"/images/mysql-procedure.png","permalink":"/posts/mysql-writing-procedure/","series":null,"tags":["MySQL","存储过程"],"title":"MySQL 存储过程"},{"categories":["Go"],"content":"有幸搞了个 CSIG 的线上面试，感觉是“没什么感觉”，一般般吧，没过。\n前面介绍什么就不说了，我这边没突出什么工作亮点，然后就直接共享桌面写代码了。题目是编程实现一个由字符串数组表示的大数的除以 9 的计算，后面又追问了小数点后值如何保存，所以索性在线下实现也写了写。\n其实，对于这种手撕算法题还是挺反感的，有点类似于“形而上”的学习态度，”结伴编程“多少会是有些紧张，没写出来也很正常。但是换位思考一下，问题确实来源于实际，而且看别人码代码总是能看出一些面试者的风格或问题，多少可以作为出题人考查的标准。所以没对没错吧，自己也确实没有准备过算法题，一般般吧。\n自己的实现 回到这个问题，大数是指那些无法用固定长度类型保存的数值，所以需要用可变长的数组来模拟计算和存储结果。下方代码的实现逻辑比较简单，就是按位对数值进行除以 9 取商取模的操作：\n 计算第 1 位数值除以 9，取商取模； 计算后续的数值，保存到一个新的 []string 作为结果返回；  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func div(ns []string, prec int) []string { result := make([]string, 0) // 被除数 \tdividend, _ := strconv.ParseInt(ns[0], 10, 64) // 模 \tvar remainder int64 if dividend \u0026lt; 9 { remainder = dividend } else { result = append(result, \u0026#34;1\u0026#34;) } for _, v := range ns[1:] { addition, _ := strconv.ParseInt(v, 10, 64) dividend = remainder * 10 + addition result = append(result, fmt.Sprintf(\u0026#34;%d\u0026#34;, dividend / 9)) remainder = dividend % 9 } if prec \u0026gt; 0 { result = append(result, \u0026#34;.\u0026#34;) } for prec \u0026gt; 0 { dividend = remainder * 10 result = append(result, fmt.Sprintf(\u0026#34;%d\u0026#34;, dividend / 9)) remainder = dividend % 9 prec-- } return result } func main() { op1 := []string{\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;5\u0026#34;} prec := 6 result := div(op1, prec) for _, v := range result { fmt.Print(v) } fmt.Println() op2 := []string{\u0026#34;5\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;1\u0026#34;} prec = 7 result = div(op2, prec) for _, v := range result { fmt.Print(v) } fmt.Println() } 1371.666666 6035.6666666 math/big 包实现 Go 的 math/big 对于大数运算是有实现的，顺带也来看一看。math/big 的 Int 类型的结构如下：\ntype Int struct { neg bool // 符号 \tabs nat // 整数的绝对值 } type nat []Word type Word uint 所以 Int 类型的底层实现是一个 uint 切片，除法运算如下：\nfunc (z *Int) Div(x, y *Int) *Int { y_neg := y.neg // z may be an alias for y \tvar r Int z.QuoRem(x, y, \u0026amp;r) // Step 1 \tif r.neg { if y_neg { z.Add(z, intOne) } else { z.Sub(z, intOne) } } return z } func (z *Int) QuoRem(x, y, r *Int) (*Int, *Int) { z.abs, r.abs = z.abs.div(r.abs, x.abs, y.abs) // Step 2 \tz.neg, r.neg = len(z.abs) \u0026gt; 0 \u0026amp;\u0026amp; x.neg != y.neg, len(r.abs) \u0026gt; 0 \u0026amp;\u0026amp; x.neg // 0 has no sign \treturn z, r } func (z nat) div(z2, u, v nat) (q, r nat) { if len(v) == 0 { panic(\u0026#34;division by zero\u0026#34;) } if u.cmp(v) \u0026lt; 0 { q = z[:0] r = z2.set(u) return } if len(v) == 1 { var r2 Word q, r2 = z.divW(u, v[0]) r = z2.setWord(r2) return } q, r = z.divLarge(z2, u, v) return } 也是带了个余数 r *Int 参与计算，除法的计算使用了 Knuth\u0026rsquo;s Algorithm D。\n总结 后面查资料发现，整数除以 9 是有一定规律的，所以出题人才会这么出，这个确实没接触过，具体计算看这个吧《任意多位数除以 9：计算规律让你一辈子不忘》。\n 会就会，不会就是不会； 除以 9 的规律，可以知道，但不用去记，这种 tricky 的技巧并不具备普适性； 以后尽量多看看算法题； ","date":"2022-04-15","img":"/images/logo-interview-artist-magazine-interview.jpg","permalink":"/posts/interview-csig/","series":null,"tags":["面试经","大数除法"],"title":"CSIG 线上面试"},{"categories":["数据库"],"content":"数据库是应用的数据存储中心，请求增多和数据量增大都会对数据库造成严重的影响，导致数据库服务性能偏低。所以归纳了个别优化点，后续有看到新的内容也会追加。\nRoadmap 资源  MySQL 配置检查工具 tuning-primer MySQL 配置检查工具 MySQLTuner 配置项优化 MySQL Performance Tuning Settings ","date":"2022-04-14","img":"/images/balance-resources.png","permalink":"/posts/database-performance-tuning/","series":null,"tags":["MySQL","性能优化","roadmap"],"title":"MySQL 性能调优"},{"categories":["Python","数据挖掘","统计学"],"content":"在本文开头，贴一段百科对卡方检验基本原理的介绍：\n卡方检验就是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时，卡方值就为 0，表明理论值完全符合。\n由此可见，卡方检验刻画的是一种偏离程度。那么在相关性计算中也可以利用卡方检验计算出显著性来判断两个特征是否相关。\n卡方检验 卡方检验的步骤如下：\n 定义 H0 和 H1 假设； 根据领域知识定义显著性水平 $\\alpha$，一般取 0.05，表示有 5% 的容错； 计算卡方值； 计算显著性水平，小于 $\\alpha$ 则拒绝 H0 接受 H1；  离散型特征对 离散型特征对是指特征为离散值的两维向量，如帕尔默企鹅数据集中的特征对（species，island）。下面演示特征列（species，island）是否存在相关性。\n提出假设：\n H0：特征 species 和特征 island 不相关（独立）； H1：特征 species 和特征 island 相关；  频次统计 首先，根据出现的特征值对进行频次统计：\nimport numpy as np import pandas as pd # 读取数据集 # 特征 species，island 并不包含缺失值 df = pd.read_csv(\u0026#39;./dataset/penguins_size.csv\u0026#39;, na_values=[\u0026#39;NA\u0026#39;, \u0026#39;.\u0026#39;]) # 得到 species 和 island 所有的取值 # speices 值为行名，island 为列名 index = df[\u0026#39;species\u0026#39;].unique() columns = df[\u0026#39;island\u0026#39;].unique() # 初始化一个频次矩阵 count_matrix = np.zeros((index.shape[0], columns.shape[0])) # 遍历所有的 species 值 for i, species in enumerate(index): # 当 species 为某个特定值时，计算此时各 island 值出现的次数 counts = df[df[\u0026#39;species\u0026#39;]==species][\u0026#39;island\u0026#39;].value_counts() # 在对应的行和列设置次数值 for j, island in enumerate(columns): if island in counts.index: count_matrix[i][j] = counts[island] else: count_matrix[i][j] = 0 df_counts = pd.DataFrame(count_matrix, columns=columns, index=index) print(df_counts) Torgersen Biscoe Dream Adelie 52.0 44.0 56.0 Chinstrap 0.0 0.0 68.0 Gentoo 0.0 124.0 0.0 输出表示：\n 当 species 为 Adelie 时，表示 Torgersen 出现 52次，Biscoe 出现 44 次，Dream 出现 56 次； 其余类似；  计算估计值 估计值的计算公式如下： $$ E_{ij} = \\frac{R_i \\times C_j} {N} $$ 其中 $R_i$ 表示第 $i$ 行的总和；$C_j$ 表示第 $j$ 列的总和；$N$ 表示所有值的总和。代码如下：\n# 行和 rows_total = df_counts.sum(axis=1).values # 列和 cols_total = df_counts.sum(axis=0).values # 总和 total = df_counts.values.sum() # 根据公式计算估计值 estimated_count_matrix = np.zeros((index.shape[0], columns.shape[0])) for i in range(index.shape[0]): for j in range(columns.shape[0]): estimated_count_matrix[i][j] = rows_total[i]*cols_total[j]/total df_estimated_counts = pd.DataFrame(estimated_count_matrix, columns=columns, index=index) print(df_estimated_counts) Torgersen Biscoe Dream Adelie 22.976744 74.232558 54.790698 Chinstrap 10.279070 33.209302 24.511628 Gentoo 18.744186 60.558140 44.697674 计算卡方值 卡方值的计算公式如下： $$ {\\chi}^2 = \\sum \\frac {(O_{ij} - E_{ij})^2} {E_{ij}} $$ 其中 $O_{ij}$ 为实际的频次值。代码如下：\ndf_chisq = np.power(df_counts - df_estimated_counts, 2) / estimated_count_matrix print(df_chisq) Torgersen Biscoe Dream Adelie 36.660955 12.312759 0.026691 Chinstrap 10.279070 33.209302 77.156789 Gentoo 18.744186 66.462901 44.697674 chi = df_chisq.values.sum() print(chi) 299.55032743148195 计算显著性 先计算自由度，公式如下： $$ degree = (r - 1) \\times (c - 1) $$ 其中 $r$ 为行数；$c$ 为列数。计算显著性的代码如下：\nfrom scipy import stats degree = (len(index) - 1) * (len(columns) - 1) pvalue = 1 - stats.chi2.cdf(x=chi, df=degree) print(pvalue) 0.0 p 值小于 0.05，所以拒绝 H0，说明特征 species 和特征 island 相关。\n完整代码 import numpy as np import pandas as pd from scipy import stats df = pd.read_csv(\u0026#39;./dataset/penguins_size.csv\u0026#39;, na_values=[\u0026#39;NA\u0026#39;, \u0026#39;.\u0026#39;]) index = df[\u0026#39;species\u0026#39;].unique() columns = df[\u0026#39;island\u0026#39;].unique() count_matrix = np.zeros((index.shape[0], columns.shape[0])) for i, species in enumerate(index): counts = df[df[\u0026#39;species\u0026#39;]==species][\u0026#39;island\u0026#39;].value_counts() for j, island in enumerate(columns): if island in counts.index: count_matrix[i][j] = counts[island] else: count_matrix[i][j] = 0 df_counts = pd.DataFrame(count_matrix, columns=columns, index=index) print(df_counts) rows_total = df_counts.sum(axis=1).values cols_total = df_counts.sum(axis=0).values total = df_counts.values.sum() estimated_count_matrix = np.zeros((index.shape[0], columns.shape[0])) for i in range(index.shape[0]): for j in range(columns.shape[0]): estimated_count_matrix[i][j] = rows_total[i]*cols_total[j]/total df_estimated_counts = pd.DataFrame(estimated_count_matrix, columns=columns, index=index) print(df_estimated_counts) df_chisq = np.power(df_counts - df_estimated_counts, 2) / estimated_count_matrix print(df_chisq) chi = df_chisq.values.sum() print(chi) degree = (len(index) - 1) * (len(columns) - 1) pvalue = 1 - stats.chi2.cdf(x=chi, df=degree) print(pvalue) 参考  STAT #3: Chi-Squared Test(卡方检验) A beginner’s guide to Chi-square test in python from scratch  ","date":"2022-04-11","img":"/images/chi-square-test.webp","permalink":"/posts/python-chi-square-test/","series":null,"tags":["Chi-Square","scipy","NumPy","Pandas"],"title":"卡方检验 - 检验特征对是否相关"},{"categories":["Python","可视化","数据挖掘","机器学习","统计学"],"content":"今天导师在群里分享了一个链接 23 个优秀的机器学习训练公共数据集，看了一下，决定对帕尔默企鹅数据集（Palmer Archipelago (Antarctica) penguin data）做一些分析。\n数据集介绍 数据集是在 Kaggle 下载的，包含两个文件：\n penguins_lter.csv：原始数据文件； penguins_size.csv：特征约简后的数据文件；  本次分析使用的是简化后的数据集 penguins_size.csv。数据集共 344 个样本，特征信息如下表：\n   特征 数据类型 说明     species 离散值 标签信息，值为 Adelie|Chinstrap|Gentoo 之一   island 离散值 岛屿，值为 Torgersen|Biscoe|Dream 之一   culmen_length_mm 连续值 喙的长度（mm）   culmen_depth_mm 连续值 喙的高度（mm）   flipper_length_mm 连续值 脚蹼长度（mm）   body_mass_g 连续值 体重（克）   sex 离散值 性别，值为 MALE| FEMALE 之一     数据集包含缺失数据，用 NA 表示特征值缺失，其中第 337 样本的 sex 特征值为“.”，在此也认为是缺失值。\n 使用 pandas 查看数据集的统计信息：\nimport pandas as pd df = pd.read_csv(\u0026#39;./dataset/penguins_size.csv\u0026#39;, na_values=[\u0026#39;NA\u0026#39;, \u0026#39;.\u0026#39;]) print(df.describe()) culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g count 342.000000 342.000000 342.000000 342.000000 mean 43.921930 17.151170 200.915205 4201.754386 std 5.459584 1.974793 14.061714 801.954536 min 32.100000 13.100000 172.000000 2700.000000 25% 39.225000 15.600000 190.000000 3550.000000 50% 44.450000 17.300000 197.000000 4050.000000 75% 48.500000 18.700000 213.000000 4750.000000 max 59.600000 21.500000 231.000000 6300.000000 显然，统计信息中并不包含离散特征。\n缺失数据 对数据集的缺失数据进行一次统计。\n# 打印出不完整样本在数据集中的下标 print(df.isna().any(axis=1).where(lambda not_exist: not_exist).dropna().index) Int64Index([3, 8, 9, 10, 11, 47, 246, 286, 324, 336, 339], dtype=\u0026#39;int64\u0026#39;) # 打印出缺失特征值个数统计 print(df.isna().astype(int, False).sum()) species 0 island 0 culmen_length_mm 2 culmen_depth_mm 2 flipper_length_mm 2 body_mass_g 2 sex 11 dtype: int64 使用 missingno 包来查看缺失数据分布：\nimport missingno as msno msno.matrix(df) 综上，得到以下结论：\n 存在两个样本的 culmen_length_mm、culmen_depth_mm、flipper_length_mm、body_mass_g 和 sex 特征值缺失，编号分别为 3 和 339（以 0 为开始计数）； 缺失值主要集中在 sex 特征中，共有 11 个样本存在缺失；  预测企鹅性别 预测企鹅性别中，sex 为目标特征，所以先计算连续型特征与目标特征的 Point-biserial 相关系数 $r_{pb} (r_{pb} \\in [0, 1])$。\nfrom scipy import stats # 剔除数据集中不完整样本 df_com = df.drop([3, 8, 9, 10, 11, 47, 246, 286, 324, 336, 339], inplace=False) # 计算 Point-biserial 相关系数 series_sex = df_com.loc[:,\u0026#39;sex\u0026#39;].copy() series_sex[series_sex == \u0026#39;MALE\u0026#39;] = 0 series_sex[series_sex == \u0026#39;FEMALE\u0026#39;] = 1 print(\u0026#39;Point-biserial\u0026#39;) for column in df_com.columns[2:6]: cor, pvalue = stats.pointbiserialr(series_sex, df_com[column]) print(column, \u0026#34;\u0026lt;=\u0026gt;\u0026#34;, \u0026#39;sex\u0026#39;) print(\u0026#34;correlation: \u0026#34;, cor) print(\u0026#34;pvalue: \u0026#34;, pvalue) print() Point-biserial culmen_length_mm \u0026lt;=\u0026gt; sex correlation: -0.34407778223748564 pvalue: 1.0942555387200282e-10 culmen_depth_mm \u0026lt;=\u0026gt; sex correlation: -0.37267328821677664 pvalue: 2.0664103457552388e-12 flipper_length_mm \u0026lt;=\u0026gt; sex correlation: -0.2551688758106061 pvalue: 2.3910970925543724e-06 body_mass_g \u0026lt;=\u0026gt; sex correlation: -0.4249869909039952 pvalue: 4.897246751596804e-16 $r_{pb}$ 值为负，表示当目标特征 sex 为 0，特征（culmen_length_mm、culmen_depth_mm、flipper_length_mm、body_mass_g）趋向高于 sex 为 1 时对应的值。同时，4 个 p 值均小于 0.05，所以在统计意义上是显著的。\n然后计算离散型特征与目标特征的相关性，使用卡方检测进行判断，计算过程可看《卡方检验 - 检验特征对是否相关》。\nimport numpy as np from scipy import stats def chi_significance(x, y): \u0026#34;\u0026#34;\u0026#34;计算离散特征对卡方检验的显著性\u0026#34;\u0026#34;\u0026#34; index = x.unique() columns = y.unique() r, c = len(index), len(columns) count_matrix = np.zeros((r, c)) for i in range(r): counts = y[x==index[i]].value_counts() for j in range(c): if columns[j] in counts.index: count_matrix[i][j] = counts[columns[j]] rows_total = np.sum(count_matrix, axis=1) cols_total = np.sum(count_matrix, axis=0) total = count_matrix.sum() estimated_count_matrix = np.zeros((r, c)) for i in range(r): for j in range(c): estimated_count_matrix[i][j] = rows_total[i]*cols_total[j]/total chi = (np.power(count_matrix - estimated_count_matrix, 2) / estimated_count_matrix).sum() degree = (r - 1) * (c - 1) return 1 - stats.chi2.cdf(x=chi, df=degree) for column in [\u0026#39;species\u0026#39;, \u0026#39;island\u0026#39;]: print(column, \u0026#34;\u0026lt;=\u0026gt;\u0026#34;, \u0026#34;sex\u0026#34;) print(\u0026#34;pvalue: \u0026#34;, chi_significance(df_com[column], df_com[\u0026#39;sex\u0026#39;])) species \u0026lt;=\u0026gt; sex pvalue: 0.9759893689765846 island \u0026lt;=\u0026gt; sex pvalue: 0.971611229281065 从两对特征的 p 值可知，特征 species、island 与目标特征 sex 的相关性并不显著，所以排除相关。\n构建预测模型 从前文的相关性计算可知，目标特征 sex 与特征 species、island 不相关，但是与特征 culmen_length_mm、culmen_depth_mm、flipper_length_mm、body_mass_g 的相关性显著，所以在构建预测模型中不考虑特征 species 和 island。\n下面使用支持向量机（Support Vector Machine，SVM）对未知目标特征进行预测，采用 10-Fold 进行交叉验证：\nfrom sklearn.svm import SVC from sklearn.pipeline import make_pipeline from sklearn.preprocessing import StandardScaler from sklearn.model_selection import KFold from sklearn.model_selection import cross_val_score scaler = StandardScaler() scaler.fit(X) cv = KFold(n_splits=10, random_state=1, shuffle=True) clf = make_pipeline(scaler, SVC( gamma=\u0026#39;scale\u0026#39;, C=2., kernel=\u0026#39;rbf\u0026#39;, random_state=1, verbose=True, tol=0.00001 )) scores = cross_val_score(clf, X, y, scoring=\u0026#39;accuracy\u0026#39;, cv=cv, n_jobs=-1) print(\u0026#39;accuracy: %.3f(%.3f)\u0026#39; % (np.mean(scores), np.std(scores))) accuracy: 0.904 (0.047) clf.fit(X, y) test_X = df.iloc[[8, 9, 10, 11, 47, 246, 286, 324, 336],:][[\u0026#39;culmen_length_mm\u0026#39;, \u0026#39;culmen_depth_mm\u0026#39;, \u0026#39;flipper_length_mm\u0026#39;, \u0026#39;body_mass_g\u0026#39;]].values print(clf.predict(scaler.transform(test_X))) [\u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39;] 上述完成了以下几件事：\n 将特征 culmen_length_mm、culmen_depth_mm、flipper_length_mm、body_mass_g 作为输入，特征 sex 作为预测值； 对输入做标准化处理； 采用 10-Fold 交叉验证，输出平均准确率为 0.904，标准差为 0.047； 训练模型； 预测目标特征；  预测结果如下表：\n   编号 sex 预测值     8 MALE   9 MALE   10 MALE   11 MALE   47 MALE   246 MALE   286 MALE   324 MALE   336 MALE    从预测结果来看，怎么都是 MALE，本能地选择不相信模型结果 -|_|-。\n完整代码 import pandas as pd import missingno as msno from scipy import stats import numpy as np from sklearn.svm import SVC from sklearn.pipeline import make_pipeline from sklearn.preprocessing import StandardScaler from sklearn.model_selection import KFold from sklearn.model_selection import cross_val_score df = pd.read_csv(\u0026#39;./dataset/penguins_size.csv\u0026#39;, na_values=[\u0026#39;NA\u0026#39;, \u0026#39;.\u0026#39;]) print(df.describe()) # 打印出不完整样本在数据集中的下标 print(df.isna().any(axis=1).where(lambda not_exist: not_exist).dropna().index) # 打印出缺失特征值个数统计 print(df.isna().astype(int, False).sum()) msno.matrix(df) # 剔除数据集中不完整样本 df_com = df.drop([3, 8, 9, 10, 11, 47, 246, 286, 324, 336, 339], inplace=False) # 计算 Point-biserial 相关系数 series_sex = df_com.loc[:,\u0026#39;sex\u0026#39;].copy() series_sex[series_sex == \u0026#39;MALE\u0026#39;] = 0 series_sex[series_sex == \u0026#39;FEMALE\u0026#39;] = 1 print(\u0026#39;Point-biserial\u0026#39;) for column in df_com.columns[2:6]: cor, pvalue = stats.pointbiserialr(series_sex, df_com[column]) print(column, \u0026#34;\u0026lt;=\u0026gt;\u0026#34;, \u0026#39;sex\u0026#39;) print(\u0026#34;correlation: \u0026#34;, cor) print(\u0026#34;pvalue: \u0026#34;, pvalue) print() def chi_significance(x, y): \u0026#34;\u0026#34;\u0026#34;计算离散特征对卡方检验的显著性\u0026#34;\u0026#34;\u0026#34; index = x.unique() columns = y.unique() r, c = len(index), len(columns) count_matrix = np.zeros((r, c)) for i in range(r): counts = y[x==index[i]].value_counts() for j in range(c): if columns[j] in counts.index: count_matrix[i][j] = counts[columns[j]] rows_total = np.sum(count_matrix, axis=1) cols_total = np.sum(count_matrix, axis=0) total = count_matrix.sum() estimated_count_matrix = np.zeros((r, c)) for i in range(r): for j in range(c): estimated_count_matrix[i][j] = rows_total[i]*cols_total[j]/total chi = (np.power(count_matrix - estimated_count_matrix, 2) / estimated_count_matrix).sum() degree = (r - 1) * (c - 1) return 1 - stats.chi2.cdf(x=chi, df=degree) for column in [\u0026#39;species\u0026#39;, \u0026#39;island\u0026#39;]: print(column, \u0026#34;\u0026lt;=\u0026gt;\u0026#34;, \u0026#34;sex\u0026#34;) print(\u0026#34;pvalue: \u0026#34;, chi_significance(df_com[column], df_com[\u0026#39;sex\u0026#39;])) X, y = df_com[[\u0026#39;culmen_length_mm\u0026#39;, \u0026#39;culmen_depth_mm\u0026#39;, \u0026#39;flipper_length_mm\u0026#39;, \u0026#39;body_mass_g\u0026#39;]].values, df_com[\u0026#39;sex\u0026#39;].values scaler = StandardScaler() scaler.fit(X) cv = KFold(n_splits=10, random_state=1, shuffle=True) clf = make_pipeline(scaler, SVC( gamma=\u0026#39;scale\u0026#39;, C=2., kernel=\u0026#39;rbf\u0026#39;, random_state=1, verbose=True, tol=0.00001 )) scores = cross_val_score(clf, X, y, scoring=\u0026#39;accuracy\u0026#39;, cv=cv, n_jobs=-1) print(\u0026#39;accuracy: %.3f(%.3f)\u0026#39; % (np.mean(scores), np.std(scores))) clf.fit(X, y) test_X = df.iloc[[8, 9, 10, 11, 47, 246, 286, 324, 336],:][[\u0026#39;culmen_length_mm\u0026#39;, \u0026#39;culmen_depth_mm\u0026#39;, \u0026#39;flipper_length_mm\u0026#39;, \u0026#39;body_mass_g\u0026#39;]].values print(clf.predict(scaler.transform(test_X))) 总结  离散型特征与连续型特征的相关性可以通过 Point-biserial 相关系数进行衡量； 根据卡方检验判断离散型特征间是否相关； 预测模型为 SVM，采用 10-Fold 交叉验证的方式，预测出目标特征 sex；  参考  palmerpenguins 特征间相关系数.pdf sklearn.svm.SVC  ","date":"2022-04-11","img":"/images/Palmer-Archipelago-Antarctica-penguin-data.webp","permalink":"/posts/python-palmer-archipelago-penguin-testing/","series":null,"tags":["Matplotlib","sklearn"],"title":"帕尔默企鹅数据集测试"},{"categories":["Go"],"content":"在网络或 I/O 连接中，可以使用 net/rpc 包实现对一个对象的导出方法的调用，即远程过程调用（Remote Procedure Call，RPC）。通过向 RPC 服务注册一个对象，使其可被远程调用，进而实现一些复杂的业务逻辑。\n项目结构 示例项目的结构如下：\nclient - client.go - json_client.go models - greeting.go server - json_server.go - server.go 注册服务 一个可被远程调用的方法须满足以下条件：\n 方法所属结构是公开的； 方法是分开的； 方法的参数类型是分开的； 方法带两个参数，第 2 个参数为指针； 方法返回值为 error 类型；  如下，在 models/greeting.go 中定义了一个服务：\ntype GreetingArg struct { Name string } type GreetingReply struct { Message string } type Greeting struct {} // SayHello 方法满足上述条件 func (Greeting) SayHello(arg GreetingArg, reply *GreetingReply) error { reply.Message = \u0026#34;hello, \u0026#34; + arg.Name return nil } 现在，在 server/server.go 中编写服务器端代码：\npackage main import ( \u0026#34;gorpc/models\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc\u0026#34; ) func main() { server := rpc.NewServer() if err := server.Register(\u0026amp;models.Greeting{}); err != nil { log.Fatalln(err) } listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:2022\u0026#34;) if err != nil { log.Fatalln(err) } defer listener.Close() server.Accept(listener) } 服务器端注册了 Greeting 服务并监听了 2022 端口，等待客户端连接。在客户端 client/client.go 的代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;gorpc/models\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc\u0026#34; ) func main() { conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:2022\u0026#34;) if err != nil { log.Fatalln(err) } defer conn.Close() client := rpc.NewClient(conn) greetingArg := models.GreetingArg{Name: \u0026#34;a2htray\u0026#34;} greetingReply := models.GreetingReply{} if err = client.Call(\u0026#34;Greeting.SayHello\u0026#34;, greetingArg, \u0026amp;greetingReply); err != nil { log.Fatalln(err) } fmt.Println(greetingReply.Message) } 上述代码完成了以下几件事：\n 使用 net.Dial 连接 2022 端口； 在 TCP 连接之上，使用 rpc.NewClient 创建一个 RPC 客户端； 使用 client.Call 远程调用 Greeting 的 SayHello 方法； 返回的值体现在 greetingReply 变量中；  jsonrpc net/rpc 的传输数据使用 encoding/gob 进行编码解码，并且不支持跨语言调用，即只能使用 Go 编写的程序进行调用。encoding/gob 编码解码在源码中有给出：\n// rpc/server.go func (server *Server) ServeConn(conn io.ReadWriteCloser) { buf := bufio.NewWriter(conn) srv := \u0026amp;gobServerCodec{ rwc: conn, dec: gob.NewDecoder(conn), enc: gob.NewEncoder(buf), encBuf: buf, } server.ServeCodec(srv) } 除了 net/rpc，还可以使用 net/rpc/jsonrpc 实现 RPC 功能，该方式支持跨语言调用。新建 server/json_server.go，代码如下：\npackage main import ( \u0026#34;gorpc/models\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; ) func main() { err := rpc.Register(\u0026amp;models.Greeting{}) if err != nil { log.Fatalln(err) } listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:2023\u0026#34;) if err != nil { log.Fatalln(err) } defer listener.Close() for { conn, err := listener.Accept() if err != nil { log.Fatalln(err) } go jsonrpc.ServeConn(conn) } } 上述代码完成了以下几件事：\n 在 RPC 服务上注册了 Greeting； 监听了 2023 端口，使用 for 循环接受客户端连续； 对每一个连接使用协程进行处理；  新建 client/json_client.go，代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;gorpc/models\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; ) func main() { client, err := jsonrpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:2023\u0026#34;) if err != nil { log.Fatalln(err) } defer client.Close() greetingArg := models.GreetingArg{Name: \u0026#34;a2htray\u0026#34;} greetingReply := models.GreetingReply{} if err = client.Call(\u0026#34;Greeting.SayHello\u0026#34;, greetingArg, \u0026amp;greetingReply); err != nil { log.Fatalln(err) } fmt.Println(greetingReply.Message) } 上述代码完成了以下几件事：\n 使用 jsonrpc.Dial 连接到端口 2023； 使用 client.Call 调用了 Greeting.SayHello 方法； 打印输出返回信息；  rpc 与 jsonrpc 的区别 Go 内置的 rpc 与 jsonrpc 的区别在于：\n rpc 使用 gob 编码解码，jsonrpc 使用 json 编码解码； rpc 不支持跨语言调用，jsonrpc 支持跨语言调用； jsonrpc 在构建在 rpc 之上使用不同数据交换格式的 RPC 服务；  参考  golang下的rpc框架jsonrpc理解和使用示例 golang实现RPC的几种方式  ","date":"2022-04-10","img":"/images/operating-system-remote-procedure-call-1.png","permalink":"/posts/go-built-in-rpc-package/","series":null,"tags":["RPC","jsonrpc"],"title":"Go 内置的 RPC 包"},{"categories":["Go"],"content":"Go 1.18 在 2022 年 3 月 15 日发布，根据团队的博文介绍，1.18 版本包含 4 个重要特性：\n 泛型； fuzzing； 工作空间； 20% 的性能提升；  泛型 泛型是一种无须关心具体操作类型的编码方式，它将逻辑实现与具体类型解耦，体现在程序中的 3 个地方：\n 函数和类型的类型参数； 用于指定类型的集合； 类型推断，不需要显式指定类型；   本节是官方泛型教程的截取或修改内容，详细请查看此处。\n 不同类型求和函数 package main import \u0026#34;fmt\u0026#34; // sumInts 计算 int slice 的和 func sumInts(values []int) int { var total int for _, value := range values { total += value } return total } // sumFloat32s 计算 float32 slice 的和 func sumFloat32s(values []float32) float32 { var total float32 for _, value := range values { total += value } return total } // sum 计算的 slice 元素可以是 int 类型或 float32 类型 func sum[Element int | float32](values []Element) Element { var total Element for _, value := range values { total += value } return total } func main() { intValues := []int{1, 2, 3} float32Values := []float32{4, 5, 6} fmt.Println(sumInts(intValues)) fmt.Println(sumFloat32s(float32Values)) // sum(intValues) 等价于 sum[int](intValues) \tfmt.Println(sum(intValues)) fmt.Println(sum[int](intValues)) // sum(float32Values) 等价于 sum[float32](float32Values) \tfmt.Println(sum(float32Values)) fmt.Println(sum[float32](float32Values)) } 类型约束 示例 1：\npackage main import \u0026#34;fmt\u0026#34; // Number 类型约束，限制 Number 可以是 int 或 float32 type Number interface { int | float32 } // sum 求和 // [Element Number] 限定 Element 需要符合 Number 类型约束 // 即 Element 只能是 int 或 float32 func sum[Element Number](values []Element) Element { var total Element for _, value := range values { total += value } return total } func main() { intValues := []int{1, 2, 3} float32Values := []float32{4, 5, 6} fmt.Println(sum(intValues)) fmt.Println(sum(float32Values)) } 示例 2：\npackage main import \u0026#34;fmt\u0026#34; // Flag 底层类型为 int type Flag int const ( Flag_A Flag = iota Flag_B Flag_C ) // Number 类型约束 // ~ 操作符表示底层类型为 int 的类型也符合 type Number interface { float32 | ~int } func sum[Element Number](values []Element) Element { var total Element for _, value := range values { total += value } return total } func main() { flagValues := []Flag{ Flag_A, Flag_B, Flag_C, } float32Values := []float32{4, 5, 6} fmt.Println(sum(flagValues)) fmt.Println(sum(float32Values)) } 示例 3：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) type Flag int func (f Flag) String() string { return strconv.Itoa(int(f)) } const Flag_A Flag = iota // Number 包含了方法的类型约束 // 指定了 Number 类型的底层类型是 int 并实现了 String() string 方法 type Number interface { ~int String() string } func PrintNumber[V Number](number V) { fmt.Println(number.String()) } func main() { PrintNumber(Flag_A) } 示例 4：\npackage main import \u0026#34;fmt\u0026#34; type Flag int const ( Flag_A Flag = iota ) // PrintNumber 使用 ~ 操作符，定义类型底层实现 func PrintNumber[Number ~int](value Number) { fmt.Println(value) } func main() { PrintNumber(Flag_A) PrintNumber(1) } 总结  使用泛型可以减少相同逻辑（不同具体类型）的代码量； 使用 ~ 操作符指定底层类型； 类型约束中可以声明方法； ","date":"2022-04-10","img":"/images/golang-1.18-release.png","permalink":"/posts/go-1.18-release-features/","series":null,"tags":["Go 1.18"],"title":"Go 1.18 特性 - 泛型"},{"categories":["数据库"],"content":"Redis 服务器中与服务相关的命令，集群的配置过程可参考《Redis 集群配置过程》。\nCLUSTER nodes：显示集群主从关系 127.0.0.1:6380\u0026gt; CLUSTER nodes ac3f5aaae24bcd142b8303abedc5f57187ebc20e 127.0.0.1:6385@16385 slave 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c 0 1649562125672 2 connected 9242c455757da4ad2f5aa818d75d12cde38231c2 127.0.0.1:6383@16383 slave 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e 0 1649562126000 3 connected 5cc9ed2602986aeffaf9997f3c38c675092a4810 127.0.0.1:6384@16384 slave 92a1fd50a1c8dc003e905ac828b0db64773d6b66 0 1649562126674 1 connected 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e 127.0.0.1:6382@16382 master - 0 1649562124670 3 connected 10923-16383 92a1fd50a1c8dc003e905ac828b0db64773d6b66 127.0.0.1:6380@16380 myself,master - 0 1649562122000 1 connected 0-5460 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c 127.0.0.1:6381@16381 master - 0 1649562125000 2 connected 5461-10922 CLUSTER slots：显示哈希槽分配信息 127.0.0.1:6380\u0026gt; CLUSTER slots 1) 1) (integer) 0 2) (integer) 5460 3) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6380 3) \u0026#34;92a1fd50a1c8dc003e905ac828b0db64773d6b66\u0026#34; 4) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6384 3) \u0026#34;5cc9ed2602986aeffaf9997f3c38c675092a4810\u0026#34; 2) 1) (integer) 5461 2) (integer) 10922 3) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6381 3) \u0026#34;82ac1fe6c0af98d252ea96d4e84e7315eff31f8c\u0026#34; 4) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6385 3) \u0026#34;ac3f5aaae24bcd142b8303abedc5f57187ebc20e\u0026#34; 3) 1) (integer) 10923 2) (integer) 16383 3) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6382 3) \u0026#34;9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e\u0026#34; 4) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6383 3) \u0026#34;9242c455757da4ad2f5aa818d75d12cde38231c2\u0026#34; CLUSTER keyslot：显示 key 对应的哈希槽 127.0.0.1:6380\u0026gt; CLUSTER keyslot user:1:name (integer) 12440 ","date":"2022-04-10","img":"/images/redis-cluster.png","permalink":"/doc-redis-commands/cluster-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"集群相关"},{"categories":["Go"],"content":"Protocol Buffer 的介绍与语法已在文章《Protocol Buffer 语法》给出，本文则演示了 Protocol Buffer 如何减少了传输数据的大小。\n使用 protoc 命令生成 pb 代码文件 首先新建 proto/user.proto 文件来定义数据结构，其内容如下：\nsyntax = \u0026#34;proto3\u0026#34;;option go_package = \u0026#34;/model\u0026#34;;message User { string name = 1; enum Gender { MALE = 0; FEMALE = 1; }; Gender gender = 2;}然后，执行如下命令生成源代码文件：\nprotoc --go_out=. proto\\user.proto 主程序 main 主程序的作用是比较不同 User 结构序列化后的字节数据的大小。首先，新建 main.go 文件并定义一个 User 结构，如下：\ntype User struct { Name string Gender int32 } 主程序的逻辑如下：\nfunc main() { user := \u0026amp;User{ Name: \u0026#34;a2htray\u0026#34;, Gender: 1, } data, err = json.Marshal(user) fmt.Println(data, err) } 执行输出如下：\n[123 34 78 97 109 101 34 58 34 97 50 104 116 114 97 121 34 44 34 71 101 110 100 101 114 34 58 49 125] 29 \u0026lt;nil\u0026gt; 从输出可知，自定义的 User 的值序列化后的字节长度为 29。\n接着，使用 Protocol Buffer 生成的 User 结构并使用 proto.Marshal 方法对值进行序列化，代码如下：\nfunc main() { userPB := \u0026amp;model.User{ Name: \u0026#34;a2htray\u0026#34;, Gender: 1, } data, err = proto.Marshal(userPB) fmt.Println(data, len(data), err) } 执行输出如下：\n[10 7 97 50 104 116 114 97 121 16 1] 11 \u0026lt;nil\u0026gt; 从输出可知，Protocol Buffer 生成的 User 类型的值序列化后的字节长度为 11。\n综上，分别使用 JSON 和 Protocol Buffer 序列化相同的数据信息，使用 Protocol Buffer 得到的字节长度要更小，更有得于在网络中的传输。\n完整代码 演示完成后，当前项目的目录结构如下：\nmodel - user.pb.go # 通过 protoc 命令生成 proto - user.proto # 定义数据结构 main.go main.go 的完整内容如下：\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;./model\u0026#34; \u0026#34;google.golang.org/protobuf/proto\u0026#34; ) type User struct { Name string Gender int32 } func main() { user := \u0026amp;User{ Name: \u0026#34;a2htray\u0026#34;, Gender: 1, } data, err := json.Marshal(user) fmt.Println(data, len(data), err) userPB := \u0026amp;model.User{ Name: \u0026#34;a2htray\u0026#34;, Gender: 1, } data, err = proto.Marshal(userPB) fmt.Println(data, len(data), err) } 总结  Protocol Buffer 序列化的数据量更小； ","date":"2022-04-09","img":"","permalink":"/posts/protocol-buffer-reduce-data-size/","series":null,"tags":["protocol buffer"],"title":"Protocol Buffer 减少传输数据的大小"},{"categories":["Go"],"content":"Protocol Buffer（Protobuf） 是一种高效的数据结构序列化的机制，同时也是一种结构化数据的存储格式。\n 序列化与反序列化\n 序列化：将数据结构或对象转换成二进制串的过程； 反序列化：将序列化后的二进制串转换成数据结构或对象的过程；   语法 /* * 语法 *//* * 指定 Protobuf 解析使用的版本，可以是 proto3 或 proto2 */syntax = \u0026#34;proto3\u0026#34;;/* * message 定义中的每一个字段都有一个唯一标识，该标识用于在二进制格式中识别字段 * 字段的标识一旦使用就不要进行修改 * 当标识为 1 到 15 时，使用一个字节进行编码，字节信息中包含字段的标识以及类型 * 当标识为 16 到 2047 时，使用两个字节进行编码 * Field numbers in the range 16 through 2047 take two bytes. So you should reserve the numbers 1 through 15 for very frequently occurring message elements. * 在编码的过程中，标识使用应当留有余地，便于将来扩展 * 标识最小的值是 1，最大的值为 2^29-1 * 不能使用的标识为 19000 到 19999 * 不能再使用已经被 reserved 的标识 *//* 定义 message 的语法： message ${MessageName} { ${Scalar Value Type} ${FieldName1} = ${Tag Number1}; . . . ${Scalar Value Type} ${FieldNameN} = ${Tag NumberN}; } */message MessageTypes { /* * 标量值类型 */ string stringType = 1; // 字符串可以是 UTF-8 编码，也可以是一个 7 比特的 ASCII 字符，默认为“”  // 数值类型，默认为 0  int32 int32Type = 2; // 使用变量长度进行编码，如果是负数，请使用 sint32  int64 int64Type = 3; // 使用变量长度进行编码，如果是负数，请使用 sint64  uint32 uInt32Type = 4; // 使用变量长度进行编码  uint64 uInt64Type = 5; // 使用变量长度进行编码  sint32 sInt32Type = 6; // 使用变量长度进行编码，处理负数更高效  sint64 sInt64Type = 7; // 使用变量长度进行编码，处理负数更高效  fixed32 fixed32Type = 8; // 变量总是占 4 个字节，当值大于 2^28 时，比使用 uint32 更有效率  fixed64 fixed64Type = 9; // 变量总是占 8 个字节，当值大于 2^56 时，比使用 uint64 更有效率  sfixed32 sfixed32Type = 10; // 变量总是占 4 个字节  sfixed64 sfixed64Type = 11; // 变量总是占 8 个字节  bool boolType = 12; // 布尔类型，默认为 false  bytes bytesType = 13; // 可包含任意长度的字节数组，默认为长度为 0 的字节数组  double doubleType = 14; float floatType = 15; enum Week { UNDEFINED = 0; // 第 1 个值  SUNDAY = 1; MONDAY = 2; TUESDAY = 3; WEDNESDAY = 4; THURSDAY = 5; FRIDAY = 6; SATURDAY = 7; } Week wkDayType = 16; /* * 定义标量值类型的集合 * Syntax: repeated ${ScalarType} ${name} = TagValue */ repeated string listOfString = 17; // List[String] }/* * 在其它 message 中使用已定义的 message */message Person { string fname = 1; string sname = 2;}message City { Person p = 1;}/* * 嵌套的 message 定义 */message NestedMessages { message FirstLevelNestedMessage { string firstString = 1; message SecondLevelNestedMessage { string secondString = 2; } } FirstLevelNestedMessage msg = 1; FirstLevelNestedMessage.SecondLevelNestedMessage msg2 = 2;}/* * .proto 文件的引入 */// one.proto // message One { // string oneMsg = 1; // } // two.proto // import \u0026#34;myproject/one.proto\u0026#34; // message Two { // string twoMsg = 2; // } /* * 高级知识点 *//* * message 发生改变时，永远不要修改或使用已经删除字段的标识 *//* * 使用 reserved 保留已删除的标识或字段名 */message ReservedMessage { reserved 0, 1, 2, 3 to 10; // 这里的标识不可再使用  reserved \u0026#34;firstMsg\u0026#34;, \u0026#34;secondMsg\u0026#34;, \u0026#34;thirdMsg\u0026#34;; // 这里的字段名不可再使用 }/* * 引用其它文件中定义的 message */import \u0026#34;google/protobuf/any.proto\u0026#34;;message AnySampleMessage { repeated google.protobuf.Any.details = 1;}/* * OneOf * 相同于 union，只能是其中一个 * 使用 oneof 的 message 不能被 repeated */message OneOfMessage { oneof msg { string fname = 1; string sname = 2; };}/* * Maps * map 字段不能被 repeated */message MessageWithMaps { map\u0026lt;string, string\u0026gt; mapOfMessages = 1;}/* * Packages * 声明一个包名，防止同名的 message * 语法: package ${packageName}; 访问方式 ${packageName}.${messageName} = ${tagNumber}; *//* * 在 RPC 系统中使用，其中可以定义方法 */message SearchRequest { string queryString = 1;}message SearchResponse { string queryResponse = 1;}service SearchService { rpc Search (SearchRequest) returns (SearchResponse);}数据类型 Protobuf 内置的数据类型以及在 Go 中对应的数据类型：\n   Protobuf Go     double float64   float float32   int32 int32   int64 int64   uint32 uint32   uint64 uint64   sint32 int32   sint64 int64   fixed32 uint32   fixed64 uint64   sfixed64 int64   bool bool   string string   bytes []byte    书写规范 代码编写要遵循某种特定的规则，如 Python 的 PEP8，.proto 文件的内容也应该按照统一的格式，这样才能规范团队编码风格，易于他人理解。\n message 采用驼峰命名法且首字母大写；  message UserConfig {} // 符合 message user_config {} // 不符合  字段名采用下划线分隔命名法且均小写；  message Product { string fasta_origin = 1;} // 符合 message Product { string FastaOrigin = 1} // 不符合  枚举型命名格式与 message 相同，枚举值全部大写，并且用下划线分隔命名法；  enum Week { MY_MONDAY = 0} // 符合 enum Week { MyMonday = 0} // 不符合  service 和方法名都采用驼峰命名法，并且首字母大写；  service Greeter { rpc SayHello(HelloRequest) returns (HelloReply);} // 符合 service Greeter { rpc say_hello(HelloRequest) returns (HelloReply);} // 不符合 与 JSON 的区别    Protobuf JSON     由 Google 开发、用于序列化和反序列化结构化数据的高效编码方式 轻量型的数据交换格式   可自定义规则、方法的消息格式 仅仅只是一种消息格式   二进制格式 文本格式   支持的语言有限 绝大部分语言都支持   微服务间数据传输的格式 WEB 应用与服务器间的传输格式   相同数据序列化后的数据量较小 相同数据序列化后的数据量较大    参考  https://learnxinyminutes.com/docs/protocol-buffer-3/ https://zhuanlan.zhihu.com/p/95869546  ","date":"2022-04-08","img":"","permalink":"/posts/protocol-buffer-syntax/","series":null,"tags":["protocol buffer"],"title":"Protocol Buffer 语法"},{"categories":["数据库","运维"],"content":"Redis 集群是基于“主从复制”特性之上的分布式 Redis 版本，可提供高并发、高性能、高可用的数据库服务。Redis 集群突破了单台服务器的内存局限，集群中的每一个节点都可以存储数据，同时维护着 \u0026ldquo;key-node\u0026rdquo; 的映射表。本文记录了 3 主 3 从的 Redis 集群的配置过程，主要内容包括：\n Redis 集群的配置过程； 集群相关命令； Go 存取集群数据；  环境信息\n$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.2 LTS Release: 20.04 Codename: focal $ redis-server -v Redis server v=6.2.6 sha=00000000:0 malloc=jemalloc-5.1.0 bits=64 build=9c9e426e2f96cc51 配置过程 配置文件 3 主使用的端口分别为 6380、6381 和 6382，3 从使用的端口为 6383、6384 和 6385。创建配置文件以及工作目录：\n$ mkdir /etc/redis/cluster $ chown redis.redis /etc/redis/cluster $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6380.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6381.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6382.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6383.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6384.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6385.conf 各配置文件的修改内容如下：\n# /etc/redis/cluster/redis-6380.conf port 6380 cluster-enabled yes pidfile /run/redis/redis-server-6380.pid logfile /var/log/redis/redis-server-6380.log dbfilename dump-6380.rdb cluster-config-file nodes-6380.conf # /etc/redis/cluster/redis-6381.conf port 6381 cluster-enabled yes pidfile /run/redis/redis-server-6381.pid logfile /var/log/redis/redis-server-6381.log dbfilename dump-6381.rdb cluster-config-file nodes-6381.conf # /etc/redis/cluster/redis-6382.conf port 6382 cluster-enabled yes pidfile /run/redis/redis-server-6382.pid logfile /var/log/redis/redis-server-6382.log dbfilename dump-6382.rdb cluster-config-file nodes-6382.conf # /etc/redis/cluster/redis-6383.conf port 6383 cluster-enabled yes pidfile /run/redis/redis-server-6383.pid logfile /var/log/redis/redis-server-6383.log dbfilename dump-6383.rdb cluster-config-file nodes-6383.conf # /etc/redis/cluster/redis-6384.conf port 6384 cluster-enabled yes pidfile /run/redis/redis-server-6384.pid logfile /var/log/redis/redis-server-6384.log dbfilename dump-16381.rdb cluster-config-file nodes-6384.conf 启动脚本 编写 redis-cluster.sh 脚本，记得 chmod a+x redis-cluster.sh 一下：\n#!/bin/bash  if [ \u0026#34;$1\u0026#34; == \u0026#34;start\u0026#34; ]; then redis-server /etc/redis/cluster/redis-6380.conf redis-server /etc/redis/cluster/redis-6381.conf redis-server /etc/redis/cluster/redis-6382.conf redis-server /etc/redis/cluster/redis-6383.conf redis-server /etc/redis/cluster/redis-6384.conf redis-server /etc/redis/cluster/redis-6385.conf elif [ \u0026#34;$1\u0026#34; == \u0026#34;stop\u0026#34; ]; then redis-cli -p 6380 shutdown redis-cli -p 6381 shutdown redis-cli -p 6382 shutdown redis-cli -p 6383 shutdown redis-cli -p 6384 shutdown redis-cli -p 6385 shutdown else echo \u0026#34;please, pass an action [start|stop]\u0026#34; fi 启动所有 Redis 节点：\n$ ./redis-cluster.sh start 验证集群节点是否启动：\nps -ef | grep redis-server root 4025397 1 0 11:10 ? 00:00:00 redis-server *:6380 [cluster] root 4025405 1 0 11:10 ? 00:00:00 redis-server *:6381 [cluster] root 4025411 1 0 11:10 ? 00:00:00 redis-server *:6382 [cluster] root 4025417 1 0 11:10 ? 00:00:00 redis-server *:6383 [cluster] root 4025423 1 0 11:10 ? 00:00:00 redis-server *:6384 [cluster] root 4025429 1 0 11:10 ? 00:00:00 redis-server *:6385 [cluster] 配置集群 使用 redis-cli 命令配置集群：\n$ redis-cli --cluster create 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385 --cluster-replicas 1 \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 6 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 Adding replica 127.0.0.1:6384 to 127.0.0.1:6380 Adding replica 127.0.0.1:6385 to 127.0.0.1:6381 Adding replica 127.0.0.1:6383 to 127.0.0.1:6382 \u0026gt;\u0026gt;\u0026gt; Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: 92a1fd50a1c8dc003e905ac828b0db64773d6b66 127.0.0.1:6380 slots:[0-5460] (5461 slots) master M: 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c 127.0.0.1:6381 slots:[5461-10922] (5462 slots) master M: 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e 127.0.0.1:6382 slots:[10923-16383] (5461 slots) master S: 9242c455757da4ad2f5aa818d75d12cde38231c2 127.0.0.1:6383 replicates 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e S: 5cc9ed2602986aeffaf9997f3c38c675092a4810 127.0.0.1:6384 replicates 92a1fd50a1c8dc003e905ac828b0db64773d6b66 S: ac3f5aaae24bcd142b8303abedc5f57187ebc20e 127.0.0.1:6385 replicates 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join . \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 127.0.0.1:6380) M: 92a1fd50a1c8dc003e905ac828b0db64773d6b66 127.0.0.1:6380 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: ac3f5aaae24bcd142b8303abedc5f57187ebc20e 127.0.0.1:6385 slots: (0 slots) slave replicates 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c S: 9242c455757da4ad2f5aa818d75d12cde38231c2 127.0.0.1:6383 slots: (0 slots) slave replicates 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e S: 5cc9ed2602986aeffaf9997f3c38c675092a4810 127.0.0.1:6384 slots: (0 slots) slave replicates 92a1fd50a1c8dc003e905ac828b0db64773d6b66 M: 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e 127.0.0.1:6382 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c 127.0.0.1:6381 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. 输出信息为集群的哈希槽的分配信息及主从关系，可知：\n 共有 16384（以 0 开始计数），将 0-5460 的哈希槽分配给主节点 1，将 5461-10922 的哈希槽分配给主节点 2，将 10923-16383 的哈希槽分配给主节点 3； 127.0.0.1:6384 是 127.0.0.1:6380 的备份，127.0.0.1:6385 是 127.0.0.1:6381 的备份，127.0.0.1:6383 是 127.0.0.1:6382 的备份；  管理工具 RedisInsight 是 Redis 官方提供的 Redis 服务器图形化管理工具，操作性很强，包含：\n 数据维护； 性能测试； 可视化； 支持不同类型的 Redis 服务；  注意事项  创建集群时，如果一个 Redis 实例中含有键值对，集群会创建失败；  [ERR] Node 127.0.0.1:6380 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0. 集群模式中，各 Redis 节点要使用两个端口，分别为指定的 port 和 port+10000； ","date":"2022-04-07","img":"","permalink":"/posts/redis-cluster-deployment/","series":null,"tags":["Redis"],"title":"Redis 集群配置过程"},{"categories":["Python","可视化"],"content":"每当有快速绘制图表的需求时，第一时间反应到的肯定是 Matplotlib，因为其官方提供了详细的 API 文档及示例。但是每次在编码时，总是时不时地需要查看文档，不利用于可视化快速成型。所以在本文中罗列一些 bar 图的快速实现，方便 Ctrl+C/V。\n基本实现 import matplotlib.pyplot as plt import numpy as np data = [120, 200, 150, 80, 70, 110, 130] x = np.arange(len(data)) plt.bar( x, # bar 在 x 轴的位置 data, width=0.6, # bar 的宽度 label=\u0026#39;Sales\u0026#39;, ) plt.xticks( x, # 标签的位置 [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], ) plt.legend() plt.title(\u0026#39;Products\u0026#39;) bar 设置颜色 import matplotlib.pyplot as plt import numpy as np colors = [\u0026#39;#009392\u0026#39;, \u0026#39;#39b185\u0026#39;, \u0026#39;#9ccb86\u0026#39;, \u0026#39;#e9e29c\u0026#39;, \u0026#39;#eeb479\u0026#39;, \u0026#39;#e88471\u0026#39;, \u0026#39;#cf5974\u0026#39;] data = [120, 200, 150, 80, 70, 110, 130] x = np.arange(len(data)) plt.bar( x, data, width=0.6, color=colors, # 单值或者可迭代对象，如果长度与数组不匹配则会从头反复使用色值 ) plt.xticks( x, [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], ) plt.title(\u0026#39;Sales\u0026#39;) 显示数值 import matplotlib.pyplot as plt import numpy as np colors = [\u0026#39;#009392\u0026#39;, \u0026#39;#39b185\u0026#39;, \u0026#39;#9ccb86\u0026#39;, \u0026#39;#e9e29c\u0026#39;, \u0026#39;#eeb479\u0026#39;, \u0026#39;#e88471\u0026#39;, \u0026#39;#cf5974\u0026#39;] data = [120, 200, 150, 80, 70, 110, 130] x = np.arange(len(data)) bar = plt.bar( x, data, width=0.6, color=colors, ) plt.bar_label( bar, label_type=\u0026#39;edge\u0026#39;, # 标签显示的位置，edge 为默认值；如果是 center 则显示在 bar 中间（垂直水平居中） ) plt.xticks( x, [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], ) plt.title(\u0026#39;Sales\u0026#39;) 层叠 bar 图 import matplotlib.pyplot as plt import numpy as np data_man = [120, 200, 150, 80, 70, 110, 130] data_woman = [100, 50, 90, 50, 80, 30, 30] x = np.arange(len(data)) bar1 = plt.bar( x, data_man, label=\u0026#39;Man\u0026#39;, color=\u0026#39;#009392\u0026#39;, ) bar2 = plt.bar( x, data_woman, bottom=data_man, label=\u0026#39;Woman\u0026#39;, color=\u0026#39;#cf5974\u0026#39;, ) plt.bar_label( bar1, label_type=\u0026#39;center\u0026#39;, labels=data_man, # 设置显示的值 ) plt.bar_label( bar2, label_type=\u0026#39;center\u0026#39;, labels=data_woman, ) plt.xticks( x, [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], ) plt.legend() 多条 bar 通过调整 bar 的位置和宽度来实现多条 bar 不重叠显示。\nimport matplotlib.pyplot as plt import numpy as np data_man = [120, 200, 150, 80, 70, 110, 130] data_woman = [100, 50, 90, 50, 80, 30, 30] x = np.arange(len(data)) width = 0.4 bar1 = plt.bar( x - width/2, # 位置 data_man, width=width, # 宽度 label=\u0026#39;Man\u0026#39;, color=\u0026#39;#eeb479\u0026#39;, ) bar2 = plt.bar( x + width/2, data_woman, width=width, label=\u0026#39;Woman\u0026#39;, color=\u0026#39;#cf5974\u0026#39;, ) plt.bar_label(bar1) plt.bar_label(bar2) plt.legend() 动态 bar 图 import matplotlib.pyplot as plt import numpy as np from matplotlib.animation import FuncAnimation data_man = [120, 200, 150, 80, 70, 110, 130] frames = 10 fig = plt.figure() axes = fig.add_subplot(1,1,1) axes.set_ylim(0, 250) def generate_animate_data(data, n): \u0026#34;\u0026#34;\u0026#34;生成每帧的数据\u0026#34;\u0026#34;\u0026#34; animate_data = [] for v in data: animate_data.append(np.linspace(0, v, n)) return np.array(animate_data) animate_data = generate_animate_data(data_man, frames) def animate(i): plt.bar( [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], animate_data[:,i], color=\u0026#39;#eeb479\u0026#39;, label=\u0026#39;Man\u0026#39; ) ani = FuncAnimation( fig, animate, frames=frames, # 帧数 interval=300, ) plt.title(\u0026#39;Man\u0026#39;) bar 图案 plt.bar 函数有两个可选参数 facecolor 和 edgecolor 控制。\nimport matplotlib.pyplot as plt import numpy as np bar_styles = { \u0026#39;man\u0026#39;: { \u0026#39;facecolor\u0026#39;: \u0026#39;#ee8479\u0026#39;, \u0026#39;edgecolor\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;hatch\u0026#39;: \u0026#39;//\u0026#39;, }, \u0026#39;woman\u0026#39;: { \u0026#39;facecolor\u0026#39;: \u0026#39;#cf5974\u0026#39;, \u0026#39;edgecolor\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;hatch\u0026#39;: \u0026#39;--\u0026#39;, } } data_man = [120, 200, 150, 80, 70, 110, 130] data_woman = [100, 50, 90, 50, 80, 30, 30] x = np.arange(len(data)) width = 0.4 bar1 = plt.bar( x - width/2, data_man, width=width, label=\u0026#39;Man\u0026#39;, **bar_styles[\u0026#39;man\u0026#39;] ) bar2 = plt.bar( x + width/2, data_woman, width=width, label=\u0026#39;Woman\u0026#39;, **bar_styles[\u0026#39;woman\u0026#39;] ) plt.bar_label(bar1) plt.bar_label(bar2) plt.legend() ","date":"2022-04-05","img":"","permalink":"/posts/python-matplotlib-bar-tips/","series":null,"tags":["Matplotlib"],"title":"Matplotlib Bar 图常规编码"},{"categories":["Python","数据挖掘"],"content":"k-means 算法是一种无监督的聚类算法，其优点是逻辑简单、易于实现。\n基本原理 质心是指一个簇中样本的均值向量，k-means 中的 means 就是从这里来的。当确定 k 个质心后，需要计算样本与 k 个质心的距离，而样本则归属于距离最近的质心所在的簇。随着算法的迭代，质心的位置会发生变化。质心的变化程度也是算法结束的一个条件，迭代前后质心位置变化通常使用 SSE 来刻画。\n其中 $n$ 是质心的维数，$c^{(t)}_{ij}$ 表示 $t$ 次迭代中第 $i$ 个质心的第 $j$ 维值。\n步骤  确定 k 值、最大迭代数及误差值； 随机选择 k 个样本作为质心； 分别计算样本与质心的距离，将样本划分到 k 个簇； 重新计算 k 个簇的质心，比较前后质心的误差；  若误差小于等于设置的误差值，则算法结束； 若误差大于设置的误差值，则执行步骤 5；   判断是否达到最大迭代数，若未达到则执行步骤 3，否则算法结束；  问题 选择 k-means 算法做聚类分析时，以下几个问题值得注意：\n 初始质心的选择； k 值的确定； 距离公式的确定；  k-means 算法容易局部最优，并且算法的结果在很大程度上取决于初始质心的选择，不同的初始质心可能会得到截然不同的聚类结果。同时，在面对未知类别个数的数据集时，如何确定 k 值也是一件麻烦事。通常做法都在小样本集上尝试不同的 k 值，然后比较聚类的结果并将 k 值定为跑得最好结果的那次 k 值。距离公式的选择则是需要依靠领域知识，因为在不同的领域中，样本的相似度的计算方式会有所不同。\n完整代码 import numpy as np import matplotlib.pyplot as plt def distance(x1, x2): \u0026#34;\u0026#34;\u0026#34;欧式距离\u0026#34;\u0026#34;\u0026#34; return np.sqrt(np.sum(np.power(x1 - x2, 2))) def sse(centroids1, centroids2): return np.sum(np.sqrt(np.sum(np.power(centroids1 - centroids2, 2), axis=1))) def update_centroid(centroids, data): r, _ = data.shape cluster_idxs = [] for i in range(len(centroids)): cluster_idxs.append([]) for i in range(r): ds = np.array([distance(data[i], centroid) for centroid in centroids]) sorted_idxs = np.argsort(ds) cluster_idxs[sorted_idxs[0]].append(i) new_centroids = [] for i, cluster_idx in enumerate(cluster_idxs): if len(cluster_idx) == 0: new_centroids.append(centroids[i]) else: new_centroids.append(np.mean(data[cluster_idx], axis=0)) return np.array(new_centroids) def initial_centroids(k, data): r, _ = data.shape idxs = np.arange(0, r) np.random.shuffle(idxs) return data[idxs[:k]] def cluster(centroids, data): r, _ = data.shape cluster_idxs = [] for i in range(len(centroids)): cluster_idxs.append([]) for i in range(r): ds = np.array([distance(data[i], centroid) for centroid in centroids]) sorted_idxs = np.argsort(ds) cluster_idxs[sorted_idxs[0]].append(i) return cluster_idxs data = np.random.uniform(5, 10, size=(400, 2)) k = 5 colors = [\u0026#39;#4e9e9d\u0026#39;, \u0026#39;#86cc7f\u0026#39;, \u0026#39;#506798\u0026#39;, \u0026#39;#4f1b63\u0026#39;, \u0026#39;#fbe85a\u0026#39;] tol = 1e-6 iteration = 12 plt.figure(figsize=(10, 4)) fig = plt.figure(figsize=(10, 15)) axes = fig.subplots(nrows=3, ncols=2) centroids = initial_centroids(k, data) i = 0 while iteration \u0026gt;= 0: if iteration % 2 == 1: cluster_idxs = cluster(centroids, data) for color_idx, cluster_idx in enumerate(cluster_idxs): fig.axes[i].scatter(data[cluster_idx][:,0], data[cluster_idx][:,1], c=colors[color_idx]) fig.axes[i].scatter(centroids[:,0], centroids[:,1], s=30, marker=\u0026#39;*\u0026#39;, c=\u0026#39;red\u0026#39;) fig.axes[i].set_title(\u0026#39;iter %d\u0026#39; % iteration) i = i + 1 new_centroids = update_centroid(centroids, data) if sse(new_centroids, centroids) \u0026lt;= tol: centroids = new_centroids break centroids = new_centroids iteration = iteration - 1 下图是执行得到的一次结果图：\n其它  帖子讨论了 k-means 和 c-means 是否是相同的概念，得票最多的回答认为是同一概念，所以本文对两者不作区分；  总结  k-means 算法结束的两个条件；  迭代结束； 质心位置变化小于误差值；   Python 实现 k-means 算法； ","date":"2022-04-02","img":"/images/357_2019_9314_Fig1_HTML.png","permalink":"/posts/data-analysis-kmeans/","series":null,"tags":["k-means"],"title":"K-Means 基本原理及其实现"},{"categories":["Go","Web"],"content":"Revel 是一个以高效率、高性能著称的 Go Web 框架，提供了路由、参数解析和验证、会话机制、模板机制、缓存和任务管理等诸多常用的 Web 开发功能。同时作为一个全栈的 MVC 框架， Revel 通过模块实现了组件的复用，因此可以大大提高开发者的效率。其高性能则是依托 Go 语言的性能，相信这个不必多说。但相较于其它职责相对单一的 Web 框架（如 Gin、go-restful），Revel 只能说是在保证性能的基础上尽可能地对开发者友好。\n问题重现 环境\n  Go 的版本：go1.16.9 windows/amd64\n  Revel：v1.0.0\n  今天在试验 Revel 项目时，运行新建的项目会报错，如下：\n$ revel run -a . ERROR 10:46:39 file.go:372: Error seeking=github.com/revel/revel count=1 App Import Path=github.com/revel/revel filesystem path=github.com/revel/revel errors=\u0026#34;[-: no required module provides package github.com/revel/revel; to add it:\\n\\tgo get github.com/revel/revel]\u0026#34; Downloading related packages ... completed. Revel executing: run a Revel application WARN 10:46:41 harness.go:175: No http.addr specified in the app.conf listening on localhost interface only. This will not allow external access to your application Changed detected, recompiling Parsing packages, (may require download if not cached)...Changed detected, recompiling Completed ERROR 10:46:44 build.go:406: Build errors errors=\u0026#34;C:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\memcached.go:11:2: no required module provides package github.com/bradfitz/gomemcache/memcache; to add it:\\n\\tgo get github.com/bradfitz/gomemcache/memcache\\nC:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\redis.go:10:2: no required module provides package github.com/garyburd/redigo/redis; to add it:\\n\\tgo get github.com/garyburd/redigo/redis\\nC:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\inmemory.go:12:2: no required module provides package github.com/patrickmn/go-cache; to add it:\\n\\tgo get github.com/patrickmn/go-cache\\n\u0026#34; C:\\Users\\a2htray\\go\\src\\omics-framework\\C:\\Users\\a2htray\\go\\pkg\\mod\\github.com\\revel\\revel@v1.0.0\\cache\\memcached.go:11 WARN 10:46:44 build.go:420: Could not find in GO path file=C:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\memcached.go:11 ERROR 10:46:44 harness.go:239: Build detected an error error=\u0026#34;Go Compilation Error (in C:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\memcached.go:11:2): no required module provides package github.com/bradfitz/gomemcache/memcache; to add it:\u0026#34; Error compiling code, to view error details see proxy running on http://:9000 Time to recompile 2.4257731s 新建的 Revel 项目使用 go.mod 对包进行管理，初始的包如下：\nrequire ( github.com/go-stack/stack v1.8.1 // indirect github.com/revel/modules v1.0.0 github.com/revel/revel v1.0.0 ) 通过错误输出，可知当前项目缺少了 3 个包：\ngithub.com/bradfitz/gomemcache/memcache github.com/garyburd/redigo/redis github.com/patrickmn/go-cache 解决办法 既然是项目缺少包，那就只要把缺失的包 go get 一下即可。\n$ go get github.com/bradfitz/gomemcache/memcache $ go get github.com/garyburd/redigo/redis $ go get github.com/patrickmn/go-cache 再次运行：\n$ revel run -a . Revel executing: run a Revel application WARN 11:33:47 harness.go:175: No http.addr specified in the app.conf listening on localhost interface only. This will not allow external access to your application Changed detected, recompiling Parsing packages, (may require download if not cached)... Completed Changed detected, recompiling INFO 11:33:54 app run.go:34: Running revel server INFO 11:33:54 app plugin.go:9: Go to /@tests to run the tests. Revel proxy is listening, point your browser to : Revel engine is listening on.. localhost:52469 9000 Time to recompile 7.0696399s 其它 在这个 issue 1528  里，有人说是 Go 版本问题，即在 Go 1.15 中是可以运行的。我想解决上面的问题，就把缺失包补上就可以了，而且也猜应该不是 Go 版本问题，毕竟 Revel 的 cache 实现中也确实使用了这 3 个包。再深入想一想，如果 Revel 项目也是通过 Go Module 管理包的话，revel run 的时候就会自动下载这些包。\n","date":"2022-03-31","img":"","permalink":"/posts/go-revel-run-require-packages/","series":null,"tags":["Revel"],"title":"Go 1.16 运行 Revel 项目"},{"categories":["数据库","运维"],"content":"Redis 主从复制可以实现数据库的读写分离，即主节点负责接收写请求、从节点负责接收读请求，是高性能 Redis 服务的基础。所以配置 Redis 主从复制应当作为开发者的技能之一，后文内容包括：\n 单机配置一主二从的主从复制服务 服务验证；  环境信息\n$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.2 LTS Release: 20.04 Codename: focal $ redis-server -v Redis server v=6.2.6 sha=00000000:0 malloc=jemalloc-5.1.0 bits=64 build=9c9e426e2f96cc51 配置过程 主节点使用 6379 端口，两个从节点分别使用 6380 和 6381 端口。\nRedis 配置文件 复制两份 Redis 配置文件分别为两个从节点的配置文件：\ncp -a /etc/redis/redis.conf /etc/redis/redis-server-6380.conf cp -a /etc/redis/redis.conf /etc/redis/redis-server-6381.conf 修改两个配置文件的内容，修改及新增内容如下：\n# redis-6380.conf # 修改项 port 6380 pidfile /run/redis/redis-server-6380.pid logfile /var/log/redis/redis-server-6380.log dbfilename dump-6380.rdb # 新增项 slaveof 127.0.0.1 6379 # redis-6381.conf # 修改项 port 6381 pidfile /run/redis/redis-server-6381.pid logfile /var/log/redis/redis-server-6381.log dbfilename dump-6381.rdb # 新增项 slaveof 127.0.0.1 6379 systemd 配置文件 复制两份 systemd 配置文件分别作为两个从节点的服务启动文件：\ncp -a /lib/systemd/system/redis-server.service /lib/systemd/system/redis-server-6380.service cp -a /lib/systemd/system/redis-server.service /lib/systemd/system/redis-server-6381.service 修改两个配置文件的内容，均为修改项，如下：\n# redis-server-6380.service [Service] ExecStart=/usr/bin/redis-server /etc/redis/redis-server-6380.conf PIDFile=/run/redis/redis-server-6380.pid # redis-server-6381.service [Service] ExecStart=/usr/bin/redis-server /etc/redis/redis-server-6381.conf PIDFile=/run/redis/redis-server-6381.pid 修改之后，需要执行如下命令进行重新加载：\nsystemctl daemon-reload 启动服务 配置完成后，通过 systemd 的管理命令分别在 3 个终端各启动 1 个服务，命令及显示如下：\n# 主节点 $ systemctl start redis-server.service $ redis-cli -p 6379 127.0.0.1:6379\u0026gt; INFO Replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6380,state=online,offset=308,lag=0 slave1:ip=127.0.0.1,port=6381,state=online,offset=308,lag=1 # 其它 ... # 从节点 6380 $ systemctl start redis-server-6380.service $ redis-cli -p 6380 127.0.0.1:6380\u0026gt; INFO Replication # Replication role:slave master_host:127.0.0.1 master_port:6379 # 其它 ... # 从节点 6381 $ systemctl start redis-server-6381.service $ redis-cli -p 6381 127.0.0.1:6381\u0026gt; INFO Replication # Replication role:slave master_host:127.0.0.1 master_port:6379 # 其它 ... 读写 Redis 数据库 是否发生主从复制，可按如下的命令依次执行进行验证。\n# 主节点 127.0.0.1:6379\u0026gt; SET topic master-slave-replication OK # 从节点 6380 127.0.0.1:6380\u0026gt; GET topic \u0026#34;master-slave-replication\u0026#34; # 从节点 6381 127.0.0.1:6381\u0026gt; GET topic \u0026#34;master-slave-replication\u0026#34; 其它 systemd 是 Linux 服务器管理服务的其中一种方式，服务的启动与关闭也可以通过 redis-server 命令或其它方式进行实现。Redis 使用到的目录及文件信息包括：\n /run/redis/：存放 Redis 服务的 pid 文件，由 pidfile 配置项决定；  /var/log/redis/：存放 Redis 服务的日志文件，由 logfile 配置项决定； /var/lib/redis：存放 RDB 文件，由 dir 和 dbfilename 配置项决定；  完整脚本 #!/bin/bash  SLAVE1_PORT=6380 SLAVE2_PORT=6381 cat /etc/redis/redis.conf | \\ sed \u0026#34;s/^port\\ 6379/port\\ $SLAVE1_PORT/g\u0026#34; | \\ sed \u0026#34;s/^pidfile \\/run\\/redis\\/redis-server\\.pid/pidfile \\/run\\/redis\\/redis-server-$SLAVE1_PORT\\.pid/g\u0026#34; | \\ sed \u0026#34;s/^logfile \\/var\\/log\\/redis\\/redis-server\\.log/logfile \\/var\\/log\\/redis\\/redis-server-$SLAVE1_PORT\\.log/g\u0026#34; | \\ sed \u0026#34;s/^dbfilename dump\\.rdb/dbfilename dump-$SLAVE1_PORT\\.rdb/g\u0026#34; | \\ sed \u0026#34;\\$a\\\\slaveof 127.0.0.1 6379\\\\\u0026#34; \u0026gt; /etc/redis/redis-server-$SLAVE1_PORT.conf chown redis.redis /etc/redis/redis-server-$SLAVE1_PORT.conf cat /etc/redis/redis.conf | \\ sed \u0026#34;s/^port\\ 6379/port\\ $SLAVE2_PORT/g\u0026#34; | \\ sed \u0026#34;s/^pidfile \\/run\\/redis\\/redis-server\\.pid/pidfile \\/run\\/redis\\/redis-server-$SLAVE2_PORT\\.pid/g\u0026#34; | \\ sed \u0026#34;s/^logfile \\/var\\/log\\/redis\\/redis-server\\.log/logfile \\/var\\/log\\/redis\\/redis-server-$SLAVE2_PORT\\.log/g\u0026#34; | \\ sed \u0026#34;s/^dbfilename dump\\.rdb/dbfilename dump-$SLAVE2_PORT\\.rdb/g\u0026#34; | \\ sed \u0026#34;\\$a\\\\slaveof 127.0.0.1 6379\\\\\u0026#34; \u0026gt; /etc/redis/redis-server-$SLAVE2_PORT.conf chown redis.redis /etc/redis/redis-server-$SLAVE2_PORT.conf cat /lib/systemd/system/redis-server.service | \\ sed \u0026#34;s/\\/etc\\/redis\\/redis\\.conf/\\/etc\\/redis\\/redis-server-$SLAVE1_PORT\\.conf/g\u0026#34; | \\ sed \u0026#34;s/\\/run\\/redis\\/redis-server\\.pid/\\/run\\/redis\\/redis-server-$SLAVE1_PORT\\.pid/g\u0026#34; \u0026gt; /lib/systemd/system/redis-server-$SLAVE1_PORT.service chown root.root /lib/systemd/system/redis-server-$SLAVE1_PORT.service cat /lib/systemd/system/redis-server.service | \\ sed \u0026#34;s/\\/etc\\/redis\\/redis\\.conf/\\/etc\\/redis\\/redis-server-$SLAVE2_PORT\\.conf/g\u0026#34; | \\ sed \u0026#34;s/\\/run\\/redis\\/redis-server\\.pid/\\/run\\/redis\\/redis-server-$SLAVE2_PORT\\.pid/g\u0026#34; \u0026gt; /lib/systemd/system/redis-server-$SLAVE2_PORT.service chown root.root /lib/systemd/system/redis-server-$SLAVE2_PORT.service systemctl daemon-reload systemctl start redis-server.service systemctl start redis-server-$SLAVE1_PORT.service systemctl start redis-server-$SLAVE2_PORT.service 总结  Redis 主从复制的配置过程； Redis 服务相关配置项说明； ","date":"2022-03-30","img":"","permalink":"/posts/redis-master-slave-replication-deployment/","series":null,"tags":["Redis"],"title":"Redis 主从复制配置过程"},{"categories":["数据库"],"content":"Redis 服务器中与服务相关的命令。\nINFO：查看当前服务器信息 格式：INFO [section]\n127.0.0.1:6380\u0026gt; INFO # Server redis_version:6.2.6 redis_git_sha1:00000000 redis_git_dirty:0 redis_build_id:9c9e426e2f96cc51 redis_mode:standalone os:Linux 5.4.0-77-generic x86_64 arch_bits:64 # 还有很多 ... SHUTDOWN：客户端断开连接 格式：SHUTDOWN [NOSAVE|SAVE]\n127.0.0.1:6379\u0026gt; SHUTDOWN SAVE not connected\u0026gt; EXIT：退出客户端 127.0.0.1:6379\u0026gt; EXIT ","date":"2022-03-30","img":"","permalink":"/doc-redis-commands/server-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"服务相关"},{"categories":["Web"],"content":"同源策略（Same-Origin Policy，SOP）是一种保护 Web 资源的安全机制，它限制了不同源之间的资源访问。需要说明的是，SOP 只作用于应用脚本，这意味着在 HTML 标签中可以引入不同源的图片、CSS 文件或动态加载的脚本文件（见验证 1）。\n同源 URL 统一资源标识符（Uniform Resource Locator，URL）标识了一个 Web 资源，其格式为：\nschema://host[:port][/path ...]\n其中 schema 可为 http 或 https，port 默认为 80。如果两个 URL 的 schema、host、port 都相同时，则认为这两个 URL 是同源的。现有 URL 为 http://foo.com/bar，以下是其它 URL 是否同源的说明。\n   URL 是否同源 说明     https://foo.com 否 schema 不同   http://bar.com 否 host 不同   http://foo.com:81/bar 否 port 不同   http://foo.com/zot 是 3 个都相同    访问规则 通常，直接读取跨域资源是不允许的，但仍然可以通过内嵌跨域资源进行访问。以下是允许跨域访问的规则：\n   方式 说明     iframes 响应头的 X-Frame-Options 字段可以设置 \u0026lt;frame\u0026gt;、\u0026lt;iframe\u0026gt;、\u0026lt;embed\u0026gt; 或 object 标签可引用的页面，但跨域读 iframe 里的内容是不允许的   CSS \u0026lt;link\u0026gt; 标签的 href 属性和 CSS 文件中的 @import 指令   forms 此处不应该是读取，而是说 \u0026lt;form\u0026gt; 的 action 属性可以设置不同源的 URL，指的是目标服务可以接收不同源的数据   images 通过 \u0026lt;img\u0026gt; 标签访问跨域图片，但在 canvas 元素里加载跨域图片是不允许的   multimedia 通过 \u0026lt;video\u0026gt; 和 \u0026lt;audio\u0026gt; 标签加载跨域的多媒体资源   script 通过 \u0026lt;script\u0026gt;  标签加载跨域的脚本，但请求跨域的 API 是不允许的    所以以上的规则容易变成 Web 服务攻击的入口，应当警惕。\n验证 验证 1 示例目录结构\n验证 1 - static - images profile.jpg index.html main.go // main.go package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { fs := http.FileServer(http.Dir(\u0026#34;./static/\u0026#34;)) http.Handle(\u0026#34;/static/\u0026#34;, http.StripPrefix(\u0026#34;/static\u0026#34;, fs)) log.Fatal(http.ListenAndServe(\u0026#34;:8001\u0026#34;, nil)) } \u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;验证 1\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;图片不受同源策略限制\u0026lt;/p\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; height=\u0026#34;100\u0026#34; alt=\u0026#34;profile\u0026#34; src=\u0026#34;http://localhost:8001/static/images/profile.jpg\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 总结  URL 是否同源取决于 schema、host、port 是否一致； 尽管跨域访问是不允许的，但仍然有一定的跨域可访问规则； ","date":"2022-03-29","img":"","permalink":"/posts/web-same-origin-policy/","series":null,"tags":["Web 安全"],"title":"同源策略 Same-Origin Policy"},{"categories":["Python"],"content":"在开发过程中，开发者常常需要对文件执行读写操作，仅以此文记录读写文件的常规用法。\n打开和关闭文件 Python 的内建函数 open 可以打开一个文件，可返回一个文件对象 TextIOWrapper（也称文件句柄）。打开的文件应当及时关闭，否则过多的文件对象容易造成内存占用，导致程序运行内存不足。按照是否调用文件对象的 close 方法，有两种打开和关闭文件的代码书写方式：\n 显式 close 隐式 close  显式 close\ndef open1(): f = open(\u0026#39;./students.dat\u0026#39;) try: lines = f.readlines() print(lines) finally: f.close() 隐式 close\ndef open2(): with open(\u0026#39;./students.dat\u0026#39;) as f: lines = f.readlines() print(lines)  支持 with 语句的对象需要实现 __enter__ 和 __exit__ 两个方法，其中 TextIOWrapper 类实现了 __exit__ 方法，IOBase 类实现了 __enter__ 方法。\n 上述两个函数的作用相同，都是用于打开 students.dat 文件并打印所有的行。\nopen 函数 内建函数 open 的签名如下：\ndef open( file: _OpenFile, mode: OpenTextMode = ..., buffering: int = ..., encoding: str | None = ..., errors: str | None = ..., newline: str | None = ..., closefd: bool = ..., opener: _Opener | None = ..., ) -\u0026gt; TextIOWrapper: ...  file：字符串文件路径或实现了 os.PathLike 抽象类的实例； mode：打开模式，默认 r，可选； buffering：设置缓冲策略，可选； encoding：编码格式，可选； errors：编码或解码发生错误时的错误信息，可选； newline：断行的方式，可用的参数值有 None、' '、'\\n'、'\\r' 和 '\\r\\n'，可选； closefd：必须为 True，否则报错，可选； opener：自定义的打开器，调用的函数，返回一个文件描述符，可选；  os.PathLike 抽象类 os.PathLike 是一个抽象类，定义了 __fspath__ 方法，任何实现了 __fspath__ 方法的类的实例都可以作为 open 函数的 file 参数值。\nimport os class MyFile(os.PathLike): def __init__(self, filename) -\u0026gt; None: self.filename = filename def __fspath__(self): return self.filename def open3(): with open(MyFile(\u0026#39;./students.dat\u0026#39;)) as f: lines = f.readlines() print(lines) mode 参数值 mode 参数值可为：\n   Mode      'r' 读打开（默认）   'w' 读打开，若文件不存在则创建，若文件存在则会清空文件内容   'x' 以独占的方式创建文件，如果文件已存在则报错   'a' 以追加的形式打开文件，文件不存在会创建，文件存在的话，不会清空文件内容   't' 文本模式（默认）   'b' 二进制打开文件   '+' 以更新的方式打开文件    f.close 方法 当文件对象调用 close 方法后，对象的 closed 属性会置为 True，也可以通过该属性可以检查文件对象是否关闭。\ndef view_f_closed(): f = open(\u0026#39;./students.dat\u0026#39;) f.close() print(f.closed) 读写文件 文件对象中有如下几个方法可用于读取文件内容：\n   方法 用法     .read(size=-1) 按指定的字节数读取文件内容，当 size 为 -1 时，表示读取全部   .readline(size=-1) 按指定的字符数读取一行的内容，当 size 为 None 或 -1 时，表示读取整行内容   .readlines() 读取文件中所有的行    文件对象中有如下几个方法可用于写入文件内容：\n   方法 用法     .write(string) 向文件写入字符串   .writelines(seq) 向文件中写入多行，换行符需要开发者指定    编码问题 若文件中存在中文，需要指定 encoding 参数的值，如：\ndef read_chinese(): with open(\u0026#39;./students.zh-cn.dat\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: lines = f.readlines() print(lines) 遍历文件所有的行 下面列表读取文件所有的行的几种方式。\n方式 1\ndef iterate_lines1(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: line = f.readline() while line != \u0026#39;\u0026#39;: print(line, end=\u0026#39;\u0026#39;) line = f.readline() 方式 2\ndef iterate_lines2(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: lines = f.readlines() for line in lines: print(line, end=\u0026#39;\u0026#39;) 方式 3\ndef iterate_lines3(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: for line in f: print(line, end=\u0026#39;\u0026#39;) 总结 本文的完整代码如下：\nimport os def open1(): f = open(\u0026#39;./students.dat\u0026#39;) try: lines = f.readlines() print(lines) finally: f.close() def open2(): with open(\u0026#39;./students.dat\u0026#39;) as f: lines = f.readlines() print(lines) class MyFile(os.PathLike): def __init__(self, filename) -\u0026gt; None: self.filename = filename def __fspath__(self): return self.filename def open3(): with open(MyFile(\u0026#39;./students.dat\u0026#39;)) as f: lines = f.readlines() print(lines) def view_f_closed(): f = open(\u0026#39;./students.dat\u0026#39;) f.close() print(f.closed) def read_chinese(): with open(\u0026#39;./students.zh-cn.dat\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: lines = f.readlines() print(lines) def iterate_lines1(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: line = f.readline() while line != \u0026#39;\u0026#39;: print(line, end=\u0026#39;\u0026#39;) line = f.readline() def iterate_lines2(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: lines = f.readlines() for line in lines: print(line, end=\u0026#39;\u0026#39;) def iterate_lines3(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: for line in f: print(line, end=\u0026#39;\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: print(\u0026#39;书写方式 1:\u0026#39;) open1() print(\u0026#39;书写方式 2:\u0026#39;) open2() print(\u0026#39;实现了 os.PathLike 抽象类\u0026#39;) open3() print(\u0026#39;调用 f.close 后:\u0026#39;) view_f_closed() print(\u0026#39;遍历所有的行 1:\u0026#39;) iterate_lines1() print(\u0026#39;遍历所有的行 2:\u0026#39;) iterate_lines2() print(\u0026#39;遍历所有的行 3:\u0026#39;) iterate_lines3() print(\u0026#34;读取中文:\u0026#34;) read_chinese() 运行输出为：\n书写方式 1: [\u0026#39;xiaoming\\n\u0026#39;, \u0026#39;xiaohong\\n\u0026#39;, \u0026#39;xiaolei\\n\u0026#39;, \u0026#39;xiaopang\\n\u0026#39;] 书写方式 2: [\u0026#39;xiaoming\\n\u0026#39;, \u0026#39;xiaohong\\n\u0026#39;, \u0026#39;xiaolei\\n\u0026#39;, \u0026#39;xiaopang\\n\u0026#39;] 实现了 os.PathLike 抽象类 [\u0026#39;xiaoming\\n\u0026#39;, \u0026#39;xiaohong\\n\u0026#39;, \u0026#39;xiaolei\\n\u0026#39;, \u0026#39;xiaopang\\n\u0026#39;] 调用 f.close 后: True 遍历所有的行 1: xiaoming xiaohong xiaolei xiaopang 遍历所有的行 2: xiaoming xiaohong xiaolei xiaopang 遍历所有的行 3: xiaoming xiaohong xiaolei xiaopang 读取中文: [\u0026#39;小明\\n\u0026#39;, \u0026#39;小红\\n\u0026#39;, \u0026#39;小磊\\n\u0026#39;, \u0026#39;小胖\\n\u0026#39;] 本文可总结为以下几点：\n 打开文件后，应该及时关闭。如果不想显式地调用 close 方法，推荐使用 with 语句； open 函数的 mode 参数指定了文件打开的模式，mode 参数的几个可选值非常重要； 列举了几个读写文件的常用方法，如读的 read、readline 和 readlines；写的 write 和 writelines； 3 种遍历文件所有行的方式； ","date":"2022-03-28","img":"","permalink":"/posts/python-read-and-write-file/","series":null,"tags":["file"],"title":"Python 读写文件"},{"categories":["数据库"],"content":"栈（Stack）和队列（Queue）是编程中常用的两种数据结构，下面通过 Redis 的列表（List）类型来实现栈和队列。\n栈 栈是一种受限的线性表，即“只能在一端进行插入和删除操作”，其特点是后进先出（Last In First Out，LIFO）。假设列表的右端为栈顶（插入和删除的一端），则需要使用到 RPUSH 和 RPOP 两个命令。\n127.0.0.1:6379\u0026gt; RPUSH stack 1 2 3 4 5 6 (integer) 6 127.0.0.1:6379\u0026gt; RPOP stack \u0026#34;6\u0026#34; 127.0.0.1:6379\u0026gt; RPUSH stack 7 8 9 (integer) 8 127.0.0.1:6379\u0026gt; RPOP stack \u0026#34;9\u0026#34; 127.0.0.1:6379\u0026gt; RPOP stack \u0026#34;8\u0026#34; 上述命令的说明如下：\n RPUSH stack 1 2 3 4 5 6 ：按插入的先后顺序，此时列表为 [1, 2, 3, 4, 5, 6]； RPOP：从列表右端弹出 1 个元素，该元素为 6，此时列表为 [1, 2, 3, 4, 5]； RPUSH stack 7 8 9：列表右端插入 3 个元素，此时列表为 [1, 2, 3, 4, 5, 7, 8, 9]； 最后的两次 RPOP stack：分别弹出元素 9 和 8，此时列表为 [1, 2, 3, 4, 5, 7]；  队列 队列也是一种受限的线性表，即“一端只能插入，另一端只能删除”，其特点是先进先出（First In First Out，FIFO）。假设列表的左端是队首（删除的一端），右端是队尾（插入的一端），则需要使用到 LPUSH 和 LPOP 两个命令。\n127.0.0.1:6379\u0026gt; RPUSH queue 1 2 3 4 5 6 (integer) 6 127.0.0.1:6379\u0026gt; LPOP queue \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; RPUSH queue 7 8 9 (integer) 8 127.0.0.1:6379\u0026gt; LPOP queue \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; LPOP queue \u0026#34;3\u0026#34; 上述命令的说明如下：\n RPUSH queue 1 2 3 4 5 6：按插入的先后顺序，此时列表为 [1, 2, 3, 4, 5, 6]； LPOP queue：从列表左端弹出 1 个元素，此时列表为 [2, 3, 4, 5, 6]； RPUSH queue 7 8 9：列表右端插入 3 个元素，此时列表为 [2, 3, 4, 5, 6, 7, 8, 9]； 最后两次 LPOP queue：分别从左端弹出元素 2 和 3，此时列表为 [4, 5, 6, 7, 8, 9]； ","date":"2022-03-27","img":"","permalink":"/doc-redis-commands/examples/stack-and-queue/","series":["Redis 命令手册"],"tags":["Redis"],"title":"列表模拟栈和队列"},{"categories":["数据库"],"content":"Redis 服务器中与 key 相关的命令。\nKEYS：获取数据库中匹配规则的键名 KEYS 命令遍历数据库中的所有键，支持 glob 风格通配符格式，在存在大量键值对的 Redis 服务器上应谨慎使用。\n格式：KEYS patten\n127.0.0.1:6379\u0026gt; KEYS * (empty array) 127.0.0.1:6379\u0026gt; SET config:logLevel Fatal OK 127.0.0.1:6379\u0026gt; KEYS config:* 1) \u0026#34;config:logLevel\u0026#34;  glob 风格通配符格式\n   符号 含义     ? 匹配一个字符   * 匹配任意多个字符   [] 匹配括号间的任一字符   \\ 转义     EXISTS：判断键名是否存在 EXISTS 用于判断键名是否存在，返回值为存在键名的个数。\n格式：EXISTS key [key ...]\n127.0.0.1:6379\u0026gt; EXISTS config:logLevel config:pagination (integer) 1 127.0.0.1:6379\u0026gt; EXISTS config:pagination (integer) 0 EXPIRE：给键设置过期时间 EXPIRE 可以给一个键设置一个以秒为单位的过期时间。\n格式：EXPIRE key seconds\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; EXPIRE user:1:name 5 (integer) 1 127.0.0.1:6379\u0026gt; GET user:1:name \u0026#34;xiaoming\u0026#34; # 5 秒内访问 127.0.0.1:6379\u0026gt; GET user:1:name (nil) # 5 秒后访问 EXPIREAT：给键设置过期时间 EXPIREAT 通过指定一个 UNIX 时间戳为键设置一个过期时间。\n格式：EXPIREAT key timestamp\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; EXPIREAT user:1:name 1648470000 (integer) 1 # 1648470000 为 2022-03-28 20:20:00 127.0.0.1:6379\u0026gt; GET user:1:name \u0026#34;xiaoming\u0026#34; PEXPIRE：给键设置过期时间 PEXPIRE 与 EXPIRE 类似，不同之处在于 PEXPIRE 的时间单位是微秒。\n格式：PEXPIRE key milliseconds\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; PEXPIRE user:1:name 10000 (integer) 1 127.0.0.1:6379\u0026gt; GET user:1:name \u0026#34;xiaoming\u0026#34; # 10 秒内访问 127.0.0.1:6379\u0026gt; GET user:1:name (nil) # 10 秒后访问 PEXPIREAT：给键设置过期时间 PEXPIREAT 与 EXPIREAT 类似，不同之外在于 PEXPIREAT 的时间单位是微秒。\n格式：PEXPIREAT key milliseconds-timestamp\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) -1 127.0.0.1:6379\u0026gt; PEXPIREAT user:1:name 1648470000000 (integer) 1 PERSIST：移除键的过期时间 PERSIST 可以移除键的过期，使其永不失效。\n格式：PERSIST key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; EXPIRE user:1:name 100 (integer) 1 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) 93 127.0.0.1:6379\u0026gt; PERSIST user:1:name (integer) 1 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) -1 TTL：返回键的剩余生存时间 TTL 返回以秒为单位的键的剩余生存时间，对长期有效的键使用会返回 -1。\n格式：TTL key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; EXPIRE user:1:name 100 (integer) 1 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) 93 127.0.0.1:6379\u0026gt; SET user:1:name xiaoming (integer) 1 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) -1 PTTL：返回键的剩余生存时间 PTTL 与 TTL 类似，不同之外在于返回的剩余生存时间的单位为微秒。\n格式：PTTL key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; PTTL user:1:name (integer) -1 127.0.0.1:6379\u0026gt; EXPIRE user:1:name 100 (integer) 1 127.0.0.1:6379\u0026gt; PTTL user:1:name (integer) 93978 RENAME：修改键名 RENAME 可用于修改键名。\n格式：RENAME key newkey\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; RENAME user:1:name user:2:name OK 127.0.0.1:6379\u0026gt; GET user:2:name \u0026#34;xiaoming\u0026#34; RENAMENX：修改键名 RENAMENX 命令只有在给定的新键名不存在时，才会起作用。\n格式：RENAMENX key newkey\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; KEYS user:newname* (empty array) 127.0.0.1:6379\u0026gt; RENAMENX user:1:name user:newname:1:name (integer) 1 127.0.0.1:6379\u0026gt; GET user:1:name (nil) 127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; RENAMENX user:1:name user:1:name (integer) 0 # 新键名不变，但执行不成功 DEL：删除一个或多个键 DEL 用于删除一个或多个键，返回值为删除键的个数。\n格式：DEL key [key ...]\n127.0.0.1:6379\u0026gt; DEL config:logLevel config:pagination (integer) 1 # config:pagination 此时并不存在，故返回值为 1 RANDOMKEY：随机返回一个键 格式：RANDOMKEY key\n127.0.0.1:6379\u0026gt; RANDOMKEY \u0026#34;student:weights\u0026#34; DUMP：序列化给定的键 DUMP 可以序列化指定的键并返回序列化的值。\n格式：DUMP key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; DUMP user:1:name \u0026#34;\\x00\\bxiaoming\\t\\x00\\xe6u\\x97\\x84\\x19\\x1c\\x01\\x81\u0026#34; TYPE：获取指定键对应值的类型 TYPE 用于获取指定键对应值的类型，返回值包括 string | hash | list | set | zset | stream\n格式：TYPE key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; TYPE user:1:name string DBSIZE：返回数据库中 key 的数量 格式：DBSIZE\n127.0.0.1:6379\u0026gt; DBSIZE (integer) 26 ","date":"2022-03-27","img":"/images/redis-key.jpeg","permalink":"/doc-redis-commands/key-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"键相关"},{"categories":["数据库"],"content":"Redis 是开源的、高性能的数据结构存储系统，在框架设计中常常被当作缓存服务器。不同于传统的关系型数据库（如 MySQL、PostgreSQL），Redis 将数据以键值对的方式存储于内存并且支持数据持久化。尽管 Redis 采用了单线程模型来处理请求，但其通过 I/O 多路复用技术做到了应用级别的异步，运行的性能也十分良好。\n根据操作对象的不同，可将 Redis 中的命令分成以下几类：\n 键相关命令 字符串值相关命令 列表值相关命令 集合值相关命令 有序集合值相关命令 流类型值相关命令 集群相关命令 服务相关命令  介绍完命令后，本文还会通过以下几个示例更一步说明命令的用法：\n 列表模拟栈和队 ","date":"2022-03-27","img":"/images/redis.png","permalink":"/doc-redis-commands/introduction/","series":["Redis 命令手册"],"tags":["Redis"],"title":"介绍"},{"categories":["数据库"],"content":"Redis 服务器中与 stream 相关的命令。\nXADD：向 stream 添加消息 XADD 可以向 stream 添加消息，返回实体 entry 的 ID。\n格式：XADD key *|ID field value [field value ...]\n127.0.0.1:6379\u0026gt; XADD chat:1:messages * msg \u0026#34;hello world\u0026#34; date 2020 \u0026#34;1648184286632-0\u0026#34; 127.0.0.1:6379\u0026gt; XADD chat:2:messages 1 msg \u0026#34;hello world\u0026#34; date 2020 \u0026#34;1-0\u0026#34; XRANGE：返回 stream 记录的列表 XRANGE 用于获取指定 ID 范围内的 entry，其中 - 和 + 为特征 ID，分别表示最小 ID 和最大 ID。\n格式：XRANGE key start stop [COUNT count]\n127.0.0.1:6379\u0026gt; XADD chat:1:messages * msg \u0026#34;hello GO\u0026#34; date 2021 \u0026#34;1648184498673-0\u0026#34; 127.0.0.1:6379\u0026gt; XADD chat:1:messages * msg \u0026#34;hello TypeScript\u0026#34; date 2022 \u0026#34;1648184539697-0\u0026#34; 127.0.0.1:6379\u0026gt; XRANGE chat:1:messages - + 1) 1) \u0026#34;1648184286632-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello world\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2020\u0026#34; 2) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; 3) 1) \u0026#34;1648184539697-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello TypeScript\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2022\u0026#34; 127.0.0.1:6379\u0026gt; XRANGE chat:1:messages 1648184286632-0 1648184286632-1 1) 1) \u0026#34;1648184286632-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello world\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2020\u0026#34; 127.0.0.1:6379\u0026gt; XRANGE chat:1:messages 1648184286632-0 1648184498673-1 1) 1) \u0026#34;1648184286632-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello world\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2020\u0026#34; 2) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; XREVRANGE XREVRANGE 与 XRANGE 用途相近，但该命令会以倒序的方式返回 entry。\n格式：XREVRANGE key end start [COUNT count]\n127.0.0.1:6379\u0026gt; XREVRANGE chat:1:messages 1648184498673-1 1648184286632-0 1) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; 2) 1) \u0026#34;1648184286632-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello world\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2020\u0026#34; 127.0.0.1:6379\u0026gt; XREVRANGE chat:1:messages 1648184498673-1 1648184286632-0 COUNT 1 1) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; XTRIM：裁剪 stream 格式：XTRIM key MAXLEN|MINID [=|~] threshold [LIMIT count]\nMAXLEN：用于保留最近的 entry\nMINID：用于裁剪低于某一 ID 的 entry\n127.0.0.1:6379\u0026gt; XTRIM chat:1:messages MAXLEN 2 (integer) 1 127.0.0.1:6379\u0026gt; XRANGE chat:1:messages - + 1) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; 2) 1) \u0026#34;1648184539697-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello TypeScript\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2022\u0026#34; # 此时最早加入的 entry 已经被裁剪，stream 中保留两条 entry 127.0.0.1:6379\u0026gt; XTRIM chat:1:messages MINID 1648184498674 (integer) 1 # ID 低于 1648184498674 的 entry 会被删除 XDEL：删除 stream 中 entry 格式：XDEL key ID [ID ...]\n127.0.0.1:6379\u0026gt; XRANGE chat:1:messages - + 1) 1) \u0026#34;1648184539697-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello TypeScript\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2022\u0026#34; 127.0.0.1:6379\u0026gt; XDEL chat:1:messages 1648184539697-0 (integer) 1 XLEN：返回 stream 中 entry 的数目 格式：XLEN key\n127.0.0.1:6379\u0026gt; XLEN chat:1:messages (integer) 0 127.0.0.1:6379\u0026gt; DEL chat:1:messages (integer) 1 XREAD：从一个或多个 stream 中读取数据 格式：XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] id [id ...]\nXREAD 可以以阻塞或非阻塞的方式读取 stream 的数据（指定 BLOCK）。在获取 stream 记录时，需要指定记录的 ID。\n127.0.0.1:6379\u0026gt; XRANGE api-request-log - + 1) 1) \u0026#34;1650702336219-0\u0026#34; 2) 1) \u0026#34;remote_addr\u0026#34; 2) \u0026#34;[::1]:54058\u0026#34; 3) \u0026#34;url\u0026#34; 4) \u0026#34;/api/users\u0026#34; 5) \u0026#34;access_time\u0026#34; 6) \u0026#34;1650702336\u0026#34; 7) \u0026#34;time_executed\u0026#34; 8) \u0026#34;0\u0026#34; 9) \u0026#34;body_bytes_sent\u0026#34; 10) \u0026#34;96\u0026#34; 2) 1) \u0026#34;1650702505299-0\u0026#34; 2) 1) \u0026#34;remote_addr\u0026#34; 2) \u0026#34;[::1]:54112\u0026#34; 3) \u0026#34;url\u0026#34; 4) \u0026#34;/api/users\u0026#34; 5) \u0026#34;access_time\u0026#34; 6) \u0026#34;1650702505\u0026#34; 7) \u0026#34;time_executed\u0026#34; 8) \u0026#34;0\u0026#34; 9) \u0026#34;body_bytes_sent\u0026#34; 10) \u0026#34;96\u0026#34; 127.0.0.1:6379\u0026gt; XREAD COUNT 1 BLOCK 1000 STREAMS api-request-log 1650702336219-0 1) 1) \u0026#34;api-request-log\u0026#34; 2) 1) 1) \u0026#34;1650702505299-0\u0026#34; 2) 1) \u0026#34;remote_addr\u0026#34; 2) \u0026#34;[::1]:54112\u0026#34; 3) \u0026#34;url\u0026#34; 4) \u0026#34;/api/users\u0026#34; 5) \u0026#34;access_time\u0026#34; 6) \u0026#34;1650702505\u0026#34; 7) \u0026#34;time_executed\u0026#34; 8) \u0026#34;0\u0026#34; 9) \u0026#34;body_bytes_sent\u0026#34; 10) \u0026#34;96\u0026#34; ","date":"2022-03-27","img":"/images/redis-stream.png","permalink":"/doc-redis-commands/stream-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"流相关"},{"categories":["数据库"],"content":"Redis 服务器中与有序集合相关的命令。\nZADD：添加元素 ZADD 用于将一个或多个带分数的元素添加到有序集合中，返回成功添加到有序集合的元素个数。\n当添加元素已在有序集合中时，更新元素的分数使其在有序集合中保持正确的位置。\n格式：ZADD key score member [score member ...]\n127.0.0.1:6379\u0026gt; ZADD student:weights 63.2 xiaoming 67.5 xiaolei (integer) 2 127.0.0.1:6379\u0026gt; ZADD student:weights 64.2 xiaoming (integer) 0 ZSCORE：获取元素的分数 格式：ZSCORE key member\n127.0.0.1:6379\u0026gt; ZSCORE student:weights xiaoming \u0026#34;64.200000000000003\u0026#34; 127.0.0.1:6379\u0026gt; ZSCORE student:weights xiaolei \u0026#34;67.5\u0026#34; ZRANGE：获取指定位置区间上的元素 ZRANGE 可以获取指定位置区间上的元素，包括区间的两端。\n格式：ZRANGE key min max\n127.0.0.1:6379\u0026gt; ZADD student:weights 81.5 xiaopang (integer) 1 127.0.0.1:6379\u0026gt; ZRANGE student:weights 1 2 1) \u0026#34;xiaolei\u0026#34; 2) \u0026#34;xiaopang\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGE student:weights 2 2 1) \u0026#34;xiaopang\u0026#34; ZRANGEBYSCORE：获取指定分数区间上的元素 ZRANGEBYSCORE 可指定分数区间获取元素。\n+inf 表示正无穷，-inf 表示负无穷。\n格式：ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]\n127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights 65 85 WITHSCORES 1) \u0026#34;xiaolei\u0026#34; 2) \u0026#34;67.5\u0026#34; 3) \u0026#34;xiaopang\u0026#34; 4) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights 65 85 WITHSCORES LIMIT 1 1 1) \u0026#34;xiaopang\u0026#34; 2) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights 65 85 WITHSCORES LIMIT 1 2 1) \u0026#34;xiaopang\u0026#34; 2) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights 65 85 WITHSCORES LIMIT 0 2 1) \u0026#34;xiaolei\u0026#34; 2) \u0026#34;67.5\u0026#34; 3) \u0026#34;xiaopang\u0026#34; 4) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaoming\u0026#34; 2) \u0026#34;64.200000000000003\u0026#34; 3) \u0026#34;xiaolei\u0026#34; 4) \u0026#34;67.5\u0026#34; 5) \u0026#34;xiaopang\u0026#34; 6) \u0026#34;81.5\u0026#34; ZINCRBY：增加某个元素的分数 ZINCRBY 的返回值为修改后的分数。\n格式：ZINCRBY key increment member\n127.0.0.1:6379\u0026gt; ZINCRBY student:weights 0.5 xiaoming \u0026#34;64.700000000000003\u0026#34; 127.0.0.1:6379\u0026gt; ZINCRBY student:weights -0.5 xiaoming \u0026#34;64.200000000000003\u0026#34; ZCARD：获取集合中元素的个数 格式：ZCARD key\n127.0.0.1:6379\u0026gt; ZCARD student:weights (integer) 3 ZCOUNT：获取指定分数范围内的元素个数 格式：ZCOUNT key min max\n127.0.0.1:6379\u0026gt; ZCOUNT student:weights 65 85 (integer) 2 ZREM：删除一个或多个元素 ZREM 返回删除成功的元素个数。\n格式：ZREM key member [member ...]\n127.0.0.1:6379\u0026gt; ZREM student:weights xiaoming xiaolei (integer) 2 127.0.0.1:6379\u0026gt; ZREM student:weights notaname (integer) 0 ZREMRANGEBYRANK：通过指定位置区间删除集合元素 格式：ZREMRANGEBYRANK key start stop\n127.0.0.1:6379\u0026gt; ZADD student:weights 63.2 xiaoming 67.5 xiaolei (integer) 2 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaoming\u0026#34; 2) \u0026#34;63.200000000000003\u0026#34; 3) \u0026#34;xiaolei\u0026#34; 4) \u0026#34;67.5\u0026#34; 5) \u0026#34;xiaopang\u0026#34; 6) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZREMRANGEBYRANK student:weights 0 1 (integer) 2 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaopang\u0026#34; 2) \u0026#34;81.5\u0026#34; ZREMRANGEBYSCORE：通过指定分数区间删除集合元素 格式：ZREMRANGEBYSCORE key min max\n127.0.0.1:6379\u0026gt; ZADD student:weights 63.2 xiaoming 67.5 xiaolei 81.5 xiaopang (integer) 3 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaoming\u0026#34; 2) \u0026#34;63.200000000000003\u0026#34; 3) \u0026#34;xiaolei\u0026#34; 4) \u0026#34;67.5\u0026#34; 5) \u0026#34;xiaopang\u0026#34; 6) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZREMRANGEBYSCORE student:weights 80 85 (integer) 1 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaoming\u0026#34; 2) \u0026#34;63.200000000000003\u0026#34; 3) \u0026#34;xiaolei\u0026#34; 4) \u0026#34;67.5\u0026#34; ZRANK：获取元素的排序 格式：ZRANK key member\n127.0.0.1:6379\u0026gt; ZRANK student:weights xiaolei (integer) 1 127.0.0.1:6379\u0026gt; ZRANK student:weights notaname (nil) ZREVRANK：降序获取元素的排序 格式：ZREVRANK key member\n127.0.0.1:6379\u0026gt; ZREVRANK student:weights xiaolei (integer) 0 ","date":"2022-03-27","img":"/images/redis-zset.png","permalink":"/doc-redis-commands/zset-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"有序集合相关"},{"categories":["数据库"],"content":"Redis 服务器中与列表值相关的命令。\nLPUSH：向列表左端添加元素 LPUSH 返回添加元素后列表的长度。\n格式：LPUSH key element [element ...]\n127.0.0.1:6379\u0026gt; LPUSH colors green yellow red blue gray (integer) 5 # 此时列表为 [gray blue yellow red green] LPUSHX：向列表左端添加元素 LPUSHX 与 LPUSH 类似，但只有在 key 存在的情况，操作才有效。\n格式：LPUSHX key element [element ...]\n127.0.0.1:6379\u0026gt; KEYS colors (empty array) 127.0.0.1:6379\u0026gt; LPUSHX colors red green blue (integer) 0 RPUSH：向列表右端添加元素 RPUSH 返回添加元素后列表的长度。\n格式：RPUSH key element [element ...]\n127.0.0.1:6379\u0026gt; RPUSH colors lightgreen lightyellow lightred lightblue (integer) 9 # 此时列表为 [gray blue yellow red green # lightgreen lightyellow lightred lightblue] RPUSHX：向列表右端添加元素 RPUSHX 与 RPUSH 类似，但只能存在的键有效。\n格式：RPUSHX key element [element ...]\n127.0.0.1:6379\u0026gt; KEYS colors (empty array) 127.0.0.1:6379\u0026gt; RPUSHX colors red green blue (integer) 0 127.0.0.1:6379\u0026gt; KEYS colors (empty array) LPOP：从列表左端弹出元素 LPOP 返回弹出的元素。\n格式：LPOP key [count]\n127.0.0.1:6379\u0026gt; LPOP colors 2 1) \u0026#34;gray\u0026#34; 2) \u0026#34;blue\u0026#34; # 此时列表为 [yellow red green # lightgreen lightyellow lightred lightblue] RPOP：从列表右端弹出元素 RPOP 返回弹出的元素。\n格式：RPOP key [count]\n127.0.0.1:6379\u0026gt; RPOP colors 2 1) \u0026#34;lightblue\u0026#34; 2) \u0026#34;lightred\u0026#34; # 此时列表为 [yellow red green # lightgreen lightyellow] LLEN：获取列表中元素的个数 格式：LLEN key\n127.0.0.1:6379\u0026gt; LLEN colors (integer) 5 LRANGE：获取列表指定区间上的元素 LRANGE 指定的区间包括两端。\n格式：LRANGE key start stop\n127.0.0.1:6379\u0026gt; LRANGE colors 2 -1 1) \u0026#34;green\u0026#34; 2) \u0026#34;lightgreen\u0026#34; 3) \u0026#34;lightyellow\u0026#34; LREM：删除列表中前 count 个指定的元素 格式：LREM key count element\n127.0.0.1:6379\u0026gt; LPUSH colors yellow yellow yellow (integer) 8 # 此时列表为 [yellow yellow yellow yellow red green # lightgreen lightyellow] 127.0.0.1:6379\u0026gt; LREM colors 3 yellow (integer) 3 # 此时列表为 [yellow red green # lightgreen lightyellow] LINDEX：获取指定位置上的元素 格式：LINDEX key index\n127.0.0.1:6379\u0026gt; LINDEX colors 2 \u0026#34;green\u0026#34; LSET：设置列表中指定位置上元素的值 格式：LSET key index element\n127.0.0.1:6379\u0026gt; LSET colors 0 blue OK # 此时列表为 [blue red green # lightgreen lightyellow] LTRIM：对列表进行裁剪 LTRIM 裁剪列表并保存到原有列表中。\n格式：LTRIM key start stop\n127.0.0.1:6379\u0026gt; LTRIM colors 0 2 OK # 列表只保留了前 3 个元素 127.0.0.1:6379\u0026gt; LRANGE colors 0 9 1) \u0026#34;blue\u0026#34; 2) \u0026#34;yellow\u0026#34; 3) \u0026#34;green\u0026#34; LINSERT：向列表插入元素 LINSERT 用于在列表元素前或后插入指定元素。\n格式：LINSERT key BEFORE|AFTER pivot element\n127.0.0.1:6379\u0026gt; LINSERT colors BEFORE blue red (integer) 4 127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;blue\u0026#34; 3) \u0026#34;yellow\u0026#34; 4) \u0026#34;green\u0026#34; RPOPLPUSH：操作两个列表，对元素进行弹出再推入 RPOPLPUSH 返回值为第 1 个列表弹出的元素。\n格式：RPOPLPUSH source destination\n127.0.0.1:6379\u0026gt; RPOPLPUSH colors other:colors \u0026#34;green\u0026#34; 127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;blue\u0026#34; 3) \u0026#34;yellow\u0026#34; 127.0.0.1:6379\u0026gt; LRANGE other:colors 0 -1 1) \u0026#34;green\u0026#34; BLPOP：阻塞式从列表左端弹出元素 BLPOP 同样用于从列表左端弹出元素，但是当列表为空，该命令会阻塞列表直到超时或列表有元素可弹出，超时时间单位为秒。\n格式：BLPOP key [key ...] timeout\n127.0.0.1:6379\u0026gt; BLPOP mock:list 2 (nil) (2.06s) BRPOP：阻塞式从列表右端弹出元素 BRPOP 同样用于从列表右端弹出元素，但是当列表为空，该命令会阻塞列表直到超时或列表有元素可弹出，超时时间单位为秒。\n格式：BRPOP key [key ...] timeout\n127.0.0.1:6379\u0026gt; BRPOP mock:list 2` (nil) (2.05s) RPUSHX：向已存在的列表右端添加元素 RPUSHX 用于将一个或多个元素添加到已存在列表，若列表不存在，则操作无效。\n格式：RPUSHX key element [element ...]\n127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;blue\u0026#34; 3) \u0026#34;yellow\u0026#34; 127.0.0.1:6379\u0026gt; RPUSHX colors green (integer) 4 127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;blue\u0026#34; 3) \u0026#34;yellow\u0026#34; 4) \u0026#34;green\u0026#34; 127.0.0.1:6379\u0026gt; RPUSHX not:exists:colors green (integer) 0 BRPOPLPUSH：操作两个列表，对元素进行弹出再推入 BRPOPLPUSH 与 RPOPLPUSH 类似，但如果列表中没有元素会阻塞直到等待超时或有元素弹出，超时时间的单位为秒。\n格式：BRPOPLPUSH source destination timeout\n127.0.0.1:6379\u0026gt; RPUSH colors red green yellow (integer) 3 127.0.0.1:6379\u0026gt; BRPOPLPUSH colors dest:colors 10 \u0026#34;yellow\u0026#34; 127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;green\u0026#34; 127.0.0.1:6379\u0026gt; LRANGE dest:colors 0 -1 1) \u0026#34;yellow\u0026#34; ","date":"2022-03-27","img":"/images/redis-list.png","permalink":"/doc-redis-commands/list-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"列表值相关"},{"categories":null,"content":"","date":"0001-01-01","img":"","permalink":"/offline/","series":null,"tags":null,"title":"Offline"}]