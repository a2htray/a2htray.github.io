[{"categories":["Python"],"content":"一般情况下，你们会通过文件（CSV、Excel等） 或 Python 的内置结构（字典）来创建 DataFrame 对象。但有时，数据是字符串的形式，如何将其转换成 DataFrame 对象？\n答案：将字符串强制转换成 io.StringIO，再作为 pd.read_csv 的参数。\nimport pandas as pd from io import StringIO data = \u0026#39;\u0026#39;\u0026#39;人口基本情况,1982年,1990年,2000年,2020年,2021年 0-14岁人口,34156,31670,29024,25277,24721 15-64岁人口,62517,76260,88847,96871,96481 65岁以上人口,4981,6403,8872,19064,20059\u0026#39;\u0026#39;\u0026#39; df = pd.read_csv(StringIO(data), index_col=0) ","date":"2022-11-17","img":"","permalink":"/posts/python-pandas-create-dataframe-from-raw-string/","series":null,"tags":["Pandas"],"title":"从字符串中创建 DataFrame"},{"categories":["Python"],"content":"Series 和 DataFrame 是 Pandas 中两种重要的数据结构，也是我们操作和分析的主要对象。其中 Series 是一种类似于数组、列表或表格中一列的 一维数据对象，DataFrame 则可以表示表格化的数据对象，可由多个 Series 对象组成。\n本文主要摘录 Series 和 DataFrame 两种数据结结构的创建方法以及一些注意事项。\nSeries 的创建 Pandas 提供 Series 来表示一系列的元素，与常规一维数组只能以整数作为索引不同，Series 的索引值可以是任务值，其索引值与值的映射结构类似于 Python 中 的字典。\nSeries 的构造函数 Series 的构造函数的声明如下：\ndef __init__( self, data=None, index=None, dtype: Dtype | None = None, name=None, copy: bool = False, fastpath: bool = False, ): pass 从列表中创建 Series names = [\u0026#39;Jimmy\u0026#39;, \u0026#39;Andy\u0026#39;, \u0026#39;Tony\u0026#39;, \u0026#39;John\u0026#39;] names_series = pd.Series(names) pd.Series 的第 1 个参数名为 data，即上述调用过程等价于 names_series = pd.Series(data=names)。因为列表中没有相应的值可以作为 Series 的 index 值，所以 Pandas 会以 0 起始为每 1 个元素进行索引。如果指定了 index 参数值，可以修改 Series 中的索引值。\nnames_series = pd.Series(names, index=[\u0026#39;ST0001\u0026#39;, \u0026#39;ST0002\u0026#39;, \u0026#39;ST0003\u0026#39;, \u0026#39;ST0004\u0026#39;]) 此时可以通过 names_series['ST0002'] 访问 'Andy' 元素。\n从字典中创建 Series sales = { \u0026#39;January\u0026#39;: 1000, \u0026#39;February\u0026#39;: 900, \u0026#39;March\u0026#39;: 1200, } sales_series = pd.Series(sales) Python 中的字典是 key-value 结构，所以字典值作为 data 参数值时，其 key 值会作为 Series 的 index 值。此时可以通过 sales['January'] 访问 到 1000 元素。\n从 np.ndarray 中创建 Series 从 np.ndarray 中创建 Series 与从列表中创建 Series 类似：\nx_axis_values = np.arange(0, 7) axis_series = pd.Series(x_axis_values, index=[\u0026#39;Monday\u0026#39;, \u0026#39;Tuesday\u0026#39;, \u0026#39;Wednesday\u0026#39;, \u0026#39;Thursday\u0026#39;, \u0026#39;Friday\u0026#39;, \u0026#39;Saturday\u0026#39;, \u0026#39;Sunday\u0026#39;]) 从标量中创建 Series scaled_series = pd.Series(7, index=[\u0026#39;01\u0026#39;, \u0026#39;02\u0026#39;, \u0026#39;03\u0026#39;]) 此时 scaled_series 中一共有 3 个元素，各元素的 index 分别为 \u0026lsquo;01\u0026rsquo;、\u0026lsquo;02\u0026rsquo; 和 \u0026lsquo;03\u0026rsquo;。标量作为 data 参数值时，Pandas 会按 index 参数 值的长度进行扩展。如果没有指定 index 值时，索引值则为 0 且长度为 1。\nDataFrame 的创建 Pandas 提供 DataFrame 结构可用于表示表格化的数据。\nDataFrame 的构造函数 def __init__( self, data=None, index: Axes | None = None, columns: Axes | None = None, dtype: Dtype | None = None, copy: bool | None = None, ): pass 相较于 Series 的构造函数，DataFrame 的构造函数可以指定列名（columns）。因为 DataFrame 可以视为一个或多个 Series 的集合，同样的， columns 值可以视为每一个 Series 的 name 参数的传值。\n从字典（列表为元素）中创建 DataFrame scores = { \u0026#39;Jimmy\u0026#39;: [89, 88, 93], \u0026#39;Andy\u0026#39;: [78, 90, 99], \u0026#39;Tony\u0026#39;: [83, 85, 87], \u0026#39;John\u0026#39;: [87, 67, 70], } df = pd.DataFrame(data=scores) scores 的 key 值会作为 DataFrame 的列名。\n指定 index、columns 值 index 参数用于设置 DataFrame 每行的索引值，columns 参数用于设置列名。\ndf = pd.DataFrame([ [89, 88, 93], [78, 90, 99], [83, 85, 87], [87, 67, 70], ], index=[\u0026#39;Jimmy\u0026#39;, \u0026#39;Andy\u0026#39;, \u0026#39;Tony\u0026#39;, \u0026#39;John\u0026#39;], columns=[\u0026#39;Math\u0026#39;, \u0026#39;English\u0026#39;, \u0026#39;Chinese\u0026#39;]) 上述中，df 是一个 4 行 3 列的表格化对象。如果 data 参数值是一个字典，则 columns 参数还可以起到过滤的作用。\n","date":"2022-10-15","img":"","permalink":"/posts/python-pandas-series-dataframe/","series":null,"tags":["Pandas","Series","DataFrame"],"title":"创建 Pandas 的 Series 和 DataFrame "},{"categories":["Go","Web"],"content":"Four days ago, I got a requirement to build an academic website for yunzila~. This reminds me of my previous blog experience. Since my blog is built with Hugo, I started to find an academic theme which is designed for Hugo. Here is a link to Hugo themes, and then I find the Academic theme developed by gcushen which meets my needs.\nAfter reading the documents, I try to use the latest version of Wowchemy Academic theme but bad things always come. Yes, I get into trouble when I configure the Wowchemy 5.7. the Wowchemy 5+ is too difficult for newbies. So I make a decision to use Wowchemy 4.6.3. This post records my process of configuring an academic website with Hugo and Wowchemy 4.6.3.\nInstall Hugo Extended Why use Hugo extended? Because the theme has used Sass or SCSS to stylize. You can get a specific version of the source code from the GitHub by following command:\n$ git clone -b v0.104.1 git@github.com:gohugoio/hugo.git $ cd hugo $ CGO_ENABLED=1 go install --tags extended It is noted that the latest hugo is developed with Go 1.18, make sure that the Go 1.18+ is installed in your system. During the execution of CGO_ENABLED=1 go install --tags extended, you may encounter some problems such as package is missing. Here are some details of issues I experienced.\ngo: github.com/alecthomas/chroma/v2@v2.3.0 requires github.com/alecthomas/repr@v0.1.0: missing go.sum entry; to add it: go mod download github.com/alecthomas/repr ./../go/pkg/mod/github.com/cpuguy83/go-md2man/v2@v2.0.2/md2man/md2man.go:4:2: missing go.sum entry needed to verify package github.com/russross/blackfriday/v2 (imported by github.com/cpuguy83/go-md2man/v2/md2man) is provided by exactly one module; to add: go get github.com/cpuguy83/go-md2man/v2/md2man@v2.0.2 For above issues, we need to run commands as follows:\n$ go mod download github.com/alecthomas/repr@v0.1.0 $ go get github.com/cpuguy83/go-md2man/v2/md2man@v2.0.2 Now, we need to run CGO_ENABLED=1 go install --tags extended again to build a binary executable file which will be stored to $GOPATH/bin/.\nTo test whether the hugo is installed:\n$ hugo version hugo v0.104.1-8958b8741f552c8024af5194330fbf031544a826+extended darwin/amd64 BuildDate=2022-09-26T17:05:45Z Install Wowchemy Academic Theme At present, the theme is kept in this repository. For the 4.6.3 version, I suggest you to download the source code from the release page v4.6.3.\nIf your website directory name is academic-site, you can execute the following commands to install the theme.\n$ cd academic-site $ mkdir themes/academic # decompress the zip into the folder `themes/academic` $cp -rf themes/academic/exampleSite/* ./ At last, you should to modify the theme code in themes/academic/layouts/publication/single.html at line 14.\n{{ if (.Params.publication_types) and (ne (index .Params.publication_types 0) \u0026#34;0\u0026#34;) }} changed to\n{{ if and (.Params.publication_types) (ne (index .Params.publication_types 0) \u0026#34;0\u0026#34;) }} You can run hugo server to get a glance the website.\nWrite at Last I will try to learn the structure of the theme code, and get the ability to do some modifications to make the theme more customizable.\n","date":"2022-09-28","img":"","permalink":"/posts/go-hugo-wowchemy-academic-website/","series":null,"tags":["Academic Website","Hugo","Wowchemy"],"title":"Two Steps to Build an Academic Website With Hugo and Wowchemy"},{"categories":["Python"],"content":"In normal work, I usually use Pandas as my excel read/write utility.\nHere is an example for how to write multiple dataframes to worksheets. We need to use pd.ExcelWriter method.\nimport pandas as pd writer = pd.ExcelWriter(\u0026#39;./multiple-dataframes-in-a-single-xls.xls\u0026#39;) df1 = pd.DataFrame(columns=[ \u0026#39;Book\u0026#39;, \u0026#39;Author\u0026#39;, ], data=[ (\u0026#39;Pride and Prejudice\u0026#39;, \u0026#39;Jane Austen\u0026#39;), (\u0026#39;Healing Her Heart\u0026#39;, \u0026#39;Laura Scott\u0026#39;), ]) df2 = pd.DataFrame(columns=[ \u0026#39;Website\u0026#39;, \u0026#39;Scale\u0026#39;, ], data=[ (\u0026#39;Alibaba\u0026#39;, \u0026#39;Larger\u0026#39;), (\u0026#39;Google\u0026#39;, \u0026#39;Larger\u0026#39;), ]) df1.to_excel(writer, sheet_name=\u0026#39;Book\u0026#39;, index=False) df2.to_excel(writer, sheet_name=\u0026#39;Website\u0026#39;, index=False) writer.save() If you get into trouble that the script raises an Error ModuleNotFoundError: No module named 'xlwt', you need to run pip install xlwt to install the xlwt package. It is important to note that the xlwt package is no longer maintained, and the xlwt engine will been removed in a furture version of pandas.\nAt last, don\u0026rsquo;t forget to use writer.save method to flush the buffers into the output file.\n","date":"2022-09-21","img":"","permalink":"/posts/python-pandas-write-mumultiple-dataframes-to-worksheets/","series":null,"tags":["Pandas","xls"],"title":"Write Mumultiple Dataframes to Worksheets"},{"categories":["Go"],"content":"原文：Slices/arrays explained: create, index, slice, iterate\n概述 slice 是 Go 中的一种数据结构，描述了底层实现 array 的部分信息，并不会真实地存储任何数据。\n修改 slice 中的元素，实际上就是修改底层实现 array 中的元素，引用相同 array 的 slice 也会相应被修改； func changeSliceElement() { s := []int{1, 2, 3} s1 := s s2 := s s[0] = 0 fmt.Println(s1) fmt.Println(s2) } [0 2 3] [0 2 3] slice 会进行扩容和缩容； func growSlice() { s := []int{0, 1, 2, 3} fmt.Printf(\u0026#34;slice 的长度为 %d，容量为 %d\\n\u0026#34;, len(s), cap(s)) for i := 5; i \u0026lt; 10; i++ { s = append(s, i) fmt.Printf(\u0026#34;append %d 次，slice 的长度为 %d，容量为 %d\\n\u0026#34;, i-4, len(s), cap(s)) } } slice 的长度为 4，容量为 4 append 1 次，slice 的长度为 5，容量为 8 append 2 次，slice 的长度为 6，容量为 8 append 3 次，slice 的长度为 7，容量为 8 append 4 次，slice 的长度为 8，容量为 8 append 5 次，slice 的长度为 9，容量为 16 在第 5 次 append 后，slice 进行了扩容（以 2 为倍数）。\n不同于 C 中的 realloc 方法，Go 中的 slice 没有直接的缩容方法，参考【1】中的给出了间接的方法示例。\nfunc shrinkSlice() { s := []int{0, 1, 2, 3} fmt.Printf(\u0026#34;slice 的长度为 %d，容量为 %d\\n\u0026#34;, len(s), cap(s)) s1 := append([]int{}, s[:2]...) fmt.Printf(\u0026#34;slice 的长度为 %d，容量为 %d\\n\u0026#34;, len(s1), cap(s1)) } slice 的长度为 4，容量为 4 slice 的长度为 2，容量为 2 slice 的元素访问； 定义 var s []int // a nil slice s1 := []string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;} s2 := make([]int, 2) // same as []int{0, 0} s3 := make([]int, 2, 4) // same as new([4]int)[:2] fmt.Println(len(s3), cap(s3)) // 2 4 slice 的零值为 nil，内置方法 len、cap 和 append 都会把 nil 视为一个容量为 0 的 slice； func nilSlice() { var s []int if s == nil { fmt.Printf(\u0026#34;var s []int 声明了一个 []int 的零值 nil\\n\u0026#34;) } fmt.Printf(\u0026#34;len(s) = %d, cap(s) = %d\\n\u0026#34;, len(s), cap(s)) } var s []int 声明了一个 []int 的零值 nil len(s) = 0, cap(s) = 0 内置方法 len 和 cap 分别可以得到 slice 的长度和容量； 切片 a := [...]int{0, 1, 2, 3} // an array s := a[1:3] // s == []int{1, 2} cap(s) == 3 s = a[:2] // s == []int{0, 1} cap(s) == 4 s = a[2:] // s == []int{2, 3} cap(s) == 2 s = a[:] // s == []int{0, 1, 2, 3} cap(s) == 4 支持从一个 slice 创建出新的 slice：\n通过指定索引值区间 s[low:high] 创建一个 slice； func Index() { s := []int{1, 2, 3, 4, 5} fmt.Printf(\u0026#34;s 的长度为 %d，容量为 %d\\n\u0026#34;, len(s), cap(s)) s1 := s[:2] fmt.Printf(\u0026#34;s1 = s[:2] 的长度为 %d，容量为 %d\\n\u0026#34;, len(s1), cap(s1)) // 打印出 s 和 s1 的地址 fmt.Printf(\u0026#34;s 的地址 %p，s1 的地址 %p\\n\u0026#34;, \u0026amp;s, \u0026amp;s1) // s 和 s1 的第 1 个元素是否在同一个地址上？ if \u0026amp;s == \u0026amp;s1 { fmt.Println(\u0026#34;s 和 s1 的第 1 个元素在同一个地址上\u0026#34;) } else { fmt.Println(\u0026#34;s 和 s1 的第 1 个元素不在同一个地址上\u0026#34;) } // low 和 high 的取值范围 // 创建 1 个长度为 4，容量为 8 的 slice s2 := make([]int, 4, 8) s2[0] = 1 s2[1] = 2 s2[2] = 3 s2[3] = 4 fmt.Printf(\u0026#34;s2 的长度为 %d，容量为 %d\\n\u0026#34;, len(s2), cap(s2)) s3 := s2[0:] fmt.Printf(\u0026#34;s3 的长度为 %d，容量为 %d\\n\u0026#34;, len(s3), cap(s3)) s4 := s2[0:4] fmt.Printf(\u0026#34;s4 的长度为 %d，容量为 %d\\n\u0026#34;, len(s4), cap(s4)) s5 := s2[0:5] fmt.Printf(\u0026#34;s5 的长度为 %d，容量为 %d\\n\u0026#34;, len(s5), cap(s5)) s6 := s2[0:8] fmt.Printf(\u0026#34;s6 的长度为 %d，容量为 %d\\n\u0026#34;, len(s6), cap(s6)) fmt.Printf(\u0026#34;第 8 个元素为 %d\\n\u0026#34;, s6[7]) } s 的长度为 5，容量为 5 s1 = s[:2] 的长度为 2，容量为 5 s 的地址 0xc0000b4090，s1 的地址 0xc0000b40a8 s 和 s1 的第 1 个元素不在同一个地址上 s2 的长度为 4，容量为 8 s3 的长度为 4，容量为 8 s4 的长度为 4，容量为 8 s5 的长度为 5，容量为 8 s6 的长度为 8，容量为 8 第 8 个元素为 0 从上述示例中，可以得出：\n通过 s[low:high] 创建的 slice 的内存地址与 s 的内存地址不同； high 的最大值为 slice 的容量，若容量大于长度时l，high 的值可能会大于长度，此时通过切片会得到一个以元素零值填充的 slice； slice 中的元素为引用类型时，通过切片得到的新的 slice 中的元素保持相同的引用； func IndexRefObjs() { s := make([]*strings.Reader, 4, 8) for i, char := range []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;} { s[i] = strings.NewReader(char) } s1 := s[0:4] if s[0] == s1[0] { fmt.Println(\u0026#34;s 的第 1 个元素和 s1 的第 1 个元素为相同引用\u0026#34;) } } s 的第 1 个元素和 s1 的第 1 个元素为相同引用 迭代 s := []string{\u0026#34;Foo\u0026#34;, \u0026#34;Bar\u0026#34;} for i, v := range s { fmt.Println(i, v) } 0 Foo 1 Bar range 表达式用于迭代 slice； 两个迭代值 i 和 v 分别为索引值和元素值； 第 2 个迭代值是可选的； 如果 slice 为 nil，则其可迭代值为 0； func IterNilSlice() { var s []int if s == nil { fmt.Println(\u0026#34;s 值为 nil\u0026#34;) } for i, v := range s { fmt.Println(i, v) } } s 值为 nil 上述示例可知，若一个 slice 为 nil 时，仍然可以作为 range 表达式的操作值。\n添加和复制 append 函数可以将一个元素添加到 slice 的尾部，如果超过了 slice 的容量会进行自动扩容； copy 函数可以将源 slice 中的元素复制到目标 slice 中，可复制的元素个数为源 slice 和目标 slice 长度中较小值； 参考 Does Go have no real way to shrink a slice? Is that an issue? ","date":"2022-09-19","img":"","permalink":"/posts/go-slice-usage/","series":null,"tags":["slice","翻译"],"title":"Go Slice 的使用"},{"categories":["Go"],"content":"Roadmap for Go Slice.\n","date":"2022-09-19","img":"","permalink":"/posts/go-slice-basic/","series":null,"tags":["slice"],"title":"Go Slice Roadmap"},{"categories":["Python"],"content":"django.forms 包提供了 HTML 表单验证的功能，在没有使用 DRF 的情况下，无法合理地处理 API 传参的验证，其中传参验证中就缺少了参数默认值的设置。\n层次结构 django.forms 包提供的 Field 类如下：\n__all__ = ( \u0026#39;Field\u0026#39;, \u0026#39;CharField\u0026#39;, \u0026#39;IntegerField\u0026#39;, \u0026#39;DateField\u0026#39;, \u0026#39;TimeField\u0026#39;, \u0026#39;DateTimeField\u0026#39;, \u0026#39;DurationField\u0026#39;, \u0026#39;RegexField\u0026#39;, \u0026#39;EmailField\u0026#39;, \u0026#39;FileField\u0026#39;, \u0026#39;ImageField\u0026#39;, \u0026#39;URLField\u0026#39;, \u0026#39;BooleanField\u0026#39;, \u0026#39;NullBooleanField\u0026#39;, \u0026#39;ChoiceField\u0026#39;, \u0026#39;MultipleChoiceField\u0026#39;, \u0026#39;ComboField\u0026#39;, \u0026#39;MultiValueField\u0026#39;, \u0026#39;FloatField\u0026#39;, \u0026#39;DecimalField\u0026#39;, \u0026#39;SplitDateTimeField\u0026#39;, \u0026#39;GenericIPAddressField\u0026#39;, \u0026#39;FilePathField\u0026#39;, \u0026#39;JSONField\u0026#39;, \u0026#39;SlugField\u0026#39;, \u0026#39;TypedChoiceField\u0026#39;, \u0026#39;TypedMultipleChoiceField\u0026#39;, \u0026#39;UUIDField\u0026#39;, ) 继承关系如下图：\nField: 字段基类 - InlineForeignKeyField: 关联模型的主键字段 - CharField: 字符串字段 - RegexField: 正则字符串字段 - UrlField: URL 字段 - SlugField: 是否允许 unicode 字符串 - GenericIPAdressField: IP 字段 - EmailField: 邮箱字段 - UUIDField: UUID 字段 - JSONField: JSON 字符串 - IntegerField: 整数字段 - FloatField: 浮点数字段 - DecimalField: 十进制小数字段 - BaseTemporalField: 表示时间 - DatelField: 日期字段 - TimeField: 时间字段 - DateTimeField: （日期、时间）字段 - DurationField: 时间段字段 - FileField: 文件字段 - ImageField: 图片字段 - BooleanField: 布尔字段 - NullBooleanField: 布尔字段（可为 null） - ChoiceField: 可选项字段 - ModelChoiceField: 模型选项字段（QuerySet） - ModelMultipleChoiceField: 模型选项字段（QuerySet，可多个） - TypedChoiceField: 可选项字段（强制类型） - MultipleChoiceField: 可选项字段（多选） - TypedMultipleChoiceField: 可选项字段（多选，强制类型） - FilePathField: 文件路径字段 - ComboField: 组合字段，同时使用多个字段验证器 - MultiValueField: 聚合多个字段的逻辑 - SplitDateTimeField: 多个时间值字段 基类 Field 的构造函数的声明如下：\ndef __init__(self, *, required=True, widget=None, label=None, initial=None, help_text=\u0026#39;\u0026#39;, error_messages=None, show_hidden_initial=False, validators=(), localize=False, disabled=False, label_suffix=None): initial 参数 其中有一个 initial 参数，可以用来表示 Form 渲染出的 HTML 代码中的显示值，但并不会给字段赋值，如：\nfrom django.http import HttpRequest, JsonResponse from django import forms class ExampleForm(forms.Form): name = forms.CharField(required=False, initial=\u0026#39;a2htray\u0026#39;) def django_forms_field_initial(request: HttpRequest): form = ExampleForm(request.GET) if form.is_valid(): data = form.cleaned_data print(\u0026#39;data\u0026#39;, data) print(form) else: print(form.errors) return JsonResponse({}) return JsonResponse({}) 请求该接口打印的信息如下：\ndata {\u0026#39;name\u0026#39;: \u0026#39;\u0026#39;} \u0026lt;tr\u0026gt;\u0026lt;th\u0026gt;\u0026lt;label for=\u0026#34;id_name\u0026#34;\u0026gt;Name:\u0026lt;/label\u0026gt;\u0026lt;/th\u0026gt;\u0026lt;td\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;name\u0026#34; id=\u0026#34;id_name\u0026#34;\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt; 可见，django 提供的 Field 类没有提供类似于默认值的功能。比如，当用户不能给出默认的 name 值时进行赋值。\n自定义 default 参数 封装一个需要提供默认值功能的字段类，这里以 TypedChoiceField 为例，其中 TypedChoiceField._coerce 方法本身也提供了一定的验证功能，看源码：\nclass TypedChoiceField(ChoiceField): # ... def _coerce(self, value): if value == self.empty_value or value in self.empty_values: return self.empty_value # 需要的修改地方 try: value = self.coerce(value) except (ValueError, TypeError, ValidationError): raise ValidationError( self.error_messages[\u0026#39;invalid_choice\u0026#39;], code=\u0026#39;invalid_choice\u0026#39;, params={\u0026#39;value\u0026#39;: value}, ) return value def clean(self, value): value = super().clean(value) return self._coerce(value) 当传值解析为指定的 empty_value 或在 empty_values 中时，返回指定的默认值，其余不变。\nclass MyTypeChoiceField(forms.TypedChoiceField): def __init__(self, *, default=None, **kwargs): self.default = default super().__init__(**kwargs) def _coerce(self, value): if value == self.empty_value or value in self.empty_values: return self.default else: try: value = self.coerce(value) except (ValueError, TypeError, ValidationError): raise ValidationError( self.error_messages[\u0026#39;invalid_choice\u0026#39;], code=\u0026#39;invalid_choice\u0026#39;, params={\u0026#39;value\u0026#39;: value}, ) return value 那么在使用 MyTypedChoiceField 时可以指定 default 参数，如：\nGENDER_CHOICES = ( (0, \u0026#39;Male\u0026#39;), (1, \u0026#39;Female\u0026#39;), ) class Payload(forms.Form): gender = MyTypeChoiceField(coerce=lambda p: int(p), choices=GENDER_CHOICES, required=False, default=0) def get_payload_validate(request: HttpRequest): payload = Payload(request.GET) if not payload.is_valid(): return JsonResponse({ \u0026#39;errors\u0026#39;: payload.errors, }) payload = payload.cleaned_data return JsonResponse(payload) 不带任何参数值请求该接口时的返回如下：\n{ \u0026#34;gender\u0026#34;: 0 } 不同的 Field 子类也可进行类似的继承再修改。\n","date":"2022-09-05","img":"","permalink":"/posts/python-django-parameter-validation-default/","series":null,"tags":["Django","参数验证"],"title":"扩展 Django Forms.Field - 支持 Default 属性"},{"categories":["Go"],"content":"原文：Error handling and Go\n介绍 如果你写过 Go 的代码，就一定遇到过 Go 的内置类型 error。一个 error 类型的值可用于指明程序的某种不正常的状态，比如，当打开文件失败时，os.Open 函数会返回一个非 nil 的 error 值。\nfunc Open(name string) (file *File, err error) 下面代码演示了：使用 os.Open 打开一个文件失败时，用 log.Fatal 来打印错误信息和停止程序运行。\nf, err := os.Open(\u0026#34;filename.ext\u0026#34;) if err != nil { log.Fatal(err) } // do something with the open *File f 只要知道上述一点关于 error 的内容，在 Go 中就可以做很多事，但在这篇文章中，我们会进一步地讨论 error 类型以及 Go 处理错误的最佳实践。\nerror 类型 error 类型是一种接口类型，error 值可以是任意被字符串所能表示的值，下方是接口的定义：\ntype error interface { Error() string } 与其它内置类型一样，error 类型也是提前定义，并且全局有效的。\n使用的最多的 error 实现是 errors 包中的未导出类型 errorString：\n// errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } 你可以使用 errors.New 函数构建一个 error 值，该函数会把一个字符串转换成一个 errorString，返回值是一个 error 类型。\n// New returns an error that formats as the given text. func New(text string) error { return \u0026amp;errorString{text} } 下面是使用 errors.New 的示例：\nfunc Sqrt(f float64) (float64, error) { if f \u0026lt; 0 { return 0, errors.New(\u0026#34;math: square root of negative number\u0026#34;) } // implementation } 当调用者传入一个负数时，函数会返回一个非 nil 的 error 值（实际类型为 errorString）。同时，调用者可以使用 error 的 Error 方法得到错误字符串，或者直接打印：\nf, err := Sqrt(-1) if err != nil { fmt.Println(err) } fmt 包内部会调用 error 的 Error 方法。\nerror 值有必要对一次代码执行做一次总结，应当尽可能描述错误的细节，如“open /etc/passwd: permission denied”，而不是“permission denied.”。Sqrt 的错误返回需要表明函数传递了一个无效的参数，并且要具体到无效的值。\n为了加个无效参数的信息，fmt 包的 Errorf 方法派上了用场。该方法会按照 Printf 方法的规则格式化字符串并返回一个 error 类型。\nif f \u0026lt; 0 { return 0, fmt.Errorf(\u0026#34;math: square root of negative number %g\u0026#34;, f) } 在大部分场景下，使用 fmt.Errorf 已经足够了，但由于 error 是一个接口类型，所以任意数据结构都可以作为 error 的值（只要实现了 Error 方法）。这样的话，调用者可以尽可能知道错误的具体信息。\n假设，调用者想通过 recover 函数捕获到传入 Sqrt 函数的无效参数，那可以自定义一种错误类型，而不是使用默认的 errors.errorString。\ntype NegativeSqrtError float64 func (f NegativeSqrtError) Error() string { return fmt.Sprintf(\u0026#34;math: square root of negative number %g\u0026#34;, float64(f)) } 在捕获到错误时，我们可以使用类型断言还得到无效参数并对其进行适当的处理。与之相对的是，获得错误时仅仅使用 fmt.Println 或 log.Fatal 进行打印，这并不会改变程序的行为。\n正如另一个示例，json 包中定义了 SyntaxError 类型，该类型在 json.Decode 函数解析到错误的 JSON 语法时返回。\ntype SyntaxError struct { msg string // description of error Offset int64 // error occurred after reading Offset bytes } func (e *SyntaxError) Error() string { return e.msg } 在 Error 方法中，Offset 字段没有被使用到。但调用者可以组织其它信息（文件、行）来创建新的错误消息。\nif err := dec.Decode(\u0026amp;val); err != nil { if serr, ok := err.(*json.SyntaxError); ok { line, col := findLine(f, serr.Offset) return fmt.Errorf(\u0026#34;%s:%d:%d: %v\u0026#34;, f.Name(), line, col, err) } return err } 实现 error 接口只需要定义一个 Error 方法，当然 error 实现也可以有其它的方法。比如在 net 包中，Error 实现了 error 接口，同时自己也是一个接口并定义了其它方法：\npackage net type Error interface { error Timeout() bool // Is the error a timeout? Temporary() bool // Is the error temporary? } 客户端可以为 net.Error 做测试并通过类型断言来判定当前的网络错误是不是暂时的。比如，web 爬虫遇到临时的网络错误时可以选择休眠或者停止执行。\nif nerr, ok := err.(net.Error); ok \u0026amp;\u0026amp; nerr.Temporary() { time.Sleep(1e9) continue } if err != nil { log.Fatal(err) } 简化重复错误处理 在 Go 中，错误处理非常重要。同时，Go 的语言设计和约定也鼓励开发者显式地处理错误。在某些情况下，显式处理错误会使代码冗余，但幸运的是，一些编码技术可以最小化重复错误处理的代码。\n试想一个 HTTP handler 的应用引擎（App Engine），handler 从数据库中获得数据并渲染到视图：\nfunc init() { http.HandleFunc(\u0026#34;/view\u0026#34;, viewRecord) } func viewRecord(w http.ResponseWriter, r *http.Request) { c := appengine.NewContext(r) key := datastore.NewKey(c, \u0026#34;Record\u0026#34;, r.FormValue(\u0026#34;id\u0026#34;), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { http.Error(w, err.Error(), 500) return } if err := viewTemplate.Execute(w, record); err != nil { http.Error(w, err.Error(), 500) } } 上述方法处理了由 datastore.Get 函数和 viewTemplate.Execute 函数返回的 error。在这两种情况下，服务端给用户返回一个 HTTP 状态为 500 的消息。这看上去是组织良好的代码，但如果添加更多的 handler，你会发现存在大量的重复代码。\n为了减少重复，我们可以定义 HTTP appHandler 类型，该类型为一个函数，函数的返回值是一个 error。\ntype appHandler func(http.ResponseWriter, *http.Request) error 然后，我们修改 viewRecord 函数：\nfunc viewRecord(w http.ResponseWriter, r *http.Request) error { c := appengine.NewContext(r) key := datastore.NewKey(c, \u0026#34;Record\u0026#34;, r.FormValue(\u0026#34;id\u0026#34;), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { return err } return viewTemplate.Execute(w, record) } 相较于上一个版本，该版本会更加简单。但是 http 包并不能正确理解返回 error 的 handler，为了解决这一问题，该类型可以实现 http.Hanlder 接口的 ServeHTTP 方法：\nfunc (fn appHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { if err := fn(w, r); err != nil { http.Error(w, err.Error(), 500) } } ServeHTTP 方法调用了 appHandler 函数，如果有错误则返回给用户。请注意，这里方法的接收都也是一个函数 fn。\n现在我们要注册 handler 函数时，不使用默认的 http.HanlderFunc 类型。\nfunc init() { http.Handle(\u0026#34;/view\u0026#34;, appHandler(viewRecord)) } 在这种方式下，可以对 500 的错误进行统一管理。程序可以给用户一个友好的 500 消息，同时我们还需要更好地记录错误信息。\n我们可以定义 appError 结构，该结构包含了一个 error 以及其它字段：\ntype appError struct { Error error Message string Code int } 接下来，我们修改 appHandler 的返回值类型：\ntype appHandler func(http.ResponseWriter, *http.Request) *appError 然后，让 appHandler.ServeHTTP 方法给用户显示 appError.Message，并把错误信息打印在终端：\nfunc (fn appHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { if e := fn(w, r); e != nil { // e is *appError, not os.Error. c := appengine.NewContext(r) c.Errorf(\u0026#34;%v\u0026#34;, e.Error) http.Error(w, e.Message, e.Code) } } 最后，我们更新 viewRecord：\nfunc viewRecord(w http.ResponseWriter, r *http.Request) *appError { c := appengine.NewContext(r) key := datastore.NewKey(c, \u0026#34;Record\u0026#34;, r.FormValue(\u0026#34;id\u0026#34;), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil { return \u0026amp;appError{err, \u0026#34;Record not found\u0026#34;, 404} } if err := viewTemplate.Execute(w, record); err != nil { return \u0026amp;appError{err, \u0026#34;Can\u0026#39;t display record\u0026#34;, 500} } return nil } 这个版本的 viewRecord 与上一个版本有相同行数的代码，但不同行错误处理又包含其具体的含义。 不止于此，在程序中，我们可以进一步提高错误处理的效率，如：\n以 HTML 模板的方式展示错误； 使用栈追踪技术更好地进行调试； 为 appError 编写一个构造函数来存储栈信息； 使用 recover 和 panic 设计错误恢复机制； 结论 合适的错误处理是好软件的必要项，运用本文介绍的技术一定可以编写更可靠的 Go 代码。\n","date":"2022-08-22","img":"","permalink":"/posts/go-error-handling/","series":null,"tags":["翻译"],"title":"Go 的错误处理"},{"categories":["Python"],"content":"PAT 甲级 1003 。\n# -*- coding:utf-8 -*- if __name__ == \u0026#39;__main__\u0026#39;: # n 树中节点个数 # m 非叶子节点个数 n, m = list(map(int, input().strip().split(\u0026#39; \u0026#39;))) # 二维数组 # 元素的下标表示节点的 ID # 第 1 个元素不使用 tree = [[] for _ in range(n+1)] while m != 0: tokens = list(map(int, input().split(\u0026#39; \u0026#39;))) _id = tokens[0] children = tokens[2:] tree[_id] = children m = m - 1 # 记录每一层叶子节点的数量 counts = [0 for _ in range(n+1)] # 记录最大深度 max_depth = 0 def dfs(i, depth): global max_depth, counts, tree if len(tree[i]) == 0: # 节点 i 为叶子节点 counts[depth] = counts[depth] + 1 max_depth = max(depth, max_depth) return for j in tree[i]: dfs(j, depth + 1) dfs(1, 0) print(\u0026#39; \u0026#39;.join([str(count) for count in counts[:max_depth+1]])) 测试点 4 没过，应该是没有理解 The input ends with N being 0. That case must NOT be processed. 的原因，因为不知道要输出什么。\n","date":"2022-08-03","img":"","permalink":"/posts/python-pat-1004/","series":null,"tags":["PAT"],"title":"Python PAT 甲级 1003"},{"categories":["Python"],"content":"PAT 甲级 1003 。\n# -*- coding:utf-8 -*- import sys MAX_INT = sys.maxsize if __name__ == \u0026#39;__main__\u0026#39;: # m 城市个数 # n 路径条数 # start 起始城市下标 # end 结束城市下标 m, n, start, end = map(int, input().strip().split(\u0026#39; \u0026#39;)) # nums_of_teams 各城市救援队的数量 nums_of_teams = list(map(int, input().strip().split(\u0026#39; \u0026#39;))) assert m == len(nums_of_teams) # 城市间的路径矩阵 roadmap = [ [MAX_INT for _ in range(m)] for _ in range(m) ] # 根据输入初始化 roadmap while n != 0: i, j, d = map(int, input().strip().split(\u0026#39; \u0026#39;)) roadmap[i][j] = d roadmap[j][i] = d # 对角矩阵表示无向图 n = n - 1 roadmap[start][start] = 0 # 测试点中的起始城市和结束城市可能相同 # 起始城市到其余城市最短路径条数 nums_of_short_paths = [0 for _ in range(m)] # 保存访问记录, 0 表示未访问, 1 表示已访问 visited = [0 for _ in range(m)] # 起始城市到其余城市最短路径 dists = [MAX_INT for _ in range(m)] # 起始城市到其余城市在最短路径的基础上, 各路径上城市救援队个数的和 weights = [0 for _ in range(m)] # 初始状态 nums_of_short_paths[start] = 1 # 起始城市到自己, 表示有 1 条 dists[start] = 0 weights[start] = nums_of_teams[start] for i in range(m): u = -1 min_d = MAX_INT # 在剩余未访问的城市中, 找到距离起始城市最近的城市 for j in range(m): if visited[j] == 0 and dists[j] \u0026lt; min_d: min_d = dists[j] u = j if u == -1: break visited[u] = 1 # 第 1 次找到的必然是起始城市 for k in range(m): # for 循环用于计算： # \u0026gt; 已访问城市到未访问城市的最短路径之和 if visited[k] == 0 and roadmap[u][k] != MAX_INT: # 已访问城市与未访问城市之间必须具有连通性 if dists[u] + roadmap[u][k] \u0026lt; dists[k]: dists[k] = dists[u] + roadmap[u][k] nums_of_short_paths[k] = nums_of_short_paths[u] weights[k] = weights[u] + nums_of_teams[k] elif dists[u] + roadmap[u][k] == dists[k]: nums_of_short_paths[k] = nums_of_short_paths[k] + nums_of_short_paths[u] if nums_of_teams[k] + weights[u] \u0026gt; weights[k]: weights[k] = weights[u] + nums_of_teams[k] print(f\u0026#39;{nums_of_short_paths[end]} {weights[end]}\u0026#39;, end=\u0026#39;\u0026#39;) ","date":"2022-08-01","img":"","permalink":"/posts/python-pat-1003/","series":null,"tags":["PAT"],"title":"Python PAT 甲级 1003"},{"categories":["Web"],"content":"这是一个简单的 Node.js 的 API 的使用示例：如何基于 Node.js 的完成文件的复制。\n问题起源\n该问题源起于一个前后端不分离项目的前端静态资源如 JS、CSS 文件的管理。考虑到要对第三方静态资源的修改非常少且需要对其进行版本管理，所以想到使用 npm 对其进行管理。\n步骤\n实施的步骤如下：\n使用 npm install PACKAGE_NAME 下载到本地； 在 package.json 中配置发布脚本； 发布脚本的作用是将 PACKAGE_NAME 中的静态资源复制到指定目录； stack overflow\nstack overflow 的问题：在 Node.js 中，如何快速地复制文件。高赞答案提供了两种实现方式：\n使用 fs.copyFile； const fs = require(\u0026#39;fs\u0026#39;); // File destination.txt will be created or overwritten by default. fs.copyFile(\u0026#39;source.txt\u0026#39;, \u0026#39;destination.txt\u0026#39;, (err) =\u0026gt; { if (err) throw err; console.log(\u0026#39;source.txt was copied to destination.txt\u0026#39;); }); 流的读取与写入； const fs = require(\u0026#39;fs\u0026#39;); fs.createReadStream(\u0026#39;test.log\u0026#39;).pipe(fs.createWriteStream(\u0026#39;newLog.log\u0026#39;)); 在项目中使用\n在项目中，则是预先定义一系列的资源文件的源地址与目标地址，通过 fs.copyFile 完成复制操作。\nconst fs = require(\u0026#39;fs\u0026#39;) const universalFromPrefix = (path) =\u0026gt; \u0026#39;./node_modules/\u0026#39; + path const universalToPrefix = (path) =\u0026gt; \u0026#39;./static/\u0026#39; + path const resources = { bootstrap: [ { from: universalFromPrefix(\u0026#39;bootstrap/dist/js/bootstrap.min.js\u0026#39;), to: universalToPrefix(\u0026#39;js/bootstrap.min.js\u0026#39;), }, { from: universalFromPrefix(\u0026#39;bootstrap/dist/js/bootstrap.min.js.map\u0026#39;), to: universalToPrefix(\u0026#39;js/bootstrap.min.js.map\u0026#39;), }, { from: universalFromPrefix(\u0026#39;bootstrap/dist/css/bootstrap.min.css\u0026#39;), to: universalToPrefix(\u0026#39;css/bootstrap.min.css\u0026#39;), }, { from: universalFromPrefix(\u0026#39;bootstrap/dist/css/bootstrap.min.css.map\u0026#39;), to: universalToPrefix(\u0026#39;css/bootstrap.min.css.map\u0026#39;), }, ] } for (let resKey in resources) { let resource = resources[resKey] console.log(`copy resource ${resKey}`) for (let i = 0; i \u0026lt; resource.length; i++) { let {from, to} = resource[i] fs.copyFile(from, to, (err) =\u0026gt; { if (err) throw err console.log(`=\u0026gt; copy ${from} to ${to}`) }) } } 好处\n包的下载依赖于 npm，无须手动地下载特定的静态资源。\n","date":"2022-05-12","img":"","permalink":"/doc-stackoverflow/nodejs-fs-copyfile/","series":["Stackoverflow Magic"],"tags":["stackoverflow","Node.js"],"title":"静态资源的管理-文件复制"},{"categories":["数据库","Go"],"content":"SQL 转义问题是指执行的 SQL 语句中包含了某些特定的字符，如单引号 '、反斜杠 \\ 等，导致 SQL 语句不能正常执行。所以，我们应该在拼接 SQL 语句的过程中对特别的传入参数进行转义。\n环境信息：\nMySQL 8.0.28； Go 1.16.9 windows/amd64 问题发生 创建一个示例表 test，然后执行多条 SQL 语句：\nCREATE TABLE IF NOT EXISTS test ( content text ) ENGINE = InnoDB; package main import ( \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;github.com/jmoiron/sqlx\u0026#34; \u0026#34;log\u0026#34; ) func main() { dsn := \u0026#34;root:password$@tcp(127.0.0.1:3306)/database\u0026#34; db, err := sqlx.Connect(\u0026#34;mysql\u0026#34;, dsn) if err != nil { log.Fatalln(err) } // 元素的第 1 个反斜杠负责 Go 中字符串的转义 contentSet := []string{ \u0026#34;content1\u0026#39;\u0026#34;, \u0026#34;content2\\\u0026#34;\u0026#34;, \u0026#34;content3\\\\\u0026#34;, } for _, content := range contentSet { insertStmt := \u0026#34;INSERT INTO test VALUES (\u0026#39;\u0026#34; + content + \u0026#34;\u0026#39;);\u0026#34; fmt.Println(\u0026#34;insert statement:\u0026#34;, insertStmt) _, err := db.Exec(insertStmt) if err != nil { log.Println(err) } } } insert statement: INSERT INTO test VALUES (\u0026#39;content1\u0026#39;\u0026#39;); 2022/05/11 20:27:36 Error 1064: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;\u0026#39;content1\u0026#39;\u0026#39;)\u0026#39; at line 1 insert statement: INSERT INTO test VALUES (\u0026#39;content2\u0026#34;\u0026#39;); insert statement: INSERT INTO test VALUES (\u0026#39;content3\\\u0026#39;); 2022/05/11 20:27:37 Error 1064: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;\u0026#39;content3\\\u0026#39;)\u0026#39; at line 1 生成的 3 条 SQL 语句分别为：\nINSERT INTO test VALUES (\u0026#39;content1\u0026#39;\u0026#39;); insert statement: INSERT INTO test VALUES (\u0026#39;content2\u0026#34;\u0026#39;); INSERT INTO test VALUES (\u0026#39;content3\\\u0026#39;); 显然只有第 2 条语句是合法的\n从输出中得到，只有第 2 条语句是执行成功的，因为 'content\u0026quot;'\ndatabase/sql 的讨论 在 issue 18478 中，开发者对 database/sql 包中是否加入转义进行了讨论。kardianos 认为转义功能并不是 database/sql 包最原始的需求，因为根据不同的数据库驱动应该有不同的转义实现。所以他建议开发者应该自行实现转义功能。时隔一年后，kardianos 做出了部分妥协，表示会在部分数据库驱动增加转义实现。\nYou can get the driver from sql.DB.Driver() so while it isn\u0026#39;t a direct method from it in this shim, you can use in in a similar way right now. Here\u0026#39;s what I\u0026#39;d like to see: 1. evolve and verify the API that is in sqlexp, 2. get a few drivers to implement it (they usually appreciate PRs), 3. then if it makes sense (which I think it would at that point), bring it into the std lib. Perhaps it would be good to combine the escaper functions with the database name function. We\u0026#39;d probably want to make it easy to expand it in the future as well, which would mean changing it into a struct with methods. 基本 args 传入 现修改上述代码，内容如下：\npackage main import ( _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;github.com/jmoiron/sqlx\u0026#34; \u0026#34;log\u0026#34; ) func main() { dsn := \u0026#34;root:password$@tcp(127.0.0.1:3306)/database\u0026#34; db, err := sqlx.Connect(\u0026#34;mysql\u0026#34;, dsn) if err != nil { log.Fatalln(err) } contentSet := []string{ \u0026#34;content1\u0026#39;\u0026#34;, \u0026#34;content2\\\u0026#34;\u0026#34;, \u0026#34;content3\\\\\u0026#34;, } for _, content := range contentSet { _, err := db.Exec(\u0026#34;INSERT INTO test VALUES (?);\u0026#34;, content) if err != nil { log.Println(err) } } } 数据可以正常导入。\nmysql\u0026gt; SELECT * FROM test; +-----------+ | content | +-----------+ | content2\u0026#34; | | content1\u0026#39; | | content2\u0026#34; | | content3\\ | +-----------+ 4 rows in set (0.13 sec) 自定义转义功能 如果实在需要自己去拼接 SQL 语句，则需要在拼接前对其进行转义\n抄一个 issue 里的转义函数作为备用。\nfunc Escape(source string) string { var j int = 0 if len(source) == 0 { return \u0026#34;\u0026#34; } tempStr := source[:] desc := make([]byte, len(tempStr)*2) for i := 0; i \u0026lt; len(tempStr); i++ { flag := false var escape byte switch tempStr[i] { case \u0026#39;\\r\u0026#39;: flag = true escape = \u0026#39;\\r\u0026#39; break case \u0026#39;\\n\u0026#39;: flag = true escape = \u0026#39;\\n\u0026#39; break case \u0026#39;\\\\\u0026#39;: flag = true escape = \u0026#39;\\\\\u0026#39; break case \u0026#39;\\\u0026#39;\u0026#39;: flag = true escape = \u0026#39;\\\u0026#39;\u0026#39; break case \u0026#39;\u0026#34;\u0026#39;: flag = true escape = \u0026#39;\u0026#34;\u0026#39; break case \u0026#39;\\032\u0026#39;: flag = true escape = \u0026#39;Z\u0026#39; break default: } if flag { desc[j] = \u0026#39;\\\\\u0026#39; desc[j+1] = escape j = j + 2 } else { desc[j] = tempStr[i] j = j + 1 } } return string(desc[0:j]) } 再次对程序进行修改，修改后内容如下：\nfunc main() { dsn := \u0026#34;root:bgird123$@tcp(127.0.0.1:3306)/minority\u0026#34; db, err := sqlx.Connect(\u0026#34;mysql\u0026#34;, dsn) if err != nil { log.Fatalln(err) } contentSet := []string{ \u0026#34;content1\u0026#39;\u0026#34;, \u0026#34;content2\\\u0026#34;\u0026#34;, \u0026#34;content3\\\\\u0026#34;, } for _, content := range contentSet { insertStmt := \u0026#34;INSERT INTO test VALUES (\u0026#39;\u0026#34; + Escape(content) + \u0026#34;\u0026#39;);\u0026#34; fmt.Println(\u0026#34;insert statement:\u0026#34;, insertStmt) _, err := db.Exec(insertStmt) if err != nil { log.Println(err) } } } insert statement: INSERT INTO test VALUES (\u0026#39;content1\\\u0026#39;\u0026#39;); insert statement: INSERT INTO test VALUES (\u0026#39;content2\\\u0026#34;\u0026#39;); insert statement: INSERT INTO test VALUES (\u0026#39;content3\\\\\u0026#39;); 数据可以正常插入。\n总结 手动拼接 SQL 语句时一定要进行转义； database/sql 内置了 MySQL 驱动的转义功能，其它的没试； ","date":"2022-05-11","img":"/images/word-image-16.png","permalink":"/posts/go-sql-escape/","series":null,"tags":["sqlx","MySQL"],"title":"SQL 转义问题"},{"categories":["生产工具","运维"],"content":"Docker 命令快速查询，收集了与 docker image 相关的命令及部分示例。\nroadmap ","date":"2022-05-10","img":"","permalink":"/posts/docker-roadmap-image/","series":null,"tags":["roadmap","Docker","docker image"],"title":"与 Image 概念相关的命令"},{"categories":["Go"],"content":"在回忆管道方向的语法上时不时地会出错，所以搜罗一些资料以加强自身的记忆。\n基础 channel 是 Go 提供同步的、强类型的消息传输功能的一种数据结构，搭配上 goroutine，构建了 Go 的 Communicating Sequential Processes（CSP）并发模型。\nchannel 和 goroutine 是 Go 的 CSP 并发模型的基石。\n定义一个 channel 只需要一个 chan 关键字及 channel 中传输的元素的类型，如：\nvar c chan int // 或 c := make(chan int) 默认情况下，channel 的双向的，即 channel 的一端可读、另一端可写。因为没有定义 channel 的方向，在编写程序的过程中，很有可以向一个已关闭的 channel 发送信息。比较优的编码实践应该在代码中指定 channel 的方向。\nchannel 的方向 操作符 \u0026lt;- 用于指定 channel 是方向，表示读或写的操作。由此可知，声明一个 channel 有 3 种方式：\nvar c chan int // 双向 var c \u0026lt;-chan int // 只能读 var c chan\u0026lt;- int // 只能写 记忆方式：\n\u0026lt;-chan // 从 channel 中来 chan\u0026lt;- // 到 channel 中去 值得注意的是，一开始的 channel 声明可以是双向的，并且可以作为参数的过程中指定 channel 的方法，这样就可以避免在读取 channel 的过程中关闭 channel（因为只有写 channel 的代码才有权限关闭 channel）。\n只读的 channel 不能被关闭。\n在函数签名中，也应该使用带有方向的 channel 作为参数类型或返回值类型，除非在某一函数中完全使用双向的 channel。\nfunc ReturnReadOnly() \u0026lt;-chan int { c := make(chan int) // ... return c } // 因为 ReturnReadOnly 返回的是只读的 channel，所以 readOnly 是只读的 // 但在 ReturnReadOnly 函数中声明的是一个双向的 channel `c := make(chan int)` readOnly := ReturnReadOnly() 使用带方向的 channel 的好处：\n事先声明 channel 的读写性质； 编写的 channel 相关代码语义明显； 参考 Directional Channels in Go ","date":"2022-05-05","img":"","permalink":"/posts/go-channel-direction/","series":null,"tags":["channel"],"title":"Channel 的方向"},{"categories":["数据库","Go"],"content":"当发送给数据库的语句过大时，会报如下错误：\npanic: Error 1105: Parameter of prepared statement which is set through mysql_send_long_data() is longer than \u0026#39;max_allowed_packet\u0026#39; bytes 从报错中可知，需要修改 max_allowed_packet 选项的值。\nmy.cnf 在 my.cnf 配置文件中修改该选项是最直接了当的，修改成合适的值后重启服务即可。\n[mysqld] max_allowed_packet=16M 会话 当打开一个会话时，也可以使用下面的语句设置全局或当前的 max_allowed_packet 值。\nSET GLOBAL max_allowed_packet=1073741824; SET max_allowed_packet=1073741824; 第 1 个在服务重启后失效，第 2 个在会话结束会失效。\ngo-sql-driver/mysql 更多情况下，还是希望在程序中控制该选项，所以要看下使用的数据库驱动是否支持该选项。很庆幸，go-sql-driver/mysql 是支持的，使用的版本如下：\ngo-sql-driver/mysql@v1.6.0 在使用 gorm 中，返回一个 *gorm.DB 实例，我们都会使用下面的代码：\ndb, err := gorm.Open(mysql.Open(\u0026#34;username:password@tcp(host:port)/database?queryString\u0026#34;), \u0026amp;gorm.Config{}) 下面说一下整行代码的执行顺序：\nmysql.Open 简单返回一个实现 gorm.Dialector 接口的实例（只是简单的赋值，并没有作解析）； gorm.Open 会调用 Dialector.Initialize 方法，并且会真正地打开数据库连接； db.ConnPool, err = sql.Open(dialector.DriverName, dialector.DSN) 在 sql.Open 中会调用； connector, err := driverCtx.OpenConnector(dataSourceName) 在 driverCtx.OpenConnector 中会调用 ParseDSN 方法； ParseDSN 完成了对 DSN 的解析，包括 queryString 部分； 即：\nmysql.Open \\ \\ gorm.Open -\u0026gt; Dialector.Initialize -\u0026gt; sql.Open -\u0026gt; driverCtx.OpenConnector -\u0026gt; ParseDSN go-sql-driver/mysql 支持的 query 参数包括如下：\nallowAllFiles allowCleartextPasswords allowNativePasswords allowOldPasswords checkConnLiveness clientFoundRows collation columnsWithAlias compress # 这个是没有实现的 interpolateParams loc multiStatements parseTime readTimeout rejectReadOnly serverPubKey strict timeout tls writeTimeout maxAllowedPacket 参考 max_allowed_packet in mySQLmax_allowed_packet in mySQL ","date":"2022-04-30","img":"","permalink":"/posts/go-max-allowed-packet/","series":null,"tags":["MySQL"],"title":"Go\u0026MySQL`max_allowed_packet`"},{"categories":["正则表达式"],"content":"正则表达式教程 - 介绍。\n学习如何使用和充分利用正则表达式 这篇教程会教会你所有关于如何创造高效正则表达式的方法。教程从最基础的概念开始，所以即使你不懂正则表达式也没有关系，你也可能跟上教程的节奏。本教程会讲解正则表达式引擎的工作机制，理解正则表达式引擎有助于对一些疑难杂症的问题快速寻找解决方案。同时，本教程也旨在节约你学习正则表达式的时间，带你更好地入门。\n什么是正则表达式 一般来说，正则表达式是指用于描述某特定长度文本的模式字符串，正则的名字来源于数学方法，但本教程并不会深入数学。正则一般可以缩写为 regex 和 regexp，本教程使用 regex（PS：翻译过程中使用 regex 表示正则）。在书写的过程中，使用 regex 表示一个正则表达式字符串。\n第 1 个示例 regex 是一个完全合法的正则表达式，它是一个最简单的正则匹配模式，仅仅可以匹配字符串 regex。如：\n术语 匹配项（match）是根据正则表达式从文本中找到的一个文本片段，在本教程中使用蓝底字表示匹配项。\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b 是一个复杂的正则表达式，它描述了一系列的字母 A-Za-z、数字 0-9、点号 .、下划号 _、百分号 %、加号 + 及减号 - 的文本，然后文本后接一个 @ 符号，再接另一系列的字母、数字、点号、减号的文本，最后接至少两个的大写字母。换言之，该模式描述的是一个邮箱。如：\n正则表达式各部分说明如：\n\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b - \\b 边界符 - [A-Za-z0-9._%+-] 、 [A-Za-z0-9.-] 及 [A-Za-z] 为字符 - \\. 转义 通过上述的邮箱正则表达式，你可以在一段文本中找到邮箱字符串，或者给定一个字符串并判断其是否为一个邮箱。在本教程中，使用术语字符串表示一串字符。在实际应用中，你可以在程序或编程语言中的任意数据上使用正则表达式。\n不同的正则表达式引擎 正则表达式引擎可以是一个可处理正则表达式的程序或软件，引擎可以在给定的文本中通过模式串找到特定的字符串。通常情况下，正则表达式引擎只是一个大型应用的部分功能，并且你也不能直接修改该引擎。当需要正则表达式时，只要确保在合法的数据上使用，你可以随时的使用正则表达式引擎。\n在不同的编程语言或软件中，各正则表达式引擎并不是完全兼容，正则的语法也有各自的特点。本教程会涵盖所有流行的正则表达式的特点，包括 Perl、PCRE、PHP、.NET、 Java、JavaScript、XRegExp、VBScript、Python、Ruby、Delphi、R、Tcl、POSIX 或 其它，并介绍各正则引擎的不同之处。当然，如果教程的内容没有涵盖到你使用的语言或应用，也会介绍一些其它的正则库供你使用。\n正则初探 你可以很轻松地在支持正则表达式的文本编辑器使用正则表达式，如 EditPad Pro。如果你没有这样的编辑器，可以下免费版本的免费版本。\n将本文的内容复制到 EditPad Pro 上，然后选择 Search|Multiline Search Panel in the menu，在编辑器的底部就正则所匹配到的字符串。作为开发者的你，也必须熟悉一门编程语言，你只要使用自己熟悉的语言就可以快速的尝试正则表达式。使用正则表达式可以减少你的开发时间，因为在众多语言中，声明一个正则并利用语言提供的方法，代码量要比自己去解析要来得少很多。\n","date":"2022-04-29","img":"","permalink":"/doc-regular-expressions/introduction/","series":["正则表达式"],"tags":null,"title":"介绍"},{"categories":["生产工具"],"content":"IntelliJ IDEA 代码显示灰色，表示无任何引用，实际上是有引用。出现这种问题，非常不易于 DEBUG。\n解决方法：File -\u0026gt; Invalidate Caches \u0026hellip;\n勾选：\nClear file system cache and Local History Ask before downloading new shared indexes ","date":"2022-04-27","img":"","permalink":"/posts/ide-no-usages-found/","series":null,"tags":["JetBrains"],"title":"IDE 代码显示无引用 No Usages Found"},{"categories":["Go"],"content":"Go 中 map 是键值对的关联容器（Associative Container），可以存储不同类型的键值对，其中键的类型需要满足可比较（==）特性。\n基本操作 map 的基本操作如下：\n// 构造 m := make(map[key]value) // or m := map[key]value{} // 插入 m[k] = v // 查找 v = m[k] // 删除 delete(m, k) // 遍历 for k, v := range m // 长度 len(m) 简单实现 type element struct { k int64 v string } type map []element func (m map) Lookup(k int64) string { for _, e := range m { if e.k == k { return e.v } } return \u0026#34;\u0026#34; } 上述实现的 map 如果数据规模过大，查找元素的速率会变得很慢。由此，一个加快查找的思想是将多个元素划分到一个子集，即一个桶（bucket），根据 key 值查找到 bucket 的时间复杂度要到 O(1)，从而提前过滤了无关的数据。但为了避免同一个 bucket 存储过多数据，所以要找一个使类似 key 值达到均匀分布的哈希函数。一个好的哈希函数的标准应该是与 key 值的分布无关的，这样才能使用元素各均匀的分布。\n哈希函数 哈希函数的必须满足以下条件：\n对于唯一确定的值，函数的输出也应该是唯一确定的，不存在同一值有两个不同的输出； 函数的输出值应该服从均匀分布； 计算速度快； Go Map Go 的 map 结构如下：\n// hmap Go map 的头 type hmap struct { // key-value 的个数 count int flags uint8 // B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed // 指定 bucket 数组的起始地址 buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. // 用于 map 扩容 oldbuckets unsafe.Pointer nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields } // bmap 桶 type bmap struct { tophash [bucketCnt]uint8 } v := m[k] 编译成如下的代码：\nv := runtime.lookup(m, k) 由于 key 和 value 类型的不同，所以 lookup 的函数签名应该如下：\nfunc\u0026lt;K, V\u0026gt; lookup(m map[K]V, k K) V 显然，这是泛型的函数，但在 Go 1.18 前，Go 并没有泛型。所以 Go 在源码中使用 unsafe.Pointer 伪造了泛型。\ntype _type struct { size uintptr equal func(unsafe.Pointer, unsafe.Pointer) bool hash func(unsafe.Pinter, uintptr) uintptr } type mapType struct { key *_type value *_type } 即 key 和 value 在运行时都属于 _type 类型，并且 _type 类型实现了如 equal、hash 等方法。所以 lookup 的签名如下：\nfunc lookup(t *mapType, m *mapHeader, k unsafe.Pointer) unsafe.Pointer Map 扩容 当 map 中的键值对过多时（负载因子过大），map 会进行扩容。扩容要满足平均一个 bucket 中存在的键值对个数大于 6.5 个，步骤如下：\n向系统申请原 bucket 数组所占内存两倍的内存； 将旧桶中的数据复制到新的桶； 操作新的桶； 在复制的过程中，操作 map 的性能损耗相对较高。\n与其它语言实现的 map 对比 C++ Java Python Go \u0026amp;m[k] Yes No No No 遍历时修改 No No No Yes 自定义哈希函数（重载运算符 ==） Yes Yes Yes No Adversary Safe No No No Yes 图 1 查找速度对比\nroadmap 总结 Go 的 map 是基于 hashmap 和 bucket 实现的； 哈希函数的作用是使 key 的哈希值尽可能均匀分布； 桶中键值对平均个数大于 6.5 时，会进行扩容； 在没有泛型机制下，Go 使用 unsafe.Pointer 模拟了泛型； 参考 视频 GopherCon 2016: Keith Randall - Inside the Map Implementation Maps in Golang ","date":"2022-04-27","img":"/images/go-map.png","permalink":"/posts/go-map-detail/","series":null,"tags":["map"],"title":"Go Map"},{"categories":["Go"],"content":"面试的时候问到了一个关于 go Slice 的问题，即为什么在 a[i:] 中 i 的取值可以是 a 的长度。平时开发中也是这么用的，但没太深入的了解，所以在这篇文章中对其进行一些探讨。\nslice 删除元素 Go 标准内置包没有提供太多操作 slice 的方法，所以如果要删除 slice 的元素通常都能找到以下的实现。\nfunc remove(slice []int, s int) []int { return append(slice[:s], slice[s+1:]...) } 这里就引发出一个疑问：当要删除最后一个元素时，s+1 不就等于 slice 的长度了，但程序为什么没有报 index out of range 错误。\n两种表达式的官方解释 官方对于 a[i] 和 a[low:high]有不同的定义，分别为索引表达式 和 slice 表示式，所以两者并非一个东西。\na[i] 表达式\n下标的取值范围在 $0 \\le i \\lt len(a)$，如果超出了会报 out of range 运行时错误。\na[low:high] 表示式\n对于数组或字符串，下标的取值范围在 $0 \\le low \\le high \\le len(a)$，即下标可以取到数组的长度或字符串的长度。对于 slice 来说，下标的取值上限是 slice 的容量，显然 slice 的容量会大于等于其长度。\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { ints := make([]int, 0) for i := 0; i \u0026lt; 3; i++ { ints = append(ints, i) } fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) fmt.Println(ints[3:4]) } length: 3, capacity: 4 [0] ints 的容量为 4，所以 ints[3:4] 符合定义。另外，扩容操作只有在使用 append 方法后才会执行，正常初始化的 slice 的长度与容量相同，如下：\npackage main import \u0026#34;fmt\u0026#34; func main() { ints := []int{1, 2, 3} fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) } length: 3, capacity: 3 值得注意的是，如果 a[low:high] 中的 high 缺省了会默认为 a 的长度，则 a[len(a):] 会变成 a[len(a):len(a)] ，而 len(a) - len(a) = 0，所以会取到一个空 [] 的 slice。\n猜想一 猜想：a[len(a):] 是不是读到了 slice 相邻内存上的数据，因为相邻内存上没有数据，所以才会返回 []。所以要先了解下 slice 容量的扩展方式，例子如下：\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { ints := make([]int, 0) for i := 0; i \u0026lt; 9; i++ { // sh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;ints)) fmt.Printf(\u0026#34;before adding a element [%d]\\n\u0026#34;, i) fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) ints = append(ints, i) fmt.Printf(\u0026#34;after adding a element [%d]\\n\u0026#34;, i) fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) fmt.Println() // slice 容量从 4 开始以 2 的倍数增加 } } before adding a element [0] length: 0, capacity: 0 after adding a element [0] length: 1, capacity: 1 before adding a element [1] length: 1, capacity: 1 after adding a element [1] length: 2, capacity: 2 before adding a element [2] length: 2, capacity: 2 after adding a element [2] length: 3, capacity: 4 before adding a element [3] length: 3, capacity: 4 after adding a element [3] length: 4, capacity: 4 before adding a element [4] length: 4, capacity: 4 after adding a element [4] length: 5, capacity: 8 before adding a element [5] length: 5, capacity: 8 after adding a element [5] length: 6, capacity: 8 before adding a element [6] length: 6, capacity: 8 after adding a element [6] length: 7, capacity: 8 before adding a element [7] length: 7, capacity: 8 after adding a element [7] length: 8, capacity: 8 before adding a element [8] length: 8, capacity: 8 after adding a element [8] length: 9, capacity: 16 从输出可以得知：\n添加 int 0 后，长度为 1，容量为 1； 添加 int 1 后，长度为 2，容量为 2； 添加 int 2 后，长度为 3，容量为 4； 添加 int 4 后，长度为 5，容量为 8； 添加 int 8 后，长度为 9，容量为 16； 综上，slice 底层数组的扩展规则为容量以 2 的倍数增长。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { ints := make([]int, 0) ints = append(ints, 1, 2, 3) // slice 的长度为 3，容量为 3，取下标 3 的元素会越界 // fmt.Println(\u0026#34;try to get the 4th element\u0026#34;, ints[3]) // 取 slice 从下标 3 之后的元素，返回的是个 [] fmt.Println(\u0026#34;try to get the rest elements from the 4th element: \u0026#34;, ints[3:]) // sh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;ints)) // 打印 ints 的起始地址 fmt.Printf(\u0026#34;the start address of ints: %p\\n\u0026#34;, ints) // 第一次：打印 ints[3:] 的起始地址 fmt.Printf(\u0026#34;first the start address of ints[3:]: %p\\n\u0026#34;, ints[3:]) // 第二次：打印 ints[3:] 的起始地址 fmt.Printf(\u0026#34;second the start address of ints[3:]: %p\\n\u0026#34;, ints[3:]) // 打印 ints[2] 的地址 fmt.Printf(\u0026#34;the address of ints[2]: %p\\n\u0026#34;, \u0026amp;(ints[2])) fmt.Println() rest := ints[3:] sh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;rest)) fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, sh.Len, sh.Cap) } try to get the rest elements from the 4th element: [] the start address of ints: 0xc0000be090 first the start address of ints[3:]: 0xc0000be090 second the start address of ints[3:]: 0xc0000be090 the address of ints[2]: 0xc0000be0a0 ints 初始化为长度为 3、容量为 4 的 slice，对其进行取值操作，得到：\nints[3:] 返回一个空的 slice []，同时其起始地址与 ints 起始地址相同； 多次调用 ints[3:] 始终返回相同的结果，且长度和容量均为 0； 显然，ints[3:] 并非取到了 ints 相邻内存中的值，所以猜想不成立。\n猜想二 猜想：当 len(a) \u0026lt; cap(a) 时，a[i:j] (i \u0026lt;= j, len(a) \u0026lt; j) 取到了已分配内存中的零值。\npackage main import ( \u0026#34;fmt\u0026#34; ) func main() { ints := make([]int, 0) for i := 0; i \u0026lt; 5; i++ { ints = append(ints, i) } fmt.Printf(\u0026#34;length: %d, capacity: %d\\n\u0026#34;, len(ints), cap(ints)) fmt.Println(ints[4:8]) } length: 5, capacity: 8 [4 0 0 0] 在上述代码中，ints 的长度为 5、容量为 8，ints[4:8] 中的下标值 8 符合小于等于容量的规定，语法有效。同时看到输出，也确实取到了已分配（未使用）内存中的值。\n参考 stackoverflow: Why go doesn\u0026rsquo;t report \u0026ldquo;slice bounds out of range\u0026rdquo; in this case?\nstackoverflow: Why does go allow slicing from len(slice)?\n官方 Index 表示式\n官方 Slice 表达式\nstackoverflow: Why does go allow slicing from len(slice)?\n","date":"2022-04-26","img":"/images/go-slice.png","permalink":"/posts/go-slice-out-of-range/","series":null,"tags":["slice","stackoverflow","面试经"],"title":"Slice 什么时候报 Out of Range"},{"categories":["数据库"],"content":"小小的修改列的注释信息也能引发一些思考。\n正确的修改方式要带上原来列的定义，如：\nALTER TABLE `user` CHANGE `id` `id` INT( 11 ) COMMENT \u0026#39;id of user\u0026#39;; 高票答案的几个回复：\nNote that altering a comment will cause a full resconstruction of the table. So you may choose to live without it on very big table.\n修改列注释会重构表 （对于大表慎用）\nThat is not (or no longer) true, as long as the column definition matches the existing definition exactly. Comments can be added without causing table reconstruction.\n如果和之前的列定义一致，修改列注释不会重构表\nAlter MySQL table to add comments on columns\n","date":"2022-04-25","img":"","permalink":"/doc-stackoverflow/mysql-modify-table-column-comment/","series":["Stackoverflow Magic"],"tags":["stackoverflow","MySQL"],"title":"MySQL 修改列的注释信息"},{"categories":["Go"],"content":"在 go.mod 文件中新增 replace 信息，内容如下：\nmodule github.com/userName/mainModule require \u0026#34;github.com/userName/otherModule\u0026#34; v0.0.0 replace \u0026#34;github.com/userName/otherModule\u0026#34; v0.0.0 =\u0026gt; \u0026#34;本地包路径\u0026#34; Accessing local packages within a go module (go 1.11)\n","date":"2022-04-25","img":"","permalink":"/doc-stackoverflow/go-use-local-module-in-development/","series":["Stackoverflow Magic"],"tags":["stackoverflow","go module"],"title":"Go Module 使用本地开发的包"},{"categories":["Go"],"content":"在 Windows 下，Go 的 os 标准库提供的 Rename 方法不能跨磁盘移动文件。下面通过问题重现，提供两种解决方案。\n问题重现 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { err := os.Rename(\u0026#34;D:\\\\black.txt\u0026#34;, \u0026#34;E:\\\\black-new.txt\u0026#34;) if err != nil { fmt.Println(err) } } 执行上面的代码后报错。\nrename D:\\black.txt E:\\black-new.txt: The system cannot move the file to a different disk drive. 从源码中可知，Windows 平台有专门实现的 file_windows.go ：\n// file_windows.go func rename(oldname, newname string) error { e := windows.Rename(fixLongPath(oldname), fixLongPath(newname)) if e != nil { return \u0026amp;LinkError{\u0026#34;rename\u0026#34;, oldname, newname, e} } return nil } // syscall_windows.go func Rename(oldpath, newpath string) error { from, err := syscall.UTF16PtrFromString(oldpath) if err != nil { return err } to, err := syscall.UTF16PtrFromString(newpath) if err != nil { return err } return MoveFileEx(from, to, MOVEFILE_REPLACE_EXISTING) } // zsyscall_windows.go func MoveFileEx(from *uint16, to *uint16, flags uint32) (err error) { r1, _, e1 := syscall.Syscall(procMoveFileExW.Addr(), 3, uintptr(unsafe.Pointer(from)), uintptr(unsafe.Pointer(to)), uintptr(flags)) if r1 == 0 { err = errnoErr(e1) } return } 可见，最终移的动操作是通过系统调用完成的，其中 Rename 方法调用了两次 syscall.UTF16PtrFromString 方法，返回了两个 *uint16 类型的值，再使用 MoveFileEx 方法完成移动。\nsyscall 查看 zsyscall_windows.go 提供的方法，还有一个 MoveFile 可以尝试，所以就有了以下代码：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;syscall\u0026#34; ) func main() { oldpath := \u0026#34;D:\\\\black.txt\u0026#34; newpath := \u0026#34;E:\\\\black-new.txt\u0026#34; from, _ := syscall.UTF16PtrFromString(oldpath) to, _ := syscall.UTF16PtrFromString(newpath) fmt.Println(*from, *to) err := syscall.MoveFile(from, to) if err != nil { panic(err) } } 68 69 移动操作是成功完成的。\nstackoverflow 同时在 stackoverflow 上，也有开发者提供了移动实现。该实现的过程是借助一个中间文件，比如要移动文件到 E 盘，则先在 E 盘创建一个目标文件（os.Create），再把源文件的内容写入到目标文件（os.Copy），最后删除源文件（os.Remove），代码如下：\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) func MoveFile(sourcePath, destPath string) error { inputFile, err := os.Open(sourcePath) if err != nil { return fmt.Errorf(\u0026#34;Couldn\u0026#39;t open source file: %s\u0026#34;, err) } outputFile, err := os.Create(destPath) if err != nil { inputFile.Close() return fmt.Errorf(\u0026#34;Couldn\u0026#39;t open dest file: %s\u0026#34;, err) } defer outputFile.Close() _, err = io.Copy(outputFile, inputFile) inputFile.Close() if err != nil { return fmt.Errorf(\u0026#34;Writing to output file failed: %s\u0026#34;, err) } // The copy was successful, so now delete the original file err = os.Remove(sourcePath) if err != nil { return fmt.Errorf(\u0026#34;Failed removing original file: %s\u0026#34;, err) } return nil } 跨平台支持 如果希望应用能够在多个平台上正常运行，可以创建 file.go 和 file_windows.go，分别为不同平台要编译的源代码，也可以创建一个方法，在方法中对平台进行判断。\nfunc MoveFile(src string, dst string) error { if runtime.GOOS == \u0026#34;windows\u0026#34; { from, _ := syscall.UTF16PtrFromString(src) to, _ := syscall.UTF16PtrFromString(dst) return syscall.MoveFile(from, to) } else { return os.Rename(src, dst) } } 参考 stackoverflow: Move a file to a different drive with Go ","date":"2022-04-24","img":"","permalink":"/posts/go-file-rename-pit/","series":null,"tags":["file","I/O","Stackoverflow"],"title":"Windows 下移动文件的坑"},{"categories":["Go","Web"],"content":"从网络上下载文件是开发过程中常用的需求，常规流程是：（1）发送请求；（2）接收响应并读取响应体内容；（3）保存到本地文件。本文包含的两个例子分别来自于参考 [1] 和参考 [2]，在此基础上做了少量的修改。\n例 1 普通下载 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; ) func main() { fileUrl := \u0026#34;https://golangcode.com/logo.svg\u0026#34; filename := \u0026#34;logo.svg\u0026#34; resp, err := http.Get(fileUrl) if err != nil { panic(err) } defer resp.Body.Close() out, err := os.Create(filename) if err != nil { panic(err) } _, err = io.Copy(out, resp.Body) if err != nil { panic(err) } fmt.Println(\u0026#34;Downloaded: \u0026#34; + fileUrl) } 例 1 中使用了 io.Copy 方法将响应体内容复制到目标文件。io.Copy 是带缓冲的复制，可以避免在内存中堆积大量的数据，类似的方法还有 io.CopyBuffer。\nfunc Copy(dst Writer, src Reader) (written int64, err error) { return copyBuffer(dst, src, nil) } func CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) { if buf != nil \u0026amp;\u0026amp; len(buf) == 0 { panic(\u0026#34;empty buffer in CopyBuffer\u0026#34;) } return copyBuffer(dst, src, buf) } 例 2 带进度的下载 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/dustin/go-humanize\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) type Progress struct { total uint64 } func (p *Progress) Write(bs []byte) (n int, err error) { n = len(bs) p.total += uint64(n) p.Show() return n, nil } func (p Progress) Show() { fmt.Printf(\u0026#34;\\r%s\u0026#34;, strings.Repeat(\u0026#34; \u0026#34;, 35)) fmt.Printf(\u0026#34;\\rDownloading... %s complete\u0026#34;, humanize.Bytes(p.total)) } func main() { fileUrl := \u0026#34;https://golangcode.com/logo.svg\u0026#34; filename := \u0026#34;logo.svg\u0026#34; resp, err := http.Get(fileUrl) if err != nil { panic(err) } defer resp.Body.Close() out, err := os.Create(filename) if err != nil { panic(err) } defer out.Close() if _, err = io.Copy(out, io.TeeReader(resp.Body, \u0026amp;Progress{})); err != nil { panic(err) } } 与例 1 的不同之处在于 io.Copy 的第 2 参数换成了一个 io.teeReader 的对象。下面是 io.teeReader 的定义：\ntype teeReader struct { r Reader w Writer } func (t *teeReader) Read(p []byte) (n int, err error) { n, err = t.r.Read(p) if n \u0026gt; 0 { if n, err := t.w.Write(p[:n]); err != nil { return n, err } } return } teeReader 实现了 Reader 接口，而在 Read 方法中保留了原先读取数据的操作，新增了一个写数据的操作。Progress 实现了 Writer 接口，正好可以作为 teeReader 的 w 字段的值，所以在执行 Read 的过程中会调用 Progress.Write 方法，从而可以知道已经读取数据的大小。最后用 Progress.Show 方法将 total 字段的值输出到终端。\n参考 GolangCode: Download a File (from a URL) GolangCode: Download Large Files with Progress Reports ","date":"2022-04-24","img":"","permalink":"/posts/go-download-network-file/","series":null,"tags":["HTTP","I/O"],"title":"URL 下载网络文件"},{"categories":["Go","数据库","Web"],"content":"在 Web 开发中，常常需要对请求信息进行记录，形成日志以便于后期评估应用的性能。请求信息通常包含客户端地址、请求的 URL、请求时间及请求执行时间。在程序中，可以以同步或异步的方式完成这一需求。同步方式是指请求信息写入日志文件后才返回数据给客户端，异步方式则是在返回数据之前以新线程或进程完成对请求信息的记录。开源的日志包有：\nZap：出自 Uber 团队，以高性能著称； Zerolog：以易用性著称，支持 7 种日志级别； Logrus：兼容标准日志包格式，也是本人常用的日志包； apex/log：受 Logrus 启发，简化操作后的 Logrus； Log15：日志可读性强； 5 个日志包的详细介绍可以看《5 种结构化 Go 日志包对比分析》这篇文章。\n在 Go 开发中，一个非常简单的办法就是启用一个 goroutine 将请求信息发送到目的地，目的地可以是（1）一个日志文件；（2）一个 channel 或其它的应用（如 Redis）。在第 2 种方法中，还需要另一个拉取日志信息的服务，这类方法的优势是可以提高主体应用的性能，缺点是增加了系统的复杂度。本文的重点落在两个方面，分别为：\n解析请求，将信息发送到 Redis 服务器； 读取 Redis 服务器中的请求信息，持久化到日志文件； 所以在本次实现中，包含两个组件（app 组件和 micro-dumper 组件）分别完成上述两项功能。\napp 首先需要一个 Record 类型来描述请求信息，其结构如下：\n// Record Represent a set of a Request passing from the client type Record struct { RemoteAddr string URL string AccessTime int64 TimeExecuted int64 BodyBytesSent int64 } 在 Redis 端，我们也需要两种数据结构，分别为 Stream 和 List。Stream 可以用来保存请求的信息，而 List 则是用保存 Stream 中请求信息的 ID。\n当前 Redis 不支持以位置索引的方式访问 Stream 中的信息。Stackoverflow\n接着定义两种数据类型的键名：\nconst StreamKey = \u0026#34;api-request-log\u0026#34; const RecordIDsKey = \u0026#34;api-request-record-ids\u0026#34; 然后就是实现 Redis 的连接，用于访问 Redis 服务器。\nvar client *redis.Client var once sync.Once // Client return a redis client func Client() *redis.Client { once.Do(func() { // Maybe you should instantiate redis client by reading config file client = redis.NewClient(\u0026amp;redis.Options{ Network: \u0026#34;tcp\u0026#34;, Addr: \u0026#34;localhost:6379\u0026#34;, DB: 0, }) }) return client } 这里使用单例设计模式，应用只需要维护一个 Redis 客户端即可。有了记录（请求信息）和 Redis 客户端，就应该将记录发送到 Redis 服务器。\n// SendRecord send a record to redis server, two things are done as follows: // 1. add a entry to the stream // 2. push a entry id to the list func SendRecord(record Record) { // add a entry by call .XAdd method xaddCmd := Client().XAdd(context.Background(), \u0026amp;redis.XAddArgs{ Stream: StreamKey, ID: \u0026#34;*\u0026#34;, Values: map[string]interface{}{ \u0026#34;remote_addr\u0026#34;: record.RemoteAddr, \u0026#34;url\u0026#34;: record.URL, \u0026#34;access_time\u0026#34;: record.AccessTime, \u0026#34;time_executed\u0026#34;: record.TimeExecuted, \u0026#34;body_bytes_sent\u0026#34;: record.BodyBytesSent, }, }) if xaddCmd.Err() != nil { panic(xaddCmd.Err()) } recordID := xaddCmd.Val() // push the id to the list by call .LPush method lpushCmd := Client().LPush(context.Background(), RecordIDsKey, recordID) if lpushCmd.Err() != nil { panic(lpushCmd.Err()) } } 上述代码做了两件事情：\n将记录添加到键为 StreamKey 的 Stream； 将记录 ID 添加到键为 RecordIDsKey 的 List； 最后，app 组件的主程序如下：\nimport ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;redislog\u0026#34; \u0026#34;time\u0026#34; ) type User struct { Name string `json:\u0026#34;name\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } // dataFromDB mock retrieving data from database func dataFromDB() []*User { return []*User{ { \u0026#34;xiaoming\u0026#34;, 12, }, { \u0026#34;xiaohong\u0026#34;, 13, }, { \u0026#34;xiaobei\u0026#34;, 14, }, } } // RedisLogger a gin.HandlerFunc wrapper // extract request information, assemble to a record, and send to Redis server via goroutine func RedisLogger(f gin.HandlerFunc) gin.HandlerFunc { return func(c *gin.Context) { record := redislog.Record{ RemoteAddr: c.Request.RemoteAddr, URL: c.Request.URL.RequestURI(), AccessTime: time.Now().Unix(), } f(c) record.TimeExecuted = time.Now().Unix() - record.AccessTime record.BodyBytesSent = int64(c.Writer.Size()) go redislog.SendRecord(record) } } func main() { engine := gin.Default() engine.GET(\u0026#34;api/users\u0026#34;, RedisLogger(func(c *gin.Context) { time.Sleep(time.Second * time.Duration(rand.Int63n(5))) c.JSON(http.StatusOK, gin.H{ \u0026#34;data\u0026#34;: dataFromDB(), }) })) engine.GET(\u0026#34;api/user/:name/age\u0026#34;, RedisLogger(func(c *gin.Context) { users := dataFromDB() name := c.Param(\u0026#34;name\u0026#34;) var user *User for _, u := range users { if u.Name == name { user = u } } var age interface{} if user == nil { age = \u0026#34;unknown\u0026#34; } else { age = user.Age } c.JSON(http.StatusOK, gin.H{ \u0026#34;age\u0026#34;: age, }) })) log.Fatalln(engine.Run(\u0026#34;:9090\u0026#34;)) } 上述代码定义了两个接口：/api/users 和 /api/user/:name/age，两个 gin.HandlerFunc 都被 RedisLogger 进行“包裹”。\nmirco-dumper micro-dumper 会周期性拉取 Stream 里的记录，如果存在并保存到日志文件，反之则等待下一刻执行。主要实现其实就一个 ReadRecord 方法：\n// ReadRecord read a record from redis, three things are done as follows: // 1. retrieve a entry id from the list // 2. retrieve a entry from the stream via the entry id // 3. after retrieving the entry, delete the entry from the stream func ReadRecord() (Record, bool) { // retrieve record id from the redis list lpopCmd := Client().LPop(context.Background(), RecordIDsKey) recordID := lpopCmd.Val() if recordID == \u0026#34;\u0026#34; { return Record{}, false } // read the record from the stream xreadCmd := Client().XRead(context.Background(), \u0026amp;redis.XReadArgs{ Streams: []string{StreamKey, recordID}, Count: 1, Block: 0, }) if xreadCmd.Err() != nil { panic(xreadCmd.Err()) } // if read successfully, we should remove record from the stream xdelCmd := Client().XDel(context.Background(), StreamKey, recordID) if xdelCmd.Err() != nil { panic(xdelCmd.Err()) } record := xreadCmd.Val()[0].Messages[0].Values accessTime, _ := strconv.ParseInt(record[\u0026#34;access_time\u0026#34;].(string), 10, 64) timeExecuted, _ := strconv.ParseInt(record[\u0026#34;time_executed\u0026#34;].(string), 10, 64) bodyBytesSent, _ := strconv.ParseInt(record[\u0026#34;body_bytes_sent\u0026#34;].(string), 10, 64) return Record{ RemoteAddr: record[\u0026#34;remote_addr\u0026#34;].(string), URL: record[\u0026#34;url\u0026#34;].(string), AccessTime: accessTime, TimeExecuted: timeExecuted, BodyBytesSent: bodyBytesSent, }, true } 读记录的逻辑如下：\n从 List 中得到记录的 ID； 通过 ID 得到 Stream 中的记录； 记录获取完毕后，将该记录在 Stream 中删除； LPOP 是左端弹出操作，在获取的同时，List 中已经不存在该 ID 了。\n最后编写主程序：\nfunc main() { fmt.Println(\u0026#34;start to retrieve request record ...\u0026#34;) f, _ := os.Create(\u0026#34;./request.log\u0026#34;) for { time.Sleep(1) if record, found := redislog.ReadRecord(); found { _, err := f.WriteString(fmt.Sprintf(\u0026#34;remote addr: %s url: %s access time: %d time executed: %d body bytes sent: %d\\n\u0026#34;, record.RemoteAddr, record.URL, record.AccessTime, record.TimeExecuted, record.BodyBytesSent)) if err != nil { panic(err) } else { fmt.Println(\u0026#34;write a request record to log file\u0026#34;) } } } } 测试 运行 app 和 mirco-dumper：\n$ nohup go run app/main.go \u0026gt; app.out \u0026amp; $ nohup go run micro-dumper/main.go \u0026gt; micro-dumper.out \u0026amp; 使用 ab 测试工具发送大量请求：\n$ ab -n 1000 -c 10 http://localhost:9090/api/users $ ab -n 1000 -c 10 http://localhost:9090/api/user/xiaohong/age 查看日志：\nhead -10 request.log remote addr: [::1]:58644 url: /api/users access time: 1650716423 time executed: 0 body bytes sent: 96 remote addr: [::1]:58636 url: /api/users access time: 1650716423 time executed: 1 body bytes sent: 96 remote addr: [::1]:58666 url: /api/users access time: 1650716424 time executed: 0 body bytes sent: 96 remote addr: [::1]:58640 url: /api/users access time: 1650716423 time executed: 2 body bytes sent: 96 remote addr: [::1]:58658 url: /api/users access time: 1650716423 time executed: 2 body bytes sent: 96 remote addr: [::1]:58680 url: /api/users access time: 1650716425 time executed: 0 body bytes sent: 96 remote addr: [::1]:58648 url: /api/users access time: 1650716423 time executed: 3 body bytes sent: 96 remote addr: [::1]:58654 url: /api/users access time: 1650716423 time executed: 3 body bytes sent: 96 remote addr: [::1]:58682 url: /api/users access time: 1650716425 time executed: 1 body bytes sent: 96 remote addr: [::1]:58646 url: /api/users access time: 1650716423 time executed: 4 body bytes sent: 96 完整代码 redislog\n总结 ResponseWriter 接口定义了 Size 方法可以得到响应体中的字节数； 因为 Redis 保存的都是字符串形式，所以在 Go 代码中总是要做字符串转换； ","date":"2022-04-23","img":"/images/managing_activity_logs.jpg","permalink":"/posts/go-redis-request-log-dumper/","series":null,"tags":["Redis","logging","Gin"],"title":"Redis 的 List 和 Stream：异步记录请求信息"},{"categories":["Go"],"content":"首先贴上 Go 开发团队对 reflect 包的描述：\nPackage reflect implements run-time reflection, allowing a program to manipulate objects with arbitrary types. The typical use is to take a value with static type interface{} and extract its dynamic type information by calling TypeOf, which returns a Type.\nA call to ValueOf returns a Value representing the run-time data. Zero takes a Type and returns a Value representing a zero value for that type.\n从描述中，我们得到以下几点：\nreflect 包实现了运行时的反射机制，允许程序操作任意类型的对象； TypeOf 可以得到一个 interface{} 的具体类型，ValueOf 可以得到一个 interface{} 的具体值； 重要类型 reflect 包中定义了几种重要的、常用的类型，分别为：\nKind； Value； SliceHeader； StringHeader； Method； StructField； Kind Kind 类型用于修饰类型 Type，用于表示 Type 的种类，底层是用一个无符号整数表示：\ntype Kind uint; 其中修饰了的基础数据类型包括Bool、Int、Int32、Float32、Float64 等，引用数据类型包括Slice、Map、Chan、Interface、Func 等。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { var v1 int = 1 var v2 float32 = 1.0 v3 := struct { }{} v4 := func() {} PrintKind(v1) PrintKind(v2) PrintKind(v3) PrintKind(v4) } func PrintKind(v interface{}) { t := reflect.TypeOf(v) switch t.Kind() { case reflect.Int: fmt.Println(\u0026#34;int\u0026#34;) case reflect.Float32: fmt.Println(\u0026#34;float32\u0026#34;) case reflect.Struct: fmt.Println(\u0026#34;struct\u0026#34;) case reflect.Func: fmt.Println(\u0026#34;function\u0026#34;) // 其它的情况 ... } } int float32 struct function 如果只是单纯地打印类型 Type 的种类，直接调用 .String 方法即可。\nfunc PrintKind(v interface{}) { t := reflect.TypeOf(v) fmt.Println(t.String()) } int float32 struct {} func() Value Value 类型表示一个接口具体的值，类型的定义如下：\ntype Value struct { // 值的真实类型 typ *rtype // 指向值的指针 ptr unsafe.Pointer // 值的元数据信息 // flag 可以是多种情况的组合 flag } 在知道值类型的情况下，可以调用相应的函数获取其本身的值，即值的类型是 int，经过 ValueOf 返回 Value 类型的值就可以调用 Int 方法得到其值。但是，如果调用了不符合本身类型的方法会报错，这一类方法的开头都对值的类型做了类型判断。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { var v1 int = 1 fmt.Println(reflect.ValueOf(v1).Int()) var v2 float32 = 1.0 // fmt.Println(reflect.ValueOf(v2).Int()) 会报错 } func (v Value) Int() int64 { k := v.kind() p := v.ptr switch k { case Int: return int64(*(*int)(p)) case Int8: return int64(*(*int8)(p)) case Int16: return int64(*(*int16)(p)) case Int32: return int64(*(*int32)(p)) case Int64: return *(*int64)(p) } panic(\u0026amp;ValueError{\u0026#34;reflect.Value.Int\u0026#34;, v.kind()}) } func (f flag) mustBe(expected Kind) { // TODO(mvdan): use f.kind() again once mid-stack inlining gets better if Kind(f\u0026amp;flagKindMask) != expected { panic(\u0026amp;ValueError{methodName(), f.kind()}) } } SliceHeader SliceHeader 是 slice 运行时的底层实现，其结构如下：\ntype SliceHeader struct { // 指向底层数据的指针 // 无符号的整数表示内存中的地址 Data uintptr // slice 的长度 Len int // slice 的容量 Cap int } func main() { data := []int{1, 2, 3, 4, 5} // unsafe.Pointer 表示任意类型的指针 dataPointer := unsafe.Pointer(\u0026amp;data) sh1 := (*reflect.SliceHeader)(dataPointer) fmt.Printf(`SliceHeader { Data: %d Len: %d Cap: %d } `, sh1.Data, sh1.Len, sh1.Cap) for i := 0; i \u0026lt; sh1.Len; i++ { // slice 中各元素的地址 addr := uint(sh1.Data) + uint(unsafe.Sizeof(1)) * uint(i) // slice 中各元素的值 value := *(*int)(unsafe.Pointer(uintptr(addr))) fmt.Printf(\u0026#34;%dth element addr: 0x%x, value: %d\\n\u0026#34;, i, addr, value) } } SliceHeader { Data: 824634670792 Len: 5 Cap: 5 } 0th element addr: 0xc0000e7ec8, value: 1 1th element addr: 0xc0000e7ed0, value: 2 2th element addr: 0xc0000e7ed8, value: 3 3th element addr: 0xc0000e7ee0, value: 4 4th element addr: 0xc0000e7ee8, value: 5 上述代码构造了一个 SliceHeader 类型的变量 sh1，并逐一打印出各元素的地址和值：\n\u0026amp;data 得到了 slice 的指针，使用 unsafe.Pointer(\u0026amp;data) 强制转换变成 *ArbitraryType； 使用 (*reflect.SliceHeader)(dataPointer) 得到了一个指向 SliceHeader 的指针； fmt.Printf 打印变量中 3 个字段的信息； for 循环：先计算每一个元素的地址，再通过地址得到地址上的值，最后打印输出； 地址和值都需要进行一系列转换； 如 uintptr 不支持算法运算符，所以通过转换成 uint 类型进行计算； 值的获取则是先将 uint 转换成 uintptr，再通过 unsafe.Pointer 转换成可表示任意类型的指针，接着转成 *int 类型的指针，最后使用 * 取指针的值； StringHeader StringHeader 是 string 运行时的底层实现，其结构如下：\ntype StringHeader struct { // 指向底层数据的指针 // 无符号的整数表示内存中的地址 Data uintptr // 字符串的长度 Len int } func main() { data := []string{\u0026#34;1\u0026#34;, \u0026#34;22\u0026#34;, \u0026#34;333\u0026#34;, \u0026#34;4444\u0026#34;, \u0026#34;55555\u0026#34;} sh1 := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;data)) fmt.Printf(\u0026#34;string slice length: %d\\n\u0026#34;, sh1.Len) for i := 0; i \u0026lt; sh1.Len; i++ { // 计算第 i 个元素的地址 addr := uint(sh1.Data) + uint(i) * uint(unsafe.Sizeof(data[i])) // 转换成任意类型的指针 arbitraryPointer := unsafe.Pointer(uintptr(addr)) // 转换成字符串指针 stringPointer := (*string)(arbitraryPointer) value := *stringPointer fmt.Printf(\u0026#34;%dth value: %s\\n\u0026#34;, i, value) } } string slice length: 5 0th value: 1 1th value: 22 2th value: 333 3th value: 4444 4th value: 55555 StringHeader 的例子与 SliceHeader 类似，区别在于在指针转换时 StringHeader 使用了 *string。\nMethod Method 表示一个方法，可以使用 reflect 包动态的调用方法，传入的参数是一个 reflect.Value 的 slice，其返回值也是使用一个 reflect.Value 的 slice 表示。\ntype anyFunc func(int) int type A struct {} func (a A) AnyFunc() string { return \u0026#34;A\u0026#34; } func main() { var oneFunc anyFunc = func(i int) int { return i + 1 } // oneFunc 是一个函数指针 fmt.Printf(\u0026#34;1. pointer %p\\n\u0026#34;, oneFunc) // 函数类型的字符串表示 fmt.Printf(\u0026#34;2. %s\\n\u0026#34;, reflect.TypeOf(oneFunc).String()) // 函数指针 fmt.Printf(\u0026#34;3. %s\\n\u0026#34;, (reflect.ValueOf(\u0026amp;oneFunc)).Kind().String()) fmt.Println(\u0026#34;== call method by reflect package\u0026#34;) i := 1000 // reflect.Value 得到函数值 // .Call 调用函数 // []reflect.Value{reflect.ValueOf(i)} 是传入函数的参数 result := reflect.ValueOf(oneFunc).Call([]reflect.Value{reflect.ValueOf(i)}) fmt.Println(result[0]) // 类型中的方法 a := A{} method := reflect.TypeOf(a).Method(0) fmt.Printf(`== basic information of A.AnyFunc Type: %s Name: %s PkgPath： %s Index: %d `, method.Type, method.Name, method.PkgPath, method.Index) // 调用类型中的方法 fmt.Println(\u0026#34;== call a.AnyFunc\u0026#34;) fmt.Println(reflect.ValueOf(a).Method(0).Call([]reflect.Value{})) } StructField StructField 表示一个结构的字段，StructField 还会保存字段的 Tag 信息（StructTag）。StructTag 的底层实现是 string：\ntype StructTag string type A struct { StringField string `json:\u0026#34;jsonStringField\u0026#34;` IntField int `json:\u0026#34;jsonIntField\u0026#34;` } func main() { a := A{ StringField: \u0026#34;simple string\u0026#34;, IntField: 100, } fmt.Printf(\u0026#34;number of struct fields: %d\\n\u0026#34;, reflect.TypeOf(a).NumField()) fmt.Println(\u0026#34;== get struct field value\u0026#34;) numField := reflect.TypeOf(a).NumField() for i := 0; i \u0026lt; numField; i++ { fmt.Printf(\u0026#34;%s: %v\\n\u0026#34;, reflect.TypeOf(a).Field(i).Name, reflect.ValueOf(a).Field(i)) } fmt.Println(\u0026#34;== get struct field tag\u0026#34;) for i := 0; i \u0026lt; numField; i++ { tag := reflect.TypeOf(a).Field(i).Tag fmt.Printf(\u0026#34;%s\u0026#39;s tag string: `%s`\\n\u0026#34;, reflect.TypeOf(a).Field(i).Name, tag) fmt.Printf(\u0026#34; json: %v\\n\u0026#34;, tag.Get(\u0026#34;json\u0026#34;)) } } 总结 reflect.ValueOf(值) 和 reflect.ValueOf(指针).Elem() 等价； unsafe.Pointer 提供了任意类型指针的访问； 参考 Go 标准库 reflect stackoverflow 动态调用对象的方法 ","date":"2022-04-21","img":"/images/golang-reflect.png","permalink":"/posts/go-set-value-via-reflect-package/","series":null,"tags":["reflect","反射"],"title":"Go 的反射包 Reflect"},{"categories":["数据库"],"content":"在 MySQL 5.5 之前，默认存储引擎为 MyISAM，之后版本的默认存储引擎为 InnoDB。\n选择一个合适的存储引擎至关重要。\n存储引擎 根据是否支持事务，MySQL 的存储引擎可以分为：\n事务型； 非事务型； 表 1 为 MySQL 支持的所有存储引擎以及各存储引擎的基本介绍。\n表 1 不同的存储引擎\n存储引擎 支持事务 特点 适用场景 InnoDB 是 1. 支持行锁、灾难恢复、多版本并发控制；\n2. 支持外键、字段约束； 1. 适用于绝大部分场景； MyISAM 否 1. 读写速度快；\n2. 支持表锁；\n3. 支持 B 树索引、聚簇索引、全文搜索索引；\n4. 支持地理数据及其索引；\n5. 不支持哈希索引、外键、多版本并发控制；\n6. 存储限制为 256TB； 1. 读写频繁的应用；\n2. 数据仓库； Memory 否 1. 内存数据库；\n2. 相较于 MyISAM，读写速度更快；\n3. 支持表锁；\n4. 非持久化数据；\n5. 不支持多版本并发控制； 1. 快存快取 CSV 否 1. 通用格式，易于集成；\n2. 不支持索引；\n3. 不支持分区；\n4. 表的所有字段都要设置 not null / Merge 否 1. 底层使用 MyISAM 存储引擎；\n1. 数据仓库\nArchive 否 1. 插入数据后，数据会被压缩； 1. 存储历史数据； Federated 否 1. 集群式管理 MySQL 实例；\n1. 分布式环境； Blackhole 否 1. 可以向表插入数据，但查询只会返回空结果；\n2. 支持所有的索引类型；\n3. 不支持分区； / Example 否 啥也不是存储引擎 / 设置方法 以 InnoDB 为例，可通过以下 3 种方法设置表的存储引擎：\nmy.cnf 配置项； SET STORAGE_ENGINE； 创建表时； my.cnf 配置项 在 my.cnf 文件或其它引入的配置中，修改 [mysqld] 中的 default-storage-engine 的值，如：\n[mysqld] default-storage-engine = InnoDB SET STORAGE_ENGINE 在执行脚本文件前，先通过 SET 设置使用的存储引擎：\nSET STORAGE_ENGINE = InnoDB; 创建表时 在创建数据库表时，指定 ENGINE：\nCREATE TABLE IF NOT EXISTS test_name ( id int ) ENGINE = InnoDB; 总结 MySQL 支持多种不同的存储引擎，InnoDB 存储引擎适用于绝大多数场景，并且支持事务、多版本并发控制； 可以在 3 个层次上对存储引擎进行修改，即： 服务器层，my.cnf 配置项； 会话层，在当前会话中使用 SET 设置存储引擎； 脚本层，在创建或修改表时声明存储引擎； 参考 MySQL storage engines 官方文档 Alternative Storage Engines ","date":"2022-04-21","img":"","permalink":"/posts/mysql-set-storage-engine/","series":null,"tags":["MySQL","存储引擎"],"title":"MySQL 设置存储引擎的 3 种方法"},{"categories":["数据库"],"content":"存储过程是存储在数据库中并且已经提前编译好的 SQL 语句集合，它是应用中数据操作的部分逻辑实现。MySQL 5 版本引入了这一设计，存储过程包含 3 个部分：\n名称； 参数列表； SQL 语句； 特性 存储过程包含了诸多特性，主要包括：\n性能提升：存储过程是预先编译好、存储好的 SQL 语句集合，没有 SQL 词法/语法解析、编译的过程； 减少网络流量：客户端无须发送大量 SQL 语句到数据库，只需要提供存储过程名称和参数列表即可； 可重用：存储过程的逻辑一般都是常规周期性的逻辑操作，可重复使用； 安全性强：网络上传输的数据不包含具体的操作信息，可以为存储过程设置用户操作权限； 基本语法 在 MySQL 中，创建一个存储过程的语法如下：\nDELIMITER \u0026amp;\u0026amp; CREATE PROCEDURE procedure_name [[IN | OUT | INOUT] parameter_name datatype [, parameter datatype]) ] BEGIN -- 定义变量 ... -- 执行逻辑 ... END \u0026amp;\u0026amp; DELIMITER ; 创建存储过程时，可以使用 DELIMITER 指定分隔符，这样就可以在存储过程依然使用冒号 ; 作为语句的分隔符。\nIN | OUT | INOUT 为参数的类型，分别表示：\nIN：参数只作为输入，存储过程内部不允许对其进行修改； OUT：参数只作为输出，存储过程内部可以对其修改，但没办法访问其初始值； INOUT：同时兼具 IN 和 OUT 类型参数的特性； 在终端执行存储过程的命令如下：\nCALL procedure_name (参数列表); 使用 CALL 关键字执行存储过程； 如果有参数，需要在括号内指定，使用逗号分隔； 与 PostgreSQL 不同，MySQL 不支持下面语法：\nCREATE OR REPLACE procedureName; 要想实现相同的效果，需编写如下语句：\nDROP PROCEDURE IF EXISTS procedureName; ... CREATE PROCEDURE procedure_name ... ... 条件判断：\nDROP PROCEDURE IF EXISTS judge_num; DELIMITER \u0026amp;\u0026amp; CREATE PROCEDURE judge_num (in num int) BEGIN if num \u0026gt; 10 then SELECT \u0026#39;X \u0026gt; 10\u0026#39; AS result; elseif num \u0026lt; 0 then SELECT \u0026#39;X \u0026lt; 0\u0026#39; AS result; else SELECT \u0026#39;0 \u0026lt;= X \u0026lt;= 10\u0026#39; AS result; end if; END \u0026amp;\u0026amp; DELIMITER ; CALL judge_num(20); 示例 示例使用的数据来自 MySQL 的官方测试数据集，可直接通过 datacharmer/test_db 下载脚本和数据，数据库结构如下图：\n不带参数 DROP PROCEDURE IF EXISTS get_emps; DELIMITER \u0026amp;\u0026amp; CREATE PROCEDURE get_emps () BEGIN SELECT emp_no FROM dept_emp WHERE from_date \u0026gt; \u0026#39;1990-01-01\u0026#39;; END \u0026amp;\u0026amp; DELIMITER ; CALL get_emps; 即使存储过程未使用参数，仍然需要使用括号 ()； 在执行时，不需要括号 ()； 带 IN 类型参数 DELIMITER \u0026amp;\u0026amp; CREATE PROCEDURE total_salary (in empno varchar(5)) BEGIN SELECT sum(salary) FROM salaries WHERE emp_no=empno; END \u0026amp;\u0026amp; DELIMITER ; CALL total_salary(\u0026#39;10001\u0026#39;); IN 类型参数可以直接传入，可以不需要提前声明变量； 带 OUT 类型参数 显然，上一个例子更适合结合 OUT 类型参数。\nDROP PROCEDURE IF EXISTS out_total_salary; DELIMITER \u0026amp;\u0026amp; CREATE PROCEDURE out_total_salary (in empno varchar(5), out total int) BEGIN SELECT sum(salary) INTO total FROM salaries WHERE emp_no=empno; END \u0026amp;\u0026amp; DELIMITER ; SET @total = 0; CALL out_total_salary(\u0026#39;10001\u0026#39;, @total); SELECT @total; SET 指定的变量是弱类型变量，可以任意赋值； 最佳实践 在 stackoverfolow 找到一个关于编写存储过程的最佳实践，其中要点未做尝试，留个记录便于反复查看。\n调用存储过程时，使用全路径，减少查找存储过程的逻辑判断； CALL employees.out_total_salary('10001', @total); 做好存储过程的权限管理； 使用变量记录存储过程中的关键信息，如错误信息 @@error、行数信息 @@rowcount 等； 使用一个 OUT 类型变量，用于标识存储过程是否执行成功，可以使用 int 类型参数，0 表示成功，非 0 表示失败； 其它 SHOW CREATE PROCEDURE 可以使用 SHOW CREATE PROCEDURE 显示存储过程的基本信息：\nmysql\u0026gt; SHOW CREATE PROCEDURE dept_emp_num\\G; *************************** 1. row *************************** Procedure: dept_emp_num sql_mode: STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION Create Procedure: CREATE DEFINER=`root`@`localhost` PROCEDURE `dept_emp_num`(in deptno varchar(100), out num int) BEGIN SELECT count(emp_no) INTO num FROM dept_emp WHERE dept_no=deptno; END character_set_client: utf8mb4 collation_connection: utf8mb4_0900_ai_ci Database Collation: utf8mb4_0900_ai_ci 1 row in set (0.00 sec) information_schema.routines 表 information_schema.routines 表中存放了存储过程信息，如：\nmysql\u0026gt; SELECT routine_name, created, sql_mode, sql_data_access FROM information_schema.routines WHERE routine_type=\u0026#39;PROCEDURE\u0026#39; AND routine_name=\u0026#39;total_salary\u0026#39;\\G; *************************** 1. row *************************** ROUTINE_NAME: total_salary CREATED: 2022-04-20 09:49:57 SQL_MODE: STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION SQL_DATA_ACCESS: CONTAINS SQL 1 row in set (0.46 sec) 参考 Learn MySQL: The Basics of MySQL Stored Procedures What are the best practices in writing a sql stored procedure 存储过程 if 判断语句 ","date":"2022-04-19","img":"/images/mysql-procedure.png","permalink":"/posts/mysql-writing-procedure/","series":null,"tags":["MySQL","存储过程"],"title":"MySQL 存储过程"},{"categories":["Go","算法"],"content":"有幸搞了个 CSIG 的线上面试，感觉是“没什么感觉”，一般般吧，没过。\n前面介绍什么就不说了，我这边没突出什么工作亮点，然后就直接共享桌面写代码了。题目是编程实现一个由字符串数组表示的大数的除以 9 的计算，后面又追问了小数点后值如何保存，所以索性在线下实现也写了写。\n其实，对于这种手撕算法题还是挺反感的，有点类似于“形而上”的学习态度，”结伴编程“多少会是有些紧张，没写出来也很正常。但是换位思考一下，问题确实来源于实际，而且看别人码代码总是能看出一些面试者的风格或问题，多少可以作为出题人考查的标准。所以没对没错吧，自己也确实没有准备过算法题，一般般吧。\n自己的实现 回到这个问题，大数是指那些无法用固定长度类型保存的数值，所以需要用可变长的数组来模拟计算和存储结果。下方代码的实现逻辑比较简单，就是按位对数值进行除以 9 取商取模的操作：\n计算第 1 位数值除以 9，取商取模； 计算后续的数值，保存到一个新的 []string 作为结果返回； package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func div(ns []string, prec int) []string { result := make([]string, 0) // 被除数 dividend, _ := strconv.ParseInt(ns[0], 10, 64) // 模 var remainder int64 if dividend \u0026lt; 9 { remainder = dividend } else { result = append(result, \u0026#34;1\u0026#34;) } for _, v := range ns[1:] { addition, _ := strconv.ParseInt(v, 10, 64) dividend = remainder * 10 + addition result = append(result, fmt.Sprintf(\u0026#34;%d\u0026#34;, dividend / 9)) remainder = dividend % 9 } if prec \u0026gt; 0 { result = append(result, \u0026#34;.\u0026#34;) } for prec \u0026gt; 0 { dividend = remainder * 10 result = append(result, fmt.Sprintf(\u0026#34;%d\u0026#34;, dividend / 9)) remainder = dividend % 9 prec-- } return result } func main() { op1 := []string{\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;5\u0026#34;} prec := 6 result := div(op1, prec) for _, v := range result { fmt.Print(v) } fmt.Println() op2 := []string{\u0026#34;5\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;1\u0026#34;} prec = 7 result = div(op2, prec) for _, v := range result { fmt.Print(v) } fmt.Println() } 1371.666666 6035.6666666 math/big 包实现 Go 的 math/big 对于大数运算是有实现的，顺带也来看一看。math/big 的 Int 类型的结构如下：\ntype Int struct { neg bool // 符号 abs nat // 整数的绝对值 } type nat []Word type Word uint 所以 Int 类型的底层实现是一个 uint 切片，除法运算如下：\nfunc (z *Int) Div(x, y *Int) *Int { y_neg := y.neg // z may be an alias for y var r Int z.QuoRem(x, y, \u0026amp;r) // Step 1 if r.neg { if y_neg { z.Add(z, intOne) } else { z.Sub(z, intOne) } } return z } func (z *Int) QuoRem(x, y, r *Int) (*Int, *Int) { z.abs, r.abs = z.abs.div(r.abs, x.abs, y.abs) // Step 2 z.neg, r.neg = len(z.abs) \u0026gt; 0 \u0026amp;\u0026amp; x.neg != y.neg, len(r.abs) \u0026gt; 0 \u0026amp;\u0026amp; x.neg // 0 has no sign return z, r } func (z nat) div(z2, u, v nat) (q, r nat) { if len(v) == 0 { panic(\u0026#34;division by zero\u0026#34;) } if u.cmp(v) \u0026lt; 0 { q = z[:0] r = z2.set(u) return } if len(v) == 1 { var r2 Word q, r2 = z.divW(u, v[0]) r = z2.setWord(r2) return } q, r = z.divLarge(z2, u, v) return } 也是带了个余数 r *Int 参与计算，除法的计算使用了 Knuth\u0026rsquo;s Algorithm D。\n总结 后面查资料发现，整数除以 9 是有一定规律的，所以出题人才会这么出，这个确实没接触过，具体计算看这个吧《任意多位数除以 9：计算规律让你一辈子不忘》。\n会就会，不会就是不会； 除以 9 的规律，可以知道，但不用去记，这种 tricky 的技巧并不具备普适性； 以后尽量多看看算法题； ","date":"2022-04-15","img":"/images/logo-interview-artist-magazine-interview.jpg","permalink":"/posts/interview-csig/","series":null,"tags":["面试经","大数除法"],"title":"CSIG 线上面试"},{"categories":["数据库"],"content":"数据库是应用的数据存储中心，请求增多和数据量增大都会对数据库造成严重的影响，导致数据库服务性能偏低。所以归纳了个别优化点，后续有看到新的内容也会追加。\nRoadmap 资源 MySQL 配置检查工具 tuning-primer MySQL 配置检查工具 MySQLTuner 配置项优化 MySQL Performance Tuning Settings ","date":"2022-04-14","img":"/images/balance-resources.png","permalink":"/posts/database-performance-tuning/","series":null,"tags":["MySQL","性能优化","roadmap"],"title":"MySQL 性能调优"},{"categories":["Python","数据挖掘","统计学"],"content":"在本文开头，贴一段百科对卡方检验基本原理的介绍：\n卡方检验就是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时，卡方值就为 0，表明理论值完全符合。\n由此可见，卡方检验刻画的是一种偏离程度。那么在相关性计算中也可以利用卡方检验计算出显著性来判断两个特征是否相关。\n卡方检验 卡方检验的步骤如下：\n定义 H0 和 H1 假设； 根据领域知识定义显著性水平 $\\alpha$，一般取 0.05，表示有 5% 的容错； 计算卡方值； 计算显著性水平，小于 $\\alpha$ 则拒绝 H0 接受 H1； 离散型特征对 离散型特征对是指特征为离散值的两维向量，如帕尔默企鹅数据集中的特征对（species，island）。下面演示特征列（species，island）是否存在相关性。\n提出假设：\nH0：特征 species 和特征 island 不相关（独立）； H1：特征 species 和特征 island 相关； 频次统计 首先，根据出现的特征值对进行频次统计：\nimport numpy as np import pandas as pd # 读取数据集 # 特征 species，island 并不包含缺失值 df = pd.read_csv(\u0026#39;./dataset/penguins_size.csv\u0026#39;, na_values=[\u0026#39;NA\u0026#39;, \u0026#39;.\u0026#39;]) # 得到 species 和 island 所有的取值 # speices 值为行名，island 为列名 index = df[\u0026#39;species\u0026#39;].unique() columns = df[\u0026#39;island\u0026#39;].unique() # 初始化一个频次矩阵 count_matrix = np.zeros((index.shape[0], columns.shape[0])) # 遍历所有的 species 值 for i, species in enumerate(index): # 当 species 为某个特定值时，计算此时各 island 值出现的次数 counts = df[df[\u0026#39;species\u0026#39;]==species][\u0026#39;island\u0026#39;].value_counts() # 在对应的行和列设置次数值 for j, island in enumerate(columns): if island in counts.index: count_matrix[i][j] = counts[island] else: count_matrix[i][j] = 0 df_counts = pd.DataFrame(count_matrix, columns=columns, index=index) print(df_counts) Torgersen Biscoe Dream Adelie 52.0 44.0 56.0 Chinstrap 0.0 0.0 68.0 Gentoo 0.0 124.0 0.0 输出表示：\n当 species 为 Adelie 时，表示 Torgersen 出现 52次，Biscoe 出现 44 次，Dream 出现 56 次； 其余类似； 计算估计值 估计值的计算公式如下： $$ E_{ij} = \\frac{R_i \\times C_j} {N} $$ 其中 $R_i$ 表示第 $i$ 行的总和；$C_j$ 表示第 $j$ 列的总和；$N$ 表示所有值的总和。代码如下：\n# 行和 rows_total = df_counts.sum(axis=1).values # 列和 cols_total = df_counts.sum(axis=0).values # 总和 total = df_counts.values.sum() # 根据公式计算估计值 estimated_count_matrix = np.zeros((index.shape[0], columns.shape[0])) for i in range(index.shape[0]): for j in range(columns.shape[0]): estimated_count_matrix[i][j] = rows_total[i]*cols_total[j]/total df_estimated_counts = pd.DataFrame(estimated_count_matrix, columns=columns, index=index) print(df_estimated_counts) Torgersen Biscoe Dream Adelie 22.976744 74.232558 54.790698 Chinstrap 10.279070 33.209302 24.511628 Gentoo 18.744186 60.558140 44.697674 计算卡方值 卡方值的计算公式如下： $$ {\\chi}^2 = \\sum \\frac {(O_{ij} - E_{ij})^2} {E_{ij}} $$ 其中 $O_{ij}$ 为实际的频次值。代码如下：\ndf_chisq = np.power(df_counts - df_estimated_counts, 2) / estimated_count_matrix print(df_chisq) Torgersen Biscoe Dream Adelie 36.660955 12.312759 0.026691 Chinstrap 10.279070 33.209302 77.156789 Gentoo 18.744186 66.462901 44.697674 chi = df_chisq.values.sum() print(chi) 299.55032743148195 计算显著性 先计算自由度，公式如下： $$ degree = (r - 1) \\times (c - 1) $$ 其中 $r$ 为行数；$c$ 为列数。计算显著性的代码如下：\nfrom scipy import stats degree = (len(index) - 1) * (len(columns) - 1) pvalue = 1 - stats.chi2.cdf(x=chi, df=degree) print(pvalue) 0.0 p 值小于 0.05，所以拒绝 H0，说明特征 species 和特征 island 相关。\n完整代码 import numpy as np import pandas as pd from scipy import stats df = pd.read_csv(\u0026#39;./dataset/penguins_size.csv\u0026#39;, na_values=[\u0026#39;NA\u0026#39;, \u0026#39;.\u0026#39;]) index = df[\u0026#39;species\u0026#39;].unique() columns = df[\u0026#39;island\u0026#39;].unique() count_matrix = np.zeros((index.shape[0], columns.shape[0])) for i, species in enumerate(index): counts = df[df[\u0026#39;species\u0026#39;]==species][\u0026#39;island\u0026#39;].value_counts() for j, island in enumerate(columns): if island in counts.index: count_matrix[i][j] = counts[island] else: count_matrix[i][j] = 0 df_counts = pd.DataFrame(count_matrix, columns=columns, index=index) print(df_counts) rows_total = df_counts.sum(axis=1).values cols_total = df_counts.sum(axis=0).values total = df_counts.values.sum() estimated_count_matrix = np.zeros((index.shape[0], columns.shape[0])) for i in range(index.shape[0]): for j in range(columns.shape[0]): estimated_count_matrix[i][j] = rows_total[i]*cols_total[j]/total df_estimated_counts = pd.DataFrame(estimated_count_matrix, columns=columns, index=index) print(df_estimated_counts) df_chisq = np.power(df_counts - df_estimated_counts, 2) / estimated_count_matrix print(df_chisq) chi = df_chisq.values.sum() print(chi) degree = (len(index) - 1) * (len(columns) - 1) pvalue = 1 - stats.chi2.cdf(x=chi, df=degree) print(pvalue) 参考 STAT #3: Chi-Squared Test(卡方检验) A beginner’s guide to Chi-square test in python from scratch ","date":"2022-04-11","img":"/images/chi-square-test.webp","permalink":"/posts/python-chi-square-test/","series":null,"tags":["Chi-Square","scipy","NumPy","Pandas"],"title":"卡方检验 - 检验特征对是否相关"},{"categories":["Python","可视化","数据挖掘","机器学习","统计学"],"content":"今天导师在群里分享了一个链接 23 个优秀的机器学习训练公共数据集，看了一下，决定对帕尔默企鹅数据集（Palmer Archipelago (Antarctica) penguin data）做一些分析。\n数据集介绍 数据集是在 Kaggle 下载的，包含两个文件：\npenguins_lter.csv：原始数据文件； penguins_size.csv：特征约简后的数据文件； 本次分析使用的是简化后的数据集 penguins_size.csv。数据集共 344 个样本，特征信息如下表：\n特征 数据类型 说明 species 离散值 标签信息，值为 Adelie|Chinstrap|Gentoo 之一 island 离散值 岛屿，值为 Torgersen|Biscoe|Dream 之一 culmen_length_mm 连续值 喙的长度（mm） culmen_depth_mm 连续值 喙的高度（mm） flipper_length_mm 连续值 脚蹼长度（mm） body_mass_g 连续值 体重（克） sex 离散值 性别，值为 MALE| FEMALE 之一 数据集包含缺失数据，用 NA 表示特征值缺失，其中第 337 样本的 sex 特征值为“.”，在此也认为是缺失值。\n使用 pandas 查看数据集的统计信息：\nimport pandas as pd df = pd.read_csv(\u0026#39;./dataset/penguins_size.csv\u0026#39;, na_values=[\u0026#39;NA\u0026#39;, \u0026#39;.\u0026#39;]) print(df.describe()) culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g count 342.000000 342.000000 342.000000 342.000000 mean 43.921930 17.151170 200.915205 4201.754386 std 5.459584 1.974793 14.061714 801.954536 min 32.100000 13.100000 172.000000 2700.000000 25% 39.225000 15.600000 190.000000 3550.000000 50% 44.450000 17.300000 197.000000 4050.000000 75% 48.500000 18.700000 213.000000 4750.000000 max 59.600000 21.500000 231.000000 6300.000000 显然，统计信息中并不包含离散特征。\n缺失数据 对数据集的缺失数据进行一次统计。\n# 打印出不完整样本在数据集中的下标 print(df.isna().any(axis=1).where(lambda not_exist: not_exist).dropna().index) Int64Index([3, 8, 9, 10, 11, 47, 246, 286, 324, 336, 339], dtype=\u0026#39;int64\u0026#39;) # 打印出缺失特征值个数统计 print(df.isna().astype(int, False).sum()) species 0 island 0 culmen_length_mm 2 culmen_depth_mm 2 flipper_length_mm 2 body_mass_g 2 sex 11 dtype: int64 使用 missingno 包来查看缺失数据分布：\nimport missingno as msno msno.matrix(df) 综上，得到以下结论：\n存在两个样本的 culmen_length_mm、culmen_depth_mm、flipper_length_mm、body_mass_g 和 sex 特征值缺失，编号分别为 3 和 339（以 0 为开始计数）； 缺失值主要集中在 sex 特征中，共有 11 个样本存在缺失； 预测企鹅性别 预测企鹅性别中，sex 为目标特征，所以先计算连续型特征与目标特征的 Point-biserial 相关系数 $r_{pb} (r_{pb} \\in [0, 1])$。\nfrom scipy import stats # 剔除数据集中不完整样本 df_com = df.drop([3, 8, 9, 10, 11, 47, 246, 286, 324, 336, 339], inplace=False) # 计算 Point-biserial 相关系数 series_sex = df_com.loc[:,\u0026#39;sex\u0026#39;].copy() series_sex[series_sex == \u0026#39;MALE\u0026#39;] = 0 series_sex[series_sex == \u0026#39;FEMALE\u0026#39;] = 1 print(\u0026#39;Point-biserial\u0026#39;) for column in df_com.columns[2:6]: cor, pvalue = stats.pointbiserialr(series_sex, df_com[column]) print(column, \u0026#34;\u0026lt;=\u0026gt;\u0026#34;, \u0026#39;sex\u0026#39;) print(\u0026#34;correlation: \u0026#34;, cor) print(\u0026#34;pvalue: \u0026#34;, pvalue) print() Point-biserial culmen_length_mm \u0026lt;=\u0026gt; sex correlation: -0.34407778223748564 pvalue: 1.0942555387200282e-10 culmen_depth_mm \u0026lt;=\u0026gt; sex correlation: -0.37267328821677664 pvalue: 2.0664103457552388e-12 flipper_length_mm \u0026lt;=\u0026gt; sex correlation: -0.2551688758106061 pvalue: 2.3910970925543724e-06 body_mass_g \u0026lt;=\u0026gt; sex correlation: -0.4249869909039952 pvalue: 4.897246751596804e-16 $r_{pb}$ 值为负，表示当目标特征 sex 为 0，特征（culmen_length_mm、culmen_depth_mm、flipper_length_mm、body_mass_g）趋向高于 sex 为 1 时对应的值。同时，4 个 p 值均小于 0.05，所以在统计意义上是显著的。\n然后计算离散型特征与目标特征的相关性，使用卡方检测进行判断，计算过程可看《卡方检验 - 检验特征对是否相关》。\nimport numpy as np from scipy import stats def chi_significance(x, y): \u0026#34;\u0026#34;\u0026#34;计算离散特征对卡方检验的显著性\u0026#34;\u0026#34;\u0026#34; index = x.unique() columns = y.unique() r, c = len(index), len(columns) count_matrix = np.zeros((r, c)) for i in range(r): counts = y[x==index[i]].value_counts() for j in range(c): if columns[j] in counts.index: count_matrix[i][j] = counts[columns[j]] rows_total = np.sum(count_matrix, axis=1) cols_total = np.sum(count_matrix, axis=0) total = count_matrix.sum() estimated_count_matrix = np.zeros((r, c)) for i in range(r): for j in range(c): estimated_count_matrix[i][j] = rows_total[i]*cols_total[j]/total chi = (np.power(count_matrix - estimated_count_matrix, 2) / estimated_count_matrix).sum() degree = (r - 1) * (c - 1) return 1 - stats.chi2.cdf(x=chi, df=degree) for column in [\u0026#39;species\u0026#39;, \u0026#39;island\u0026#39;]: print(column, \u0026#34;\u0026lt;=\u0026gt;\u0026#34;, \u0026#34;sex\u0026#34;) print(\u0026#34;pvalue: \u0026#34;, chi_significance(df_com[column], df_com[\u0026#39;sex\u0026#39;])) species \u0026lt;=\u0026gt; sex pvalue: 0.9759893689765846 island \u0026lt;=\u0026gt; sex pvalue: 0.971611229281065 从两对特征的 p 值可知，特征 species、island 与目标特征 sex 的相关性并不显著，所以排除相关。\n构建预测模型 从前文的相关性计算可知，目标特征 sex 与特征 species、island 不相关，但是与特征 culmen_length_mm、culmen_depth_mm、flipper_length_mm、body_mass_g 的相关性显著，所以在构建预测模型中不考虑特征 species 和 island。\n下面使用支持向量机（Support Vector Machine，SVM）对未知目标特征进行预测，采用 10-Fold 进行交叉验证：\nfrom sklearn.svm import SVC from sklearn.pipeline import make_pipeline from sklearn.preprocessing import StandardScaler from sklearn.model_selection import KFold from sklearn.model_selection import cross_val_score scaler = StandardScaler() scaler.fit(X) cv = KFold(n_splits=10, random_state=1, shuffle=True) clf = make_pipeline(scaler, SVC( gamma=\u0026#39;scale\u0026#39;, C=2., kernel=\u0026#39;rbf\u0026#39;, random_state=1, verbose=True, tol=0.00001 )) scores = cross_val_score(clf, X, y, scoring=\u0026#39;accuracy\u0026#39;, cv=cv, n_jobs=-1) print(\u0026#39;accuracy: %.3f (%.3f)\u0026#39; % (np.mean(scores), np.std(scores))) accuracy: 0.904 (0.047) clf.fit(X, y) test_X = df.iloc[[8, 9, 10, 11, 47, 246, 286, 324, 336],:][[\u0026#39;culmen_length_mm\u0026#39;, \u0026#39;culmen_depth_mm\u0026#39;, \u0026#39;flipper_length_mm\u0026#39;, \u0026#39;body_mass_g\u0026#39;]].values print(clf.predict(scaler.transform(test_X))) [\u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39; \u0026#39;MALE\u0026#39;] 上述完成了以下几件事：\n将特征 culmen_length_mm、culmen_depth_mm、flipper_length_mm、body_mass_g 作为输入，特征 sex 作为预测值； 对输入做标准化处理； 采用 10-Fold 交叉验证，输出平均准确率为 0.904，标准差为 0.047； 训练模型； 预测目标特征； 预测结果如下表：\n编号 sex 预测值 8 MALE 9 MALE 10 MALE 11 MALE 47 MALE 246 MALE 286 MALE 324 MALE 336 MALE 从预测结果来看，怎么都是 MALE，本能地选择不相信模型结果 -|_|-。\n完整代码 import pandas as pd import missingno as msno from scipy import stats import numpy as np from sklearn.svm import SVC from sklearn.pipeline import make_pipeline from sklearn.preprocessing import StandardScaler from sklearn.model_selection import KFold from sklearn.model_selection import cross_val_score df = pd.read_csv(\u0026#39;./dataset/penguins_size.csv\u0026#39;, na_values=[\u0026#39;NA\u0026#39;, \u0026#39;.\u0026#39;]) print(df.describe()) # 打印出不完整样本在数据集中的下标 print(df.isna().any(axis=1).where(lambda not_exist: not_exist).dropna().index) # 打印出缺失特征值个数统计 print(df.isna().astype(int, False).sum()) msno.matrix(df) # 剔除数据集中不完整样本 df_com = df.drop([3, 8, 9, 10, 11, 47, 246, 286, 324, 336, 339], inplace=False) # 计算 Point-biserial 相关系数 series_sex = df_com.loc[:,\u0026#39;sex\u0026#39;].copy() series_sex[series_sex == \u0026#39;MALE\u0026#39;] = 0 series_sex[series_sex == \u0026#39;FEMALE\u0026#39;] = 1 print(\u0026#39;Point-biserial\u0026#39;) for column in df_com.columns[2:6]: cor, pvalue = stats.pointbiserialr(series_sex, df_com[column]) print(column, \u0026#34;\u0026lt;=\u0026gt;\u0026#34;, \u0026#39;sex\u0026#39;) print(\u0026#34;correlation: \u0026#34;, cor) print(\u0026#34;pvalue: \u0026#34;, pvalue) print() def chi_significance(x, y): \u0026#34;\u0026#34;\u0026#34;计算离散特征对卡方检验的显著性\u0026#34;\u0026#34;\u0026#34; index = x.unique() columns = y.unique() r, c = len(index), len(columns) count_matrix = np.zeros((r, c)) for i in range(r): counts = y[x==index[i]].value_counts() for j in range(c): if columns[j] in counts.index: count_matrix[i][j] = counts[columns[j]] rows_total = np.sum(count_matrix, axis=1) cols_total = np.sum(count_matrix, axis=0) total = count_matrix.sum() estimated_count_matrix = np.zeros((r, c)) for i in range(r): for j in range(c): estimated_count_matrix[i][j] = rows_total[i]*cols_total[j]/total chi = (np.power(count_matrix - estimated_count_matrix, 2) / estimated_count_matrix).sum() degree = (r - 1) * (c - 1) return 1 - stats.chi2.cdf(x=chi, df=degree) for column in [\u0026#39;species\u0026#39;, \u0026#39;island\u0026#39;]: print(column, \u0026#34;\u0026lt;=\u0026gt;\u0026#34;, \u0026#34;sex\u0026#34;) print(\u0026#34;pvalue: \u0026#34;, chi_significance(df_com[column], df_com[\u0026#39;sex\u0026#39;])) X, y = df_com[[\u0026#39;culmen_length_mm\u0026#39;, \u0026#39;culmen_depth_mm\u0026#39;, \u0026#39;flipper_length_mm\u0026#39;, \u0026#39;body_mass_g\u0026#39;]].values, df_com[\u0026#39;sex\u0026#39;].values scaler = StandardScaler() scaler.fit(X) cv = KFold(n_splits=10, random_state=1, shuffle=True) clf = make_pipeline(scaler, SVC( gamma=\u0026#39;scale\u0026#39;, C=2., kernel=\u0026#39;rbf\u0026#39;, random_state=1, verbose=True, tol=0.00001 )) scores = cross_val_score(clf, X, y, scoring=\u0026#39;accuracy\u0026#39;, cv=cv, n_jobs=-1) print(\u0026#39;accuracy: %.3f (%.3f)\u0026#39; % (np.mean(scores), np.std(scores))) clf.fit(X, y) test_X = df.iloc[[8, 9, 10, 11, 47, 246, 286, 324, 336],:][[\u0026#39;culmen_length_mm\u0026#39;, \u0026#39;culmen_depth_mm\u0026#39;, \u0026#39;flipper_length_mm\u0026#39;, \u0026#39;body_mass_g\u0026#39;]].values print(clf.predict(scaler.transform(test_X))) 总结 离散型特征与连续型特征的相关性可以通过 Point-biserial 相关系数进行衡量； 根据卡方检验判断离散型特征间是否相关； 预测模型为 SVM，采用 10-Fold 交叉验证的方式，预测出目标特征 sex； 参考 palmerpenguins 特征间相关系数.pdf sklearn.svm.SVC ","date":"2022-04-11","img":"/images/Palmer-Archipelago-Antarctica-penguin-data.webp","permalink":"/posts/python-palmer-archipelago-penguin-testing/","series":null,"tags":["Matplotlib","sklearn"],"title":"帕尔默企鹅数据集测试"},{"categories":["Go"],"content":" 在网络或 I/O 连接中，可以使用 net/rpc 包实现对一个对象的导出方法的调用，即远程过程调用（Remote Procedure Call，RPC）。通过向 RPC 服务注册一个对象，使其可被远程调用，进而实现一些复杂的业务逻辑。\n项目结构 示例项目的结构如下：\nclient - client.go - json_client.go models - greeting.go server - json_server.go - server.go 注册服务 一个可被远程调用的方法须满足以下条件：\n方法所属结构是公开的； 方法是分开的； 方法的参数类型是分开的； 方法带两个参数，第 2 个参数为指针； 方法返回值为 error 类型； 如下，在 models/greeting.go 中定义了一个服务：\ntype GreetingArg struct { Name string } type GreetingReply struct { Message string } type Greeting struct {} // SayHello 方法满足上述条件 func (Greeting) SayHello(arg GreetingArg, reply *GreetingReply) error { reply.Message = \u0026#34;hello, \u0026#34; + arg.Name return nil } 现在，在 server/server.go 中编写服务器端代码：\npackage main import ( \u0026#34;gorpc/models\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc\u0026#34; ) func main() { server := rpc.NewServer() if err := server.Register(\u0026amp;models.Greeting{}); err != nil { log.Fatalln(err) } listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:2022\u0026#34;) if err != nil { log.Fatalln(err) } defer listener.Close() server.Accept(listener) } 服务器端注册了 Greeting 服务并监听了 2022 端口，等待客户端连接。在客户端 client/client.go 的代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;gorpc/models\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc\u0026#34; ) func main() { conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:2022\u0026#34;) if err != nil { log.Fatalln(err) } defer conn.Close() client := rpc.NewClient(conn) greetingArg := models.GreetingArg{Name: \u0026#34;a2htray\u0026#34;} greetingReply := models.GreetingReply{} if err = client.Call(\u0026#34;Greeting.SayHello\u0026#34;, greetingArg, \u0026amp;greetingReply); err != nil { log.Fatalln(err) } fmt.Println(greetingReply.Message) } 上述代码完成了以下几件事：\n使用 net.Dial 连接 2022 端口； 在 TCP 连接之上，使用 rpc.NewClient 创建一个 RPC 客户端； 使用 client.Call 远程调用 Greeting 的 SayHello 方法； 返回的值体现在 greetingReply 变量中； jsonrpc net/rpc 的传输数据使用 encoding/gob 进行编码解码，并且不支持跨语言调用，即只能使用 Go 编写的程序进行调用。encoding/gob 编码解码在源码中有给出：\n// rpc/server.go func (server *Server) ServeConn(conn io.ReadWriteCloser) { buf := bufio.NewWriter(conn) srv := \u0026amp;gobServerCodec{ rwc: conn, dec: gob.NewDecoder(conn), enc: gob.NewEncoder(buf), encBuf: buf, } server.ServeCodec(srv) } 除了 net/rpc，还可以使用 net/rpc/jsonrpc 实现 RPC 功能，该方式支持跨语言调用。新建 server/json_server.go，代码如下：\npackage main import ( \u0026#34;gorpc/models\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; ) func main() { err := rpc.Register(\u0026amp;models.Greeting{}) if err != nil { log.Fatalln(err) } listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:2023\u0026#34;) if err != nil { log.Fatalln(err) } defer listener.Close() for { conn, err := listener.Accept() if err != nil { log.Fatalln(err) } go jsonrpc.ServeConn(conn) } } 上述代码完成了以下几件事：\n在 RPC 服务上注册了 Greeting； 监听了 2023 端口，使用 for 循环接受客户端连续； 对每一个连接使用协程进行处理； 新建 client/json_client.go，代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;gorpc/models\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; ) func main() { client, err := jsonrpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:2023\u0026#34;) if err != nil { log.Fatalln(err) } defer client.Close() greetingArg := models.GreetingArg{Name: \u0026#34;a2htray\u0026#34;} greetingReply := models.GreetingReply{} if err = client.Call(\u0026#34;Greeting.SayHello\u0026#34;, greetingArg, \u0026amp;greetingReply); err != nil { log.Fatalln(err) } fmt.Println(greetingReply.Message) } 上述代码完成了以下几件事：\n使用 jsonrpc.Dial 连接到端口 2023； 使用 client.Call 调用了 Greeting.SayHello 方法； 打印输出返回信息； rpc 与 jsonrpc 的区别 Go 内置的 rpc 与 jsonrpc 的区别在于：\nrpc 使用 gob 编码解码，jsonrpc 使用 json 编码解码； rpc 不支持跨语言调用，jsonrpc 支持跨语言调用； jsonrpc 在构建在 rpc 之上使用不同数据交换格式的 RPC 服务； 参考 golang下的rpc框架jsonrpc理解和使用示例 golang实现RPC的几种方式 ","date":"2022-04-10","img":"/images/operating-system-remote-procedure-call-1.png","permalink":"/posts/go-built-in-rpc-package/","series":null,"tags":["RPC","jsonrpc"],"title":"Go 内置的 RPC 包"},{"categories":["Go"],"content":"Go 1.18 在 2022 年 3 月 15 日发布，根据团队的博文介绍，1.18 版本包含 4 个重要特性：\n泛型； fuzzing； 工作空间； 20% 的性能提升； 泛型 泛型是一种无须关心具体操作类型的编码方式，它将逻辑实现与具体类型解耦，体现在程序中的 3 个地方：\n函数和类型的类型参数； 用于指定类型的集合； 类型推断，不需要显式指定类型； 本节是官方泛型教程的截取或修改内容，详细请查看此处。\n不同类型求和函数 package main import \u0026#34;fmt\u0026#34; // sumInts 计算 int slice 的和 func sumInts(values []int) int { var total int for _, value := range values { total += value } return total } // sumFloat32s 计算 float32 slice 的和 func sumFloat32s(values []float32) float32 { var total float32 for _, value := range values { total += value } return total } // sum 计算的 slice 元素可以是 int 类型或 float32 类型 func sum[Element int | float32](values []Element) Element { var total Element for _, value := range values { total += value } return total } func main() { intValues := []int{1, 2, 3} float32Values := []float32{4, 5, 6} fmt.Println(sumInts(intValues)) fmt.Println(sumFloat32s(float32Values)) // sum(intValues) 等价于 sum[int](intValues) fmt.Println(sum(intValues)) fmt.Println(sum[int](intValues)) // sum(float32Values) 等价于 sum[float32](float32Values) fmt.Println(sum(float32Values)) fmt.Println(sum[float32](float32Values)) } 类型约束 示例 1：\npackage main import \u0026#34;fmt\u0026#34; // Number 类型约束，限制 Number 可以是 int 或 float32 type Number interface { int | float32 } // sum 求和 // [Element Number] 限定 Element 需要符合 Number 类型约束 // 即 Element 只能是 int 或 float32 func sum[Element Number](values []Element) Element { var total Element for _, value := range values { total += value } return total } func main() { intValues := []int{1, 2, 3} float32Values := []float32{4, 5, 6} fmt.Println(sum(intValues)) fmt.Println(sum(float32Values)) } 示例 2：\npackage main import \u0026#34;fmt\u0026#34; // Flag 底层类型为 int type Flag int const ( Flag_A Flag = iota Flag_B Flag_C ) // Number 类型约束 // ~ 操作符表示底层类型为 int 的类型也符合 type Number interface { float32 | ~int } func sum[Element Number](values []Element) Element { var total Element for _, value := range values { total += value } return total } func main() { flagValues := []Flag{ Flag_A, Flag_B, Flag_C, } float32Values := []float32{4, 5, 6} fmt.Println(sum(flagValues)) fmt.Println(sum(float32Values)) } 示例 3：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) type Flag int func (f Flag) String() string { return strconv.Itoa(int(f)) } const Flag_A Flag = iota // Number 包含了方法的类型约束 // 指定了 Number 类型的底层类型是 int 并实现了 String() string 方法 type Number interface { ~int String() string } func PrintNumber[V Number](number V) { fmt.Println(number.String()) } func main() { PrintNumber(Flag_A) } 示例 4：\npackage main import \u0026#34;fmt\u0026#34; type Flag int const ( Flag_A Flag = iota ) // PrintNumber 使用 ~ 操作符，定义类型底层实现 func PrintNumber[Number ~int](value Number) { fmt.Println(value) } func main() { PrintNumber(Flag_A) PrintNumber(1) } 总结 使用泛型可以减少相同逻辑（不同具体类型）的代码量； 使用 ~ 操作符指定底层类型； 类型约束中可以声明方法； ","date":"2022-04-10","img":"/images/golang-1.18-release.png","permalink":"/posts/go-1.18-release-features/","series":null,"tags":["Go 1.18"],"title":"Go 1.18 特性 - 泛型"},{"categories":["数据库"],"content":"Redis 服务器中与服务相关的命令，集群的配置过程可参考《Redis 集群配置过程》。\nCLUSTER nodes：显示集群主从关系 127.0.0.1:6380\u0026gt; CLUSTER nodes ac3f5aaae24bcd142b8303abedc5f57187ebc20e 127.0.0.1:6385@16385 slave 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c 0 1649562125672 2 connected 9242c455757da4ad2f5aa818d75d12cde38231c2 127.0.0.1:6383@16383 slave 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e 0 1649562126000 3 connected 5cc9ed2602986aeffaf9997f3c38c675092a4810 127.0.0.1:6384@16384 slave 92a1fd50a1c8dc003e905ac828b0db64773d6b66 0 1649562126674 1 connected 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e 127.0.0.1:6382@16382 master - 0 1649562124670 3 connected 10923-16383 92a1fd50a1c8dc003e905ac828b0db64773d6b66 127.0.0.1:6380@16380 myself,master - 0 1649562122000 1 connected 0-5460 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c 127.0.0.1:6381@16381 master - 0 1649562125000 2 connected 5461-10922 CLUSTER slots：显示哈希槽分配信息 127.0.0.1:6380\u0026gt; CLUSTER slots 1) 1) (integer) 0 2) (integer) 5460 3) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6380 3) \u0026#34;92a1fd50a1c8dc003e905ac828b0db64773d6b66\u0026#34; 4) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6384 3) \u0026#34;5cc9ed2602986aeffaf9997f3c38c675092a4810\u0026#34; 2) 1) (integer) 5461 2) (integer) 10922 3) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6381 3) \u0026#34;82ac1fe6c0af98d252ea96d4e84e7315eff31f8c\u0026#34; 4) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6385 3) \u0026#34;ac3f5aaae24bcd142b8303abedc5f57187ebc20e\u0026#34; 3) 1) (integer) 10923 2) (integer) 16383 3) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6382 3) \u0026#34;9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e\u0026#34; 4) 1) \u0026#34;127.0.0.1\u0026#34; 2) (integer) 6383 3) \u0026#34;9242c455757da4ad2f5aa818d75d12cde38231c2\u0026#34; CLUSTER keyslot：显示 key 对应的哈希槽 127.0.0.1:6380\u0026gt; CLUSTER keyslot user:1:name (integer) 12440 ","date":"2022-04-10","img":"/images/redis-cluster.png","permalink":"/doc-redis-commands/cluster-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"集群相关"},{"categories":["Go"],"content":"Protocol Buffer 的介绍与语法已在文章《Protocol Buffer 语法》给出，本文则演示了 Protocol Buffer 如何减少了传输数据的大小。\n使用 protoc 命令生成 pb 代码文件 首先新建 proto/user.proto 文件来定义数据结构，其内容如下：\nsyntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;/model\u0026#34;; message User { string name = 1; enum Gender { MALE = 0; FEMALE = 1; }; Gender gender = 2; } 然后，执行如下命令生成源代码文件：\nprotoc --go_out=. proto\\user.proto 主程序 main 主程序的作用是比较不同 User 结构序列化后的字节数据的大小。首先，新建 main.go 文件并定义一个 User 结构，如下：\ntype User struct { Name string Gender int32 } 主程序的逻辑如下：\nfunc main() { user := \u0026amp;User{ Name: \u0026#34;a2htray\u0026#34;, Gender: 1, } data, err = json.Marshal(user) fmt.Println(data, err) } 执行输出如下：\n[123 34 78 97 109 101 34 58 34 97 50 104 116 114 97 121 34 44 34 71 101 110 100 101 114 34 58 49 125] 29 \u0026lt;nil\u0026gt; 从输出可知，自定义的 User 的值序列化后的字节长度为 29。\n接着，使用 Protocol Buffer 生成的 User 结构并使用 proto.Marshal 方法对值进行序列化，代码如下：\nfunc main() { userPB := \u0026amp;model.User{ Name: \u0026#34;a2htray\u0026#34;, Gender: 1, } data, err = proto.Marshal(userPB) fmt.Println(data, len(data), err) } 执行输出如下：\n[10 7 97 50 104 116 114 97 121 16 1] 11 \u0026lt;nil\u0026gt; 从输出可知，Protocol Buffer 生成的 User 类型的值序列化后的字节长度为 11。\n综上，分别使用 JSON 和 Protocol Buffer 序列化相同的数据信息，使用 Protocol Buffer 得到的字节长度要更小，更有得于在网络中的传输。\n完整代码 演示完成后，当前项目的目录结构如下：\nmodel - user.pb.go # 通过 protoc 命令生成 proto - user.proto # 定义数据结构 main.go main.go 的完整内容如下：\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;./model\u0026#34; \u0026#34;google.golang.org/protobuf/proto\u0026#34; ) type User struct { Name string Gender int32 } func main() { user := \u0026amp;User{ Name: \u0026#34;a2htray\u0026#34;, Gender: 1, } data, err := json.Marshal(user) fmt.Println(data, len(data), err) userPB := \u0026amp;model.User{ Name: \u0026#34;a2htray\u0026#34;, Gender: 1, } data, err = proto.Marshal(userPB) fmt.Println(data, len(data), err) } 总结 Protocol Buffer 序列化的数据量更小； ","date":"2022-04-09","img":"","permalink":"/posts/protocol-buffer-reduce-data-size/","series":null,"tags":["protocol buffer"],"title":"Protocol Buffer 减少传输数据的大小"},{"categories":["Go"],"content":"Protocol Buffer（Protobuf） 是一种高效的数据结构序列化的机制，同时也是一种结构化数据的存储格式。\n序列化与反序列化\n序列化：将数据结构或对象转换成二进制串的过程； 反序列化：将序列化后的二进制串转换成数据结构或对象的过程； 语法 /* * 语法 */ /* * 指定 Protobuf 解析使用的版本，可以是 proto3 或 proto2 */ syntax = \u0026#34;proto3\u0026#34;; /* * message 定义中的每一个字段都有一个唯一标识，该标识用于在二进制格式中识别字段 * 字段的标识一旦使用就不要进行修改 * 当标识为 1 到 15 时，使用一个字节进行编码，字节信息中包含字段的标识以及类型 * 当标识为 16 到 2047 时，使用两个字节进行编码 * Field numbers in the range 16 through 2047 take two bytes. So you should reserve the numbers 1 through 15 for very frequently occurring message elements. * 在编码的过程中，标识使用应当留有余地，便于将来扩展 * 标识最小的值是 1，最大的值为 2^29-1 * 不能使用的标识为 19000 到 19999 * 不能再使用已经被 reserved 的标识 */ /* 定义 message 的语法： message ${MessageName} { ${Scalar Value Type} ${FieldName1} = ${Tag Number1}; . . . ${Scalar Value Type} ${FieldNameN} = ${Tag NumberN}; } */ message MessageTypes { /* * 标量值类型 */ string stringType = 1; // 字符串可以是 UTF-8 编码，也可以是一个 7 比特的 ASCII 字符，默认为“” // 数值类型，默认为 0 int32 int32Type = 2; // 使用变量长度进行编码，如果是负数，请使用 sint32 int64 int64Type = 3; // 使用变量长度进行编码，如果是负数，请使用 sint64 uint32 uInt32Type = 4; // 使用变量长度进行编码 uint64 uInt64Type = 5; // 使用变量长度进行编码 sint32 sInt32Type = 6; // 使用变量长度进行编码，处理负数更高效 sint64 sInt64Type = 7; // 使用变量长度进行编码，处理负数更高效 fixed32 fixed32Type = 8; // 变量总是占 4 个字节，当值大于 2^28 时，比使用 uint32 更有效率 fixed64 fixed64Type = 9; // 变量总是占 8 个字节，当值大于 2^56 时，比使用 uint64 更有效率 sfixed32 sfixed32Type = 10; // 变量总是占 4 个字节 sfixed64 sfixed64Type = 11; // 变量总是占 8 个字节 bool boolType = 12; // 布尔类型，默认为 false bytes bytesType = 13; // 可包含任意长度的字节数组，默认为长度为 0 的字节数组 double doubleType = 14; float floatType = 15; enum Week { UNDEFINED = 0; // 第 1 个值 SUNDAY = 1; MONDAY = 2; TUESDAY = 3; WEDNESDAY = 4; THURSDAY = 5; FRIDAY = 6; SATURDAY = 7; } Week wkDayType = 16; /* * 定义标量值类型的集合 * Syntax: repeated ${ScalarType} ${name} = TagValue */ repeated string listOfString = 17; // List[String] } /* * 在其它 message 中使用已定义的 message */ message Person { string fname = 1; string sname = 2; } message City { Person p = 1; } /* * 嵌套的 message 定义 */ message NestedMessages { message FirstLevelNestedMessage { string firstString = 1; message SecondLevelNestedMessage { string secondString = 2; } } FirstLevelNestedMessage msg = 1; FirstLevelNestedMessage.SecondLevelNestedMessage msg2 = 2; } /* * .proto 文件的引入 */ // one.proto // message One { // string oneMsg = 1; // } // two.proto // import \u0026#34;myproject/one.proto\u0026#34; // message Two { // string twoMsg = 2; // } /* * 高级知识点 */ /* * message 发生改变时，永远不要修改或使用已经删除字段的标识 */ /* * 使用 reserved 保留已删除的标识或字段名 */ message ReservedMessage { reserved 0, 1, 2, 3 to 10; // 这里的标识不可再使用 reserved \u0026#34;firstMsg\u0026#34;, \u0026#34;secondMsg\u0026#34;, \u0026#34;thirdMsg\u0026#34;; // 这里的字段名不可再使用 } /* * 引用其它文件中定义的 message */ import \u0026#34;google/protobuf/any.proto\u0026#34;; message AnySampleMessage { repeated google.protobuf.Any.details = 1; } /* * OneOf * 相同于 union，只能是其中一个 * 使用 oneof 的 message 不能被 repeated */ message OneOfMessage { oneof msg { string fname = 1; string sname = 2; }; } /* * Maps * map 字段不能被 repeated */ message MessageWithMaps { map\u0026lt;string, string\u0026gt; mapOfMessages = 1; } /* * Packages * 声明一个包名，防止同名的 message * 语法: package ${packageName}; 访问方式 ${packageName}.${messageName} = ${tagNumber}; */ /* * 在 RPC 系统中使用，其中可以定义方法 */ message SearchRequest { string queryString = 1; } message SearchResponse { string queryResponse = 1; } service SearchService { rpc Search (SearchRequest) returns (SearchResponse); } 数据类型 Protobuf 内置的数据类型以及在 Go 中对应的数据类型：\nProtobuf Go double float64 float float32 int32 int32 int64 int64 uint32 uint32 uint64 uint64 sint32 int32 sint64 int64 fixed32 uint32 fixed64 uint64 sfixed64 int64 bool bool string string bytes []byte 书写规范 代码编写要遵循某种特定的规则，如 Python 的 PEP8，.proto 文件的内容也应该按照统一的格式，这样才能规范团队编码风格，易于他人理解。\nmessage 采用驼峰命名法且首字母大写； message UserConfig {} // 符合 message user_config {} // 不符合 字段名采用下划线分隔命名法且均小写； message Product { string fasta_origin = 1; } // 符合 message Product { string FastaOrigin = 1 } // 不符合 枚举型命名格式与 message 相同，枚举值全部大写，并且用下划线分隔命名法； enum Week { MY_MONDAY = 0 } // 符合 enum Week { MyMonday = 0 } // 不符合 service 和方法名都采用驼峰命名法，并且首字母大写； service Greeter { rpc SayHello(HelloRequest) returns (HelloReply); } // 符合 service Greeter { rpc say_hello(HelloRequest) returns (HelloReply); } // 不符合 与 JSON 的区别 Protobuf JSON 由 Google 开发、用于序列化和反序列化结构化数据的高效编码方式 轻量型的数据交换格式 可自定义规则、方法的消息格式 仅仅只是一种消息格式 二进制格式 文本格式 支持的语言有限 绝大部分语言都支持 微服务间数据传输的格式 WEB 应用与服务器间的传输格式 相同数据序列化后的数据量较小 相同数据序列化后的数据量较大 参考 https://learnxinyminutes.com/docs/protocol-buffer-3/ https://zhuanlan.zhihu.com/p/95869546 ","date":"2022-04-08","img":"","permalink":"/posts/protocol-buffer-syntax/","series":null,"tags":["protocol buffer"],"title":"Protocol Buffer 语法"},{"categories":["数据库","运维"],"content":"Redis 集群是基于“主从复制”特性之上的分布式 Redis 版本，可提供高并发、高性能、高可用的数据库服务。Redis 集群突破了单台服务器的内存局限，集群中的每一个节点都可以存储数据，同时维护着 \u0026ldquo;key-node\u0026rdquo; 的映射表。本文记录了 3 主 3 从的 Redis 集群的配置过程，主要内容包括：\nRedis 集群的配置过程； 集群相关命令； Go 存取集群数据； 环境信息\n$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.2 LTS Release: 20.04 Codename: focal $ redis-server -v Redis server v=6.2.6 sha=00000000:0 malloc=jemalloc-5.1.0 bits=64 build=9c9e426e2f96cc51 配置过程 配置文件 3 主使用的端口分别为 6380、6381 和 6382，3 从使用的端口为 6383、6384 和 6385。创建配置文件以及工作目录：\n$ mkdir /etc/redis/cluster $ chown redis.redis /etc/redis/cluster $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6380.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6381.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6382.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6383.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6384.conf $ cp -a /etc/redis/redis.conf /etc/redis/cluster/redis-6385.conf 各配置文件的修改内容如下：\n# /etc/redis/cluster/redis-6380.conf port 6380 cluster-enabled yes pidfile /run/redis/redis-server-6380.pid logfile /var/log/redis/redis-server-6380.log dbfilename dump-6380.rdb cluster-config-file nodes-6380.conf # /etc/redis/cluster/redis-6381.conf port 6381 cluster-enabled yes pidfile /run/redis/redis-server-6381.pid logfile /var/log/redis/redis-server-6381.log dbfilename dump-6381.rdb cluster-config-file nodes-6381.conf # /etc/redis/cluster/redis-6382.conf port 6382 cluster-enabled yes pidfile /run/redis/redis-server-6382.pid logfile /var/log/redis/redis-server-6382.log dbfilename dump-6382.rdb cluster-config-file nodes-6382.conf # /etc/redis/cluster/redis-6383.conf port 6383 cluster-enabled yes pidfile /run/redis/redis-server-6383.pid logfile /var/log/redis/redis-server-6383.log dbfilename dump-6383.rdb cluster-config-file nodes-6383.conf # /etc/redis/cluster/redis-6384.conf port 6384 cluster-enabled yes pidfile /run/redis/redis-server-6384.pid logfile /var/log/redis/redis-server-6384.log dbfilename dump-16381.rdb cluster-config-file nodes-6384.conf 启动脚本 编写 redis-cluster.sh 脚本，记得 chmod a+x redis-cluster.sh 一下：\n#!/bin/bash if [ \u0026#34;$1\u0026#34; == \u0026#34;start\u0026#34; ]; then redis-server /etc/redis/cluster/redis-6380.conf redis-server /etc/redis/cluster/redis-6381.conf redis-server /etc/redis/cluster/redis-6382.conf redis-server /etc/redis/cluster/redis-6383.conf redis-server /etc/redis/cluster/redis-6384.conf redis-server /etc/redis/cluster/redis-6385.conf elif [ \u0026#34;$1\u0026#34; == \u0026#34;stop\u0026#34; ]; then redis-cli -p 6380 shutdown redis-cli -p 6381 shutdown redis-cli -p 6382 shutdown redis-cli -p 6383 shutdown redis-cli -p 6384 shutdown redis-cli -p 6385 shutdown else echo \u0026#34;please, pass an action [start|stop]\u0026#34; fi 启动所有 Redis 节点：\n$ ./redis-cluster.sh start 验证集群节点是否启动：\nps -ef | grep redis-server root 4025397 1 0 11:10 ? 00:00:00 redis-server *:6380 [cluster] root 4025405 1 0 11:10 ? 00:00:00 redis-server *:6381 [cluster] root 4025411 1 0 11:10 ? 00:00:00 redis-server *:6382 [cluster] root 4025417 1 0 11:10 ? 00:00:00 redis-server *:6383 [cluster] root 4025423 1 0 11:10 ? 00:00:00 redis-server *:6384 [cluster] root 4025429 1 0 11:10 ? 00:00:00 redis-server *:6385 [cluster] 配置集群 使用 redis-cli 命令配置集群：\n$ redis-cli --cluster create 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385 --cluster-replicas 1 \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 6 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 Adding replica 127.0.0.1:6384 to 127.0.0.1:6380 Adding replica 127.0.0.1:6385 to 127.0.0.1:6381 Adding replica 127.0.0.1:6383 to 127.0.0.1:6382 \u0026gt;\u0026gt;\u0026gt; Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: 92a1fd50a1c8dc003e905ac828b0db64773d6b66 127.0.0.1:6380 slots:[0-5460] (5461 slots) master M: 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c 127.0.0.1:6381 slots:[5461-10922] (5462 slots) master M: 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e 127.0.0.1:6382 slots:[10923-16383] (5461 slots) master S: 9242c455757da4ad2f5aa818d75d12cde38231c2 127.0.0.1:6383 replicates 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e S: 5cc9ed2602986aeffaf9997f3c38c675092a4810 127.0.0.1:6384 replicates 92a1fd50a1c8dc003e905ac828b0db64773d6b66 S: ac3f5aaae24bcd142b8303abedc5f57187ebc20e 127.0.0.1:6385 replicates 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join . \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 127.0.0.1:6380) M: 92a1fd50a1c8dc003e905ac828b0db64773d6b66 127.0.0.1:6380 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: ac3f5aaae24bcd142b8303abedc5f57187ebc20e 127.0.0.1:6385 slots: (0 slots) slave replicates 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c S: 9242c455757da4ad2f5aa818d75d12cde38231c2 127.0.0.1:6383 slots: (0 slots) slave replicates 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e S: 5cc9ed2602986aeffaf9997f3c38c675092a4810 127.0.0.1:6384 slots: (0 slots) slave replicates 92a1fd50a1c8dc003e905ac828b0db64773d6b66 M: 9a91b1be7a42e1bfe4b03deaa200c0e72fcf9b8e 127.0.0.1:6382 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: 82ac1fe6c0af98d252ea96d4e84e7315eff31f8c 127.0.0.1:6381 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. 输出信息为集群的哈希槽的分配信息及主从关系，可知：\n共有 16384（以 0 开始计数），将 0-5460 的哈希槽分配给主节点 1，将 5461-10922 的哈希槽分配给主节点 2，将 10923-16383 的哈希槽分配给主节点 3； 127.0.0.1:6384 是 127.0.0.1:6380 的备份，127.0.0.1:6385 是 127.0.0.1:6381 的备份，127.0.0.1:6383 是 127.0.0.1:6382 的备份； 管理工具 RedisInsight 是 Redis 官方提供的 Redis 服务器图形化管理工具，操作性很强，包含：\n数据维护； 性能测试； 可视化； 支持不同类型的 Redis 服务； 注意事项 创建集群时，如果一个 Redis 实例中含有键值对，集群会创建失败； [ERR] Node 127.0.0.1:6380 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0. 集群模式中，各 Redis 节点要使用两个端口，分别为指定的 port 和 port+10000； ","date":"2022-04-07","img":"","permalink":"/posts/redis-cluster-deployment/","series":null,"tags":["Redis"],"title":"Redis 集群配置过程"},{"categories":["Python","可视化"],"content":"每当有快速绘制图表的需求时，第一时间反应到的肯定是 Matplotlib，因为其官方提供了详细的 API 文档及示例。但是每次在编码时，总是时不时地需要查看文档，不利用于可视化快速成型。所以在本文中罗列一些 bar 图的快速实现，方便 Ctrl+C/V。\n基本实现 import matplotlib.pyplot as plt import numpy as np data = [120, 200, 150, 80, 70, 110, 130] x = np.arange(len(data)) plt.bar( x, # bar 在 x 轴的位置 data, width=0.6, # bar 的宽度 label=\u0026#39;Sales\u0026#39;, ) plt.xticks( x, # 标签的位置 [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], ) plt.legend() plt.title(\u0026#39;Products\u0026#39;) bar 设置颜色 import matplotlib.pyplot as plt import numpy as np colors = [\u0026#39;#009392\u0026#39;, \u0026#39;#39b185\u0026#39;, \u0026#39;#9ccb86\u0026#39;, \u0026#39;#e9e29c\u0026#39;, \u0026#39;#eeb479\u0026#39;, \u0026#39;#e88471\u0026#39;, \u0026#39;#cf5974\u0026#39;] data = [120, 200, 150, 80, 70, 110, 130] x = np.arange(len(data)) plt.bar( x, data, width=0.6, color=colors, # 单值或者可迭代对象，如果长度与数组不匹配则会从头反复使用色值 ) plt.xticks( x, [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], ) plt.title(\u0026#39;Sales\u0026#39;) 显示数值 import matplotlib.pyplot as plt import numpy as np colors = [\u0026#39;#009392\u0026#39;, \u0026#39;#39b185\u0026#39;, \u0026#39;#9ccb86\u0026#39;, \u0026#39;#e9e29c\u0026#39;, \u0026#39;#eeb479\u0026#39;, \u0026#39;#e88471\u0026#39;, \u0026#39;#cf5974\u0026#39;] data = [120, 200, 150, 80, 70, 110, 130] x = np.arange(len(data)) bar = plt.bar( x, data, width=0.6, color=colors, ) plt.bar_label( bar, label_type=\u0026#39;edge\u0026#39;, # 标签显示的位置，edge 为默认值；如果是 center 则显示在 bar 中间（垂直水平居中） ) plt.xticks( x, [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], ) plt.title(\u0026#39;Sales\u0026#39;) 层叠 bar 图 import matplotlib.pyplot as plt import numpy as np data_man = [120, 200, 150, 80, 70, 110, 130] data_woman = [100, 50, 90, 50, 80, 30, 30] x = np.arange(len(data)) bar1 = plt.bar( x, data_man, label=\u0026#39;Man\u0026#39;, color=\u0026#39;#009392\u0026#39;, ) bar2 = plt.bar( x, data_woman, bottom=data_man, label=\u0026#39;Woman\u0026#39;, color=\u0026#39;#cf5974\u0026#39;, ) plt.bar_label( bar1, label_type=\u0026#39;center\u0026#39;, labels=data_man, # 设置显示的值 ) plt.bar_label( bar2, label_type=\u0026#39;center\u0026#39;, labels=data_woman, ) plt.xticks( x, [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], ) plt.legend() 多条 bar 通过调整 bar 的位置和宽度来实现多条 bar 不重叠显示。\nimport matplotlib.pyplot as plt import numpy as np data_man = [120, 200, 150, 80, 70, 110, 130] data_woman = [100, 50, 90, 50, 80, 30, 30] x = np.arange(len(data)) width = 0.4 bar1 = plt.bar( x - width/2, # 位置 data_man, width=width, # 宽度 label=\u0026#39;Man\u0026#39;, color=\u0026#39;#eeb479\u0026#39;, ) bar2 = plt.bar( x + width/2, data_woman, width=width, label=\u0026#39;Woman\u0026#39;, color=\u0026#39;#cf5974\u0026#39;, ) plt.bar_label(bar1) plt.bar_label(bar2) plt.legend() 动态 bar 图 import matplotlib.pyplot as plt import numpy as np from matplotlib.animation import FuncAnimation data_man = [120, 200, 150, 80, 70, 110, 130] frames = 10 fig = plt.figure() axes = fig.add_subplot(1,1,1) axes.set_ylim(0, 250) def generate_animate_data(data, n): \u0026#34;\u0026#34;\u0026#34;生成每帧的数据\u0026#34;\u0026#34;\u0026#34; animate_data = [] for v in data: animate_data.append(np.linspace(0, v, n)) return np.array(animate_data) animate_data = generate_animate_data(data_man, frames) def animate(i): plt.bar( [\u0026#39;Mon\u0026#39;, \u0026#39;Tue\u0026#39;, \u0026#39;Wed\u0026#39;, \u0026#39;Thu\u0026#39;, \u0026#39;Fri\u0026#39;, \u0026#39;Sat\u0026#39;, \u0026#39;Sun\u0026#39;], animate_data[:,i], color=\u0026#39;#eeb479\u0026#39;, label=\u0026#39;Man\u0026#39; ) ani = FuncAnimation( fig, animate, frames=frames, # 帧数 interval=300, ) plt.title(\u0026#39;Man\u0026#39;) bar 图案 plt.bar 函数有两个可选参数 facecolor 和 edgecolor 控制。\nimport matplotlib.pyplot as plt import numpy as np bar_styles = { \u0026#39;man\u0026#39;: { \u0026#39;facecolor\u0026#39;: \u0026#39;#ee8479\u0026#39;, \u0026#39;edgecolor\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;hatch\u0026#39;: \u0026#39;//\u0026#39;, }, \u0026#39;woman\u0026#39;: { \u0026#39;facecolor\u0026#39;: \u0026#39;#cf5974\u0026#39;, \u0026#39;edgecolor\u0026#39;: \u0026#39;black\u0026#39;, \u0026#39;hatch\u0026#39;: \u0026#39;--\u0026#39;, } } data_man = [120, 200, 150, 80, 70, 110, 130] data_woman = [100, 50, 90, 50, 80, 30, 30] x = np.arange(len(data)) width = 0.4 bar1 = plt.bar( x - width/2, data_man, width=width, label=\u0026#39;Man\u0026#39;, **bar_styles[\u0026#39;man\u0026#39;] ) bar2 = plt.bar( x + width/2, data_woman, width=width, label=\u0026#39;Woman\u0026#39;, **bar_styles[\u0026#39;woman\u0026#39;] ) plt.bar_label(bar1) plt.bar_label(bar2) plt.legend() ","date":"2022-04-05","img":"","permalink":"/posts/python-matplotlib-bar-tips/","series":null,"tags":["Matplotlib"],"title":"Matplotlib Bar 图常规编码"},{"categories":["Python","数据挖掘"],"content":"k-means 算法是一种无监督的聚类算法，其优点是逻辑简单、易于实现。\n基本原理 质心是指一个簇中样本的均值向量，k-means 中的 means 就是从这里来的。当确定 k 个质心后，需要计算样本与 k 个质心的距离，而样本则归属于距离最近的质心所在的簇。随着算法的迭代，质心的位置会发生变化。质心的变化程度也是算法结束的一个条件，迭代前后质心位置变化通常使用 SSE 来刻画。\n其中 $n$ 是质心的维数，$c^{(t)}_{ij}$ 表示 $t$ 次迭代中第 $i$ 个质心的第 $j$ 维值。\n步骤 确定 k 值、最大迭代数及误差值； 随机选择 k 个样本作为质心； 分别计算样本与质心的距离，将样本划分到 k 个簇； 重新计算 k 个簇的质心，比较前后质心的误差； 若误差小于等于设置的误差值，则算法结束； 若误差大于设置的误差值，则执行步骤 5； 判断是否达到最大迭代数，若未达到则执行步骤 3，否则算法结束； 问题 选择 k-means 算法做聚类分析时，以下几个问题值得注意：\n初始质心的选择； k 值的确定； 距离公式的确定； k-means 算法容易局部最优，并且算法的结果在很大程度上取决于初始质心的选择，不同的初始质心可能会得到截然不同的聚类结果。同时，在面对未知类别个数的数据集时，如何确定 k 值也是一件麻烦事。通常做法都在小样本集上尝试不同的 k 值，然后比较聚类的结果并将 k 值定为跑得最好结果的那次 k 值。距离公式的选择则是需要依靠领域知识，因为在不同的领域中，样本的相似度的计算方式会有所不同。\n完整代码 import numpy as np import matplotlib.pyplot as plt def distance(x1, x2): \u0026#34;\u0026#34;\u0026#34;欧式距离\u0026#34;\u0026#34;\u0026#34; return np.sqrt(np.sum(np.power(x1 - x2, 2))) def sse(centroids1, centroids2): return np.sum(np.sqrt(np.sum(np.power(centroids1 - centroids2, 2), axis=1))) def update_centroid(centroids, data): r, _ = data.shape cluster_idxs = [] for i in range(len(centroids)): cluster_idxs.append([]) for i in range(r): ds = np.array([distance(data[i], centroid) for centroid in centroids]) sorted_idxs = np.argsort(ds) cluster_idxs[sorted_idxs[0]].append(i) new_centroids = [] for i, cluster_idx in enumerate(cluster_idxs): if len(cluster_idx) == 0: new_centroids.append(centroids[i]) else: new_centroids.append(np.mean(data[cluster_idx], axis=0)) return np.array(new_centroids) def initial_centroids(k, data): r, _ = data.shape idxs = np.arange(0, r) np.random.shuffle(idxs) return data[idxs[:k]] def cluster(centroids, data): r, _ = data.shape cluster_idxs = [] for i in range(len(centroids)): cluster_idxs.append([]) for i in range(r): ds = np.array([distance(data[i], centroid) for centroid in centroids]) sorted_idxs = np.argsort(ds) cluster_idxs[sorted_idxs[0]].append(i) return cluster_idxs data = np.random.uniform(5, 10, size=(400, 2)) k = 5 colors = [\u0026#39;#4e9e9d\u0026#39;, \u0026#39;#86cc7f\u0026#39;, \u0026#39;#506798\u0026#39;, \u0026#39;#4f1b63\u0026#39;, \u0026#39;#fbe85a\u0026#39;] tol = 1e-6 iteration = 12 plt.figure(figsize=(10, 4)) fig = plt.figure(figsize=(10, 15)) axes = fig.subplots(nrows=3, ncols=2) centroids = initial_centroids(k, data) i = 0 while iteration \u0026gt;= 0: if iteration % 2 == 1: cluster_idxs = cluster(centroids, data) for color_idx, cluster_idx in enumerate(cluster_idxs): fig.axes[i].scatter(data[cluster_idx][:,0], data[cluster_idx][:,1], c=colors[color_idx]) fig.axes[i].scatter(centroids[:,0], centroids[:,1], s=30, marker=\u0026#39;*\u0026#39;, c=\u0026#39;red\u0026#39;) fig.axes[i].set_title(\u0026#39;iter %d\u0026#39; % iteration) i = i + 1 new_centroids = update_centroid(centroids, data) if sse(new_centroids, centroids) \u0026lt;= tol: centroids = new_centroids break centroids = new_centroids iteration = iteration - 1 下图是执行得到的一次结果图：\n其它 帖子讨论了 k-means 和 c-means 是否是相同的概念，得票最多的回答认为是同一概念，所以本文对两者不作区分； 总结 k-means 算法结束的两个条件； 迭代结束； 质心位置变化小于误差值； Python 实现 k-means 算法； ","date":"2022-04-02","img":"/images/357_2019_9314_Fig1_HTML.png","permalink":"/posts/data-analysis-kmeans/","series":null,"tags":["k-means"],"title":"K-Means 基本原理及其实现"},{"categories":["Go","Web"],"content":"Revel 是一个以高效率、高性能著称的 Go Web 框架，提供了路由、参数解析和验证、会话机制、模板机制、缓存和任务管理等诸多常用的 Web 开发功能。同时作为一个全栈的 MVC 框架， Revel 通过模块实现了组件的复用，因此可以大大提高开发者的效率。其高性能则是依托 Go 语言的性能，相信这个不必多说。但相较于其它职责相对单一的 Web 框架（如 Gin、go-restful），Revel 只能说是在保证性能的基础上尽可能地对开发者友好。\n问题重现 环境\nGo 的版本：go1.16.9 windows/amd64\nRevel：v1.0.0\n今天在试验 Revel 项目时，运行新建的项目会报错，如下：\n$ revel run -a . ERROR 10:46:39 file.go:372: Error seeking=github.com/revel/revel count=1 App Import Path=github.com/revel/revel filesystem path=github.com/revel/revel errors=\u0026#34;[-: no required module provides package github.com/revel/revel; to add it:\\n\\tgo get github.com/revel/revel]\u0026#34; Downloading related packages ... completed. Revel executing: run a Revel application WARN 10:46:41 harness.go:175: No http.addr specified in the app.conf listening on localhost interface only. This will not allow external access to your application Changed detected, recompiling Parsing packages, (may require download if not cached)...Changed detected, recompiling Completed ERROR 10:46:44 build.go:406: Build errors errors=\u0026#34;C:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\memcached.go:11:2: no required module provides package github.com/bradfitz/gomemcache/memcache; to add it:\\n\\tgo get github.com/bradfitz/gomemcache/memcache\\nC:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\redis.go:10:2: no required module provides package github.com/garyburd/redigo/redis; to add it:\\n\\tgo get github.com/garyburd/redigo/redis\\nC:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\inmemory.go:12:2: no required module provides package github.com/patrickmn/go-cache; to add it:\\n\\tgo get github.com/patrickmn/go-cache\\n\u0026#34; C:\\Users\\a2htray\\go\\src\\omics-framework\\C:\\Users\\a2htray\\go\\pkg\\mod\\github.com\\revel\\revel@v1.0.0\\cache\\memcached.go:11 WARN 10:46:44 build.go:420: Could not find in GO path file=C:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\memcached.go:11 ERROR 10:46:44 harness.go:239: Build detected an error error=\u0026#34;Go Compilation Error (in C:\\\\Users\\\\a2htray\\\\go\\\\pkg\\\\mod\\\\github.com\\\\revel\\\\revel@v1.0.0\\\\cache\\\\memcached.go:11:2): no required module provides package github.com/bradfitz/gomemcache/memcache; to add it:\u0026#34; Error compiling code, to view error details see proxy running on http://:9000 Time to recompile 2.4257731s 新建的 Revel 项目使用 go.mod 对包进行管理，初始的包如下：\nrequire ( github.com/go-stack/stack v1.8.1 // indirect github.com/revel/modules v1.0.0 github.com/revel/revel v1.0.0 ) 通过错误输出，可知当前项目缺少了 3 个包：\ngithub.com/bradfitz/gomemcache/memcache github.com/garyburd/redigo/redis github.com/patrickmn/go-cache 解决办法 既然是项目缺少包，那就只要把缺失的包 go get 一下即可。\n$ go get github.com/bradfitz/gomemcache/memcache $ go get github.com/garyburd/redigo/redis $ go get github.com/patrickmn/go-cache 再次运行：\n$ revel run -a . Revel executing: run a Revel application WARN 11:33:47 harness.go:175: No http.addr specified in the app.conf listening on localhost interface only. This will not allow external access to your application Changed detected, recompiling Parsing packages, (may require download if not cached)... Completed Changed detected, recompiling INFO 11:33:54 app run.go:34: Running revel server INFO 11:33:54 app plugin.go:9: Go to /@tests to run the tests. Revel proxy is listening, point your browser to : Revel engine is listening on.. localhost:52469 9000 Time to recompile 7.0696399s 其它 在这个 issue 1528 里，有人说是 Go 版本问题，即在 Go 1.15 中是可以运行的。我想解决上面的问题，就把缺失包补上就可以了，而且也猜应该不是 Go 版本问题，毕竟 Revel 的 cache 实现中也确实使用了这 3 个包。再深入想一想，如果 Revel 项目也是通过 Go Module 管理包的话，revel run 的时候就会自动下载这些包。\n","date":"2022-03-31","img":"","permalink":"/posts/go-revel-run-require-packages/","series":null,"tags":["Revel"],"title":"Go 1.16 运行 Revel 项目"},{"categories":["数据库","运维"],"content":"Redis 主从复制可以实现数据库的读写分离，即主节点负责接收写请求、从节点负责接收读请求，是高性能 Redis 服务的基础。所以配置 Redis 主从复制应当作为开发者的技能之一，后文内容包括：\n单机配置一主二从的主从复制服务 服务验证； 环境信息\n$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.2 LTS Release: 20.04 Codename: focal $ redis-server -v Redis server v=6.2.6 sha=00000000:0 malloc=jemalloc-5.1.0 bits=64 build=9c9e426e2f96cc51 配置过程 主节点使用 6379 端口，两个从节点分别使用 6380 和 6381 端口。\nRedis 配置文件 复制两份 Redis 配置文件分别为两个从节点的配置文件：\ncp -a /etc/redis/redis.conf /etc/redis/redis-server-6380.conf cp -a /etc/redis/redis.conf /etc/redis/redis-server-6381.conf 修改两个配置文件的内容，修改及新增内容如下：\n# redis-6380.conf # 修改项 port 6380 pidfile /run/redis/redis-server-6380.pid logfile /var/log/redis/redis-server-6380.log dbfilename dump-6380.rdb # 新增项 slaveof 127.0.0.1 6379 # redis-6381.conf # 修改项 port 6381 pidfile /run/redis/redis-server-6381.pid logfile /var/log/redis/redis-server-6381.log dbfilename dump-6381.rdb # 新增项 slaveof 127.0.0.1 6379 systemd 配置文件 复制两份 systemd 配置文件分别作为两个从节点的服务启动文件：\ncp -a /lib/systemd/system/redis-server.service /lib/systemd/system/redis-server-6380.service cp -a /lib/systemd/system/redis-server.service /lib/systemd/system/redis-server-6381.service 修改两个配置文件的内容，均为修改项，如下：\n# redis-server-6380.service [Service] ExecStart=/usr/bin/redis-server /etc/redis/redis-server-6380.conf PIDFile=/run/redis/redis-server-6380.pid # redis-server-6381.service [Service] ExecStart=/usr/bin/redis-server /etc/redis/redis-server-6381.conf PIDFile=/run/redis/redis-server-6381.pid 修改之后，需要执行如下命令进行重新加载：\nsystemctl daemon-reload 启动服务 配置完成后，通过 systemd 的管理命令分别在 3 个终端各启动 1 个服务，命令及显示如下：\n# 主节点 $ systemctl start redis-server.service $ redis-cli -p 6379 127.0.0.1:6379\u0026gt; INFO Replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6380,state=online,offset=308,lag=0 slave1:ip=127.0.0.1,port=6381,state=online,offset=308,lag=1 # 其它 ... # 从节点 6380 $ systemctl start redis-server-6380.service $ redis-cli -p 6380 127.0.0.1:6380\u0026gt; INFO Replication # Replication role:slave master_host:127.0.0.1 master_port:6379 # 其它 ... # 从节点 6381 $ systemctl start redis-server-6381.service $ redis-cli -p 6381 127.0.0.1:6381\u0026gt; INFO Replication # Replication role:slave master_host:127.0.0.1 master_port:6379 # 其它 ... 读写 Redis 数据库 是否发生主从复制，可按如下的命令依次执行进行验证。\n# 主节点 127.0.0.1:6379\u0026gt; SET topic master-slave-replication OK # 从节点 6380 127.0.0.1:6380\u0026gt; GET topic \u0026#34;master-slave-replication\u0026#34; # 从节点 6381 127.0.0.1:6381\u0026gt; GET topic \u0026#34;master-slave-replication\u0026#34; 其它 systemd 是 Linux 服务器管理服务的其中一种方式，服务的启动与关闭也可以通过 redis-server 命令或其它方式进行实现。Redis 使用到的目录及文件信息包括：\n/run/redis/：存放 Redis 服务的 pid 文件，由 pidfile 配置项决定； /var/log/redis/：存放 Redis 服务的日志文件，由 logfile 配置项决定； /var/lib/redis：存放 RDB 文件，由 dir 和 dbfilename 配置项决定； 完整脚本 #!/bin/bash SLAVE1_PORT=6380 SLAVE2_PORT=6381 cat /etc/redis/redis.conf | \\ sed \u0026#34;s/^port\\ 6379/port\\ $SLAVE1_PORT/g\u0026#34; | \\ sed \u0026#34;s/^pidfile \\/run\\/redis\\/redis-server\\.pid/pidfile \\/run\\/redis\\/redis-server-$SLAVE1_PORT\\.pid/g\u0026#34; | \\ sed \u0026#34;s/^logfile \\/var\\/log\\/redis\\/redis-server\\.log/logfile \\/var\\/log\\/redis\\/redis-server-$SLAVE1_PORT\\.log/g\u0026#34; | \\ sed \u0026#34;s/^dbfilename dump\\.rdb/dbfilename dump-$SLAVE1_PORT\\.rdb/g\u0026#34; | \\ sed \u0026#34;\\$a\\\\slaveof 127.0.0.1 6379\\\\\u0026#34; \u0026gt; /etc/redis/redis-server-$SLAVE1_PORT.conf chown redis.redis /etc/redis/redis-server-$SLAVE1_PORT.conf cat /etc/redis/redis.conf | \\ sed \u0026#34;s/^port\\ 6379/port\\ $SLAVE2_PORT/g\u0026#34; | \\ sed \u0026#34;s/^pidfile \\/run\\/redis\\/redis-server\\.pid/pidfile \\/run\\/redis\\/redis-server-$SLAVE2_PORT\\.pid/g\u0026#34; | \\ sed \u0026#34;s/^logfile \\/var\\/log\\/redis\\/redis-server\\.log/logfile \\/var\\/log\\/redis\\/redis-server-$SLAVE2_PORT\\.log/g\u0026#34; | \\ sed \u0026#34;s/^dbfilename dump\\.rdb/dbfilename dump-$SLAVE2_PORT\\.rdb/g\u0026#34; | \\ sed \u0026#34;\\$a\\\\slaveof 127.0.0.1 6379\\\\\u0026#34; \u0026gt; /etc/redis/redis-server-$SLAVE2_PORT.conf chown redis.redis /etc/redis/redis-server-$SLAVE2_PORT.conf cat /lib/systemd/system/redis-server.service | \\ sed \u0026#34;s/\\/etc\\/redis\\/redis\\.conf/\\/etc\\/redis\\/redis-server-$SLAVE1_PORT\\.conf/g\u0026#34; | \\ sed \u0026#34;s/\\/run\\/redis\\/redis-server\\.pid/\\/run\\/redis\\/redis-server-$SLAVE1_PORT\\.pid/g\u0026#34; \u0026gt; /lib/systemd/system/redis-server-$SLAVE1_PORT.service chown root.root /lib/systemd/system/redis-server-$SLAVE1_PORT.service cat /lib/systemd/system/redis-server.service | \\ sed \u0026#34;s/\\/etc\\/redis\\/redis\\.conf/\\/etc\\/redis\\/redis-server-$SLAVE2_PORT\\.conf/g\u0026#34; | \\ sed \u0026#34;s/\\/run\\/redis\\/redis-server\\.pid/\\/run\\/redis\\/redis-server-$SLAVE2_PORT\\.pid/g\u0026#34; \u0026gt; /lib/systemd/system/redis-server-$SLAVE2_PORT.service chown root.root /lib/systemd/system/redis-server-$SLAVE2_PORT.service systemctl daemon-reload systemctl start redis-server.service systemctl start redis-server-$SLAVE1_PORT.service systemctl start redis-server-$SLAVE2_PORT.service 总结 Redis 主从复制的配置过程； Redis 服务相关配置项说明； ","date":"2022-03-30","img":"","permalink":"/posts/redis-master-slave-replication-deployment/","series":null,"tags":["Redis"],"title":"Redis 主从复制配置过程"},{"categories":["数据库"],"content":"Redis 服务器中与服务相关的命令。\nINFO：查看当前服务器信息 格式：INFO [section]\n127.0.0.1:6380\u0026gt; INFO # Server redis_version:6.2.6 redis_git_sha1:00000000 redis_git_dirty:0 redis_build_id:9c9e426e2f96cc51 redis_mode:standalone os:Linux 5.4.0-77-generic x86_64 arch_bits:64 # 还有很多 ... SHUTDOWN：客户端断开连接 格式：SHUTDOWN [NOSAVE|SAVE]\n127.0.0.1:6379\u0026gt; SHUTDOWN SAVE not connected\u0026gt; EXIT：退出客户端 127.0.0.1:6379\u0026gt; EXIT ","date":"2022-03-30","img":"","permalink":"/doc-redis-commands/server-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"服务相关"},{"categories":["Web"],"content":"同源策略（Same-Origin Policy，SOP）是一种保护 Web 资源的安全机制，它限制了不同源之间的资源访问。需要说明的是，SOP 只作用于应用脚本，这意味着在 HTML 标签中可以引入不同源的图片、CSS 文件或动态加载的脚本文件（见验证 1）。\n同源 URL 统一资源标识符（Uniform Resource Locator，URL）标识了一个 Web 资源，其格式为：\nschema://host[:port][/path ...]\n其中 schema 可为 http 或 https，port 默认为 80。如果两个 URL 的 schema、host、port 都相同时，则认为这两个 URL 是同源的。现有 URL 为 http://foo.com/bar，以下是其它 URL 是否同源的说明。\nURL 是否同源 说明 https://foo.com 否 schema 不同 http://bar.com 否 host 不同 http://foo.com:81/bar 否 port 不同 http://foo.com/zot 是 3 个都相同 访问规则 通常，直接读取跨域资源是不允许的，但仍然可以通过内嵌跨域资源进行访问。以下是允许跨域访问的规则：\n方式 说明 iframes 响应头的 X-Frame-Options 字段可以设置 \u0026lt;frame\u0026gt;、\u0026lt;iframe\u0026gt;、\u0026lt;embed\u0026gt; 或 object 标签可引用的页面，但跨域读 iframe 里的内容是不允许的 CSS \u0026lt;link\u0026gt; 标签的 href 属性和 CSS 文件中的 @import 指令 forms 此处不应该是读取，而是说 \u0026lt;form\u0026gt; 的 action 属性可以设置不同源的 URL，指的是目标服务可以接收不同源的数据 images 通过 \u0026lt;img\u0026gt; 标签访问跨域图片，但在 canvas 元素里加载跨域图片是不允许的 multimedia 通过 \u0026lt;video\u0026gt; 和 \u0026lt;audio\u0026gt; 标签加载跨域的多媒体资源 script 通过 \u0026lt;script\u0026gt; 标签加载跨域的脚本，但请求跨域的 API 是不允许的 所以以上的规则容易变成 Web 服务攻击的入口，应当警惕。\n验证 验证 1 示例目录结构\n验证 1 - static - images profile.jpg index.html main.go // main.go package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { fs := http.FileServer(http.Dir(\u0026#34;./static/\u0026#34;)) http.Handle(\u0026#34;/static/\u0026#34;, http.StripPrefix(\u0026#34;/static\u0026#34;, fs)) log.Fatal(http.ListenAndServe(\u0026#34;:8001\u0026#34;, nil)) } \u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;验证 1\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;图片不受同源策略限制\u0026lt;/p\u0026gt; \u0026lt;img width=\u0026#34;100\u0026#34; height=\u0026#34;100\u0026#34; alt=\u0026#34;profile\u0026#34; src=\u0026#34;http://localhost:8001/static/images/profile.jpg\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 总结 URL 是否同源取决于 schema、host、port 是否一致； 尽管跨域访问是不允许的，但仍然有一定的跨域可访问规则； ","date":"2022-03-29","img":"","permalink":"/posts/web-same-origin-policy/","series":null,"tags":["Web 安全"],"title":"同源策略 Same-Origin Policy"},{"categories":["Python"],"content":"在开发过程中，开发者常常需要对文件执行读写操作，仅以此文记录读写文件的常规用法。\n打开和关闭文件 Python 的内建函数 open 可以打开一个文件，可返回一个文件对象 TextIOWrapper（也称文件句柄）。打开的文件应当及时关闭，否则过多的文件对象容易造成内存占用，导致程序运行内存不足。按照是否调用文件对象的 close 方法，有两种打开和关闭文件的代码书写方式：\n显式 close 隐式 close 显式 close\ndef open1(): f = open(\u0026#39;./students.dat\u0026#39;) try: lines = f.readlines() print(lines) finally: f.close() 隐式 close\ndef open2(): with open(\u0026#39;./students.dat\u0026#39;) as f: lines = f.readlines() print(lines) 支持 with 语句的对象需要实现 __enter__ 和 __exit__ 两个方法，其中 TextIOWrapper 类实现了 __exit__ 方法，IOBase 类实现了 __enter__ 方法。\n上述两个函数的作用相同，都是用于打开 students.dat 文件并打印所有的行。\nopen 函数 内建函数 open 的签名如下：\ndef open( file: _OpenFile, mode: OpenTextMode = ..., buffering: int = ..., encoding: str | None = ..., errors: str | None = ..., newline: str | None = ..., closefd: bool = ..., opener: _Opener | None = ..., ) -\u0026gt; TextIOWrapper: ... file：字符串文件路径或实现了 os.PathLike 抽象类的实例； mode：打开模式，默认 r，可选； buffering：设置缓冲策略，可选； encoding：编码格式，可选； errors：编码或解码发生错误时的错误信息，可选； newline：断行的方式，可用的参数值有 None、' '、'\\n'、'\\r' 和 '\\r\\n'，可选； closefd：必须为 True，否则报错，可选； opener：自定义的打开器，调用的函数，返回一个文件描述符，可选； os.PathLike 抽象类 os.PathLike 是一个抽象类，定义了 __fspath__ 方法，任何实现了 __fspath__ 方法的类的实例都可以作为 open 函数的 file 参数值。\nimport os class MyFile(os.PathLike): def __init__(self, filename) -\u0026gt; None: self.filename = filename def __fspath__(self): return self.filename def open3(): with open(MyFile(\u0026#39;./students.dat\u0026#39;)) as f: lines = f.readlines() print(lines) mode 参数值 mode 参数值可为：\nMode 'r' 读打开（默认） 'w' 读打开，若文件不存在则创建，若文件存在则会清空文件内容 'x' 以独占的方式创建文件，如果文件已存在则报错 'a' 以追加的形式打开文件，文件不存在会创建，文件存在的话，不会清空文件内容 't' 文本模式（默认） 'b' 二进制打开文件 '+' 以更新的方式打开文件 f.close 方法 当文件对象调用 close 方法后，对象的 closed 属性会置为 True，也可以通过该属性可以检查文件对象是否关闭。\ndef view_f_closed(): f = open(\u0026#39;./students.dat\u0026#39;) f.close() print(f.closed) 读写文件 文件对象中有如下几个方法可用于读取文件内容：\n方法 用法 .read(size=-1) 按指定的字节数读取文件内容，当 size 为 -1 时，表示读取全部 .readline(size=-1) 按指定的字符数读取一行的内容，当 size 为 None 或 -1 时，表示读取整行内容 .readlines() 读取文件中所有的行 文件对象中有如下几个方法可用于写入文件内容：\n方法 用法 .write(string) 向文件写入字符串 .writelines(seq) 向文件中写入多行，换行符需要开发者指定 编码问题 若文件中存在中文，需要指定 encoding 参数的值，如：\ndef read_chinese(): with open(\u0026#39;./students.zh-cn.dat\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: lines = f.readlines() print(lines) 遍历文件所有的行 下面列表读取文件所有的行的几种方式。\n方式 1\ndef iterate_lines1(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: line = f.readline() while line != \u0026#39;\u0026#39;: print(line, end=\u0026#39;\u0026#39;) line = f.readline() 方式 2\ndef iterate_lines2(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: lines = f.readlines() for line in lines: print(line, end=\u0026#39;\u0026#39;) 方式 3\ndef iterate_lines3(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: for line in f: print(line, end=\u0026#39;\u0026#39;) 总结 本文的完整代码如下：\nimport os def open1(): f = open(\u0026#39;./students.dat\u0026#39;) try: lines = f.readlines() print(lines) finally: f.close() def open2(): with open(\u0026#39;./students.dat\u0026#39;) as f: lines = f.readlines() print(lines) class MyFile(os.PathLike): def __init__(self, filename) -\u0026gt; None: self.filename = filename def __fspath__(self): return self.filename def open3(): with open(MyFile(\u0026#39;./students.dat\u0026#39;)) as f: lines = f.readlines() print(lines) def view_f_closed(): f = open(\u0026#39;./students.dat\u0026#39;) f.close() print(f.closed) def read_chinese(): with open(\u0026#39;./students.zh-cn.dat\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: lines = f.readlines() print(lines) def iterate_lines1(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: line = f.readline() while line != \u0026#39;\u0026#39;: print(line, end=\u0026#39;\u0026#39;) line = f.readline() def iterate_lines2(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: lines = f.readlines() for line in lines: print(line, end=\u0026#39;\u0026#39;) def iterate_lines3(): with open(\u0026#39;./students.dat\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: for line in f: print(line, end=\u0026#39;\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: print(\u0026#39;书写方式 1:\u0026#39;) open1() print(\u0026#39;书写方式 2:\u0026#39;) open2() print(\u0026#39;实现了 os.PathLike 抽象类\u0026#39;) open3() print(\u0026#39;调用 f.close 后:\u0026#39;) view_f_closed() print(\u0026#39;遍历所有的行 1:\u0026#39;) iterate_lines1() print(\u0026#39;遍历所有的行 2:\u0026#39;) iterate_lines2() print(\u0026#39;遍历所有的行 3:\u0026#39;) iterate_lines3() print(\u0026#34;读取中文:\u0026#34;) read_chinese() 运行输出为：\n书写方式 1: [\u0026#39;xiaoming\\n\u0026#39;, \u0026#39;xiaohong\\n\u0026#39;, \u0026#39;xiaolei\\n\u0026#39;, \u0026#39;xiaopang\\n\u0026#39;] 书写方式 2: [\u0026#39;xiaoming\\n\u0026#39;, \u0026#39;xiaohong\\n\u0026#39;, \u0026#39;xiaolei\\n\u0026#39;, \u0026#39;xiaopang\\n\u0026#39;] 实现了 os.PathLike 抽象类 [\u0026#39;xiaoming\\n\u0026#39;, \u0026#39;xiaohong\\n\u0026#39;, \u0026#39;xiaolei\\n\u0026#39;, \u0026#39;xiaopang\\n\u0026#39;] 调用 f.close 后: True 遍历所有的行 1: xiaoming xiaohong xiaolei xiaopang 遍历所有的行 2: xiaoming xiaohong xiaolei xiaopang 遍历所有的行 3: xiaoming xiaohong xiaolei xiaopang 读取中文: [\u0026#39;小明\\n\u0026#39;, \u0026#39;小红\\n\u0026#39;, \u0026#39;小磊\\n\u0026#39;, \u0026#39;小胖\\n\u0026#39;] 本文可总结为以下几点：\n打开文件后，应该及时关闭。如果不想显式地调用 close 方法，推荐使用 with 语句； open 函数的 mode 参数指定了文件打开的模式，mode 参数的几个可选值非常重要； 列举了几个读写文件的常用方法，如读的 read、readline 和 readlines；写的 write 和 writelines； 3 种遍历文件所有行的方式； ","date":"2022-03-28","img":"","permalink":"/posts/python-read-and-write-file/","series":null,"tags":["file"],"title":"Python 读写文件"},{"categories":["数据库"],"content":"栈（Stack）和队列（Queue）是编程中常用的两种数据结构，下面通过 Redis 的列表（List）类型来实现栈和队列。\n栈 栈是一种受限的线性表，即“只能在一端进行插入和删除操作”，其特点是后进先出（Last In First Out，LIFO）。假设列表的右端为栈顶（插入和删除的一端），则需要使用到 RPUSH 和 RPOP 两个命令。\n127.0.0.1:6379\u0026gt; RPUSH stack 1 2 3 4 5 6 (integer) 6 127.0.0.1:6379\u0026gt; RPOP stack \u0026#34;6\u0026#34; 127.0.0.1:6379\u0026gt; RPUSH stack 7 8 9 (integer) 8 127.0.0.1:6379\u0026gt; RPOP stack \u0026#34;9\u0026#34; 127.0.0.1:6379\u0026gt; RPOP stack \u0026#34;8\u0026#34; 上述命令的说明如下：\nRPUSH stack 1 2 3 4 5 6 ：按插入的先后顺序，此时列表为 [1, 2, 3, 4, 5, 6]； RPOP：从列表右端弹出 1 个元素，该元素为 6，此时列表为 [1, 2, 3, 4, 5]； RPUSH stack 7 8 9：列表右端插入 3 个元素，此时列表为 [1, 2, 3, 4, 5, 7, 8, 9]； 最后的两次 RPOP stack：分别弹出元素 9 和 8，此时列表为 [1, 2, 3, 4, 5, 7]； 队列 队列也是一种受限的线性表，即“一端只能插入，另一端只能删除”，其特点是先进先出（First In First Out，FIFO）。假设列表的左端是队首（删除的一端），右端是队尾（插入的一端），则需要使用到 LPUSH 和 LPOP 两个命令。\n127.0.0.1:6379\u0026gt; RPUSH queue 1 2 3 4 5 6 (integer) 6 127.0.0.1:6379\u0026gt; LPOP queue \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; RPUSH queue 7 8 9 (integer) 8 127.0.0.1:6379\u0026gt; LPOP queue \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; LPOP queue \u0026#34;3\u0026#34; 上述命令的说明如下：\nRPUSH queue 1 2 3 4 5 6：按插入的先后顺序，此时列表为 [1, 2, 3, 4, 5, 6]； LPOP queue：从列表左端弹出 1 个元素，此时列表为 [2, 3, 4, 5, 6]； RPUSH queue 7 8 9：列表右端插入 3 个元素，此时列表为 [2, 3, 4, 5, 6, 7, 8, 9]； 最后两次 LPOP queue：分别从左端弹出元素 2 和 3，此时列表为 [4, 5, 6, 7, 8, 9]； ","date":"2022-03-27","img":"","permalink":"/doc-redis-commands/examples/stack-and-queue/","series":["Redis 命令手册"],"tags":["Redis"],"title":"列表模拟栈和队列"},{"categories":["数据库"],"content":"Redis 服务器中与 key 相关的命令。\nKEYS：获取数据库中匹配规则的键名 KEYS 命令遍历数据库中的所有键，支持 glob 风格通配符格式，在存在大量键值对的 Redis 服务器上应谨慎使用。\n格式：KEYS patten\n127.0.0.1:6379\u0026gt; KEYS * (empty array) 127.0.0.1:6379\u0026gt; SET config:logLevel Fatal OK 127.0.0.1:6379\u0026gt; KEYS config:* 1) \u0026#34;config:logLevel\u0026#34; glob 风格通配符格式\n符号 含义 ? 匹配一个字符 * 匹配任意多个字符 [] 匹配括号间的任一字符 \\ 转义 EXISTS：判断键名是否存在 EXISTS 用于判断键名是否存在，返回值为存在键名的个数。\n格式：EXISTS key [key ...]\n127.0.0.1:6379\u0026gt; EXISTS config:logLevel config:pagination (integer) 1 127.0.0.1:6379\u0026gt; EXISTS config:pagination (integer) 0 EXPIRE：给键设置过期时间 EXPIRE 可以给一个键设置一个以秒为单位的过期时间。\n格式：EXPIRE key seconds\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; EXPIRE user:1:name 5 (integer) 1 127.0.0.1:6379\u0026gt; GET user:1:name \u0026#34;xiaoming\u0026#34; # 5 秒内访问 127.0.0.1:6379\u0026gt; GET user:1:name (nil) # 5 秒后访问 EXPIREAT：给键设置过期时间 EXPIREAT 通过指定一个 UNIX 时间戳为键设置一个过期时间。\n格式：EXPIREAT key timestamp\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; EXPIREAT user:1:name 1648470000 (integer) 1 # 1648470000 为 2022-03-28 20:20:00 127.0.0.1:6379\u0026gt; GET user:1:name \u0026#34;xiaoming\u0026#34; PEXPIRE：给键设置过期时间 PEXPIRE 与 EXPIRE 类似，不同之处在于 PEXPIRE 的时间单位是微秒。\n格式：PEXPIRE key milliseconds\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; PEXPIRE user:1:name 10000 (integer) 1 127.0.0.1:6379\u0026gt; GET user:1:name \u0026#34;xiaoming\u0026#34; # 10 秒内访问 127.0.0.1:6379\u0026gt; GET user:1:name (nil) # 10 秒后访问 PEXPIREAT：给键设置过期时间 PEXPIREAT 与 EXPIREAT 类似，不同之外在于 PEXPIREAT 的时间单位是微秒。\n格式：PEXPIREAT key milliseconds-timestamp\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) -1 127.0.0.1:6379\u0026gt; PEXPIREAT user:1:name 1648470000000 (integer) 1 PERSIST：移除键的过期时间 PERSIST 可以移除键的过期，使其永不失效。\n格式：PERSIST key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; EXPIRE user:1:name 100 (integer) 1 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) 93 127.0.0.1:6379\u0026gt; PERSIST user:1:name (integer) 1 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) -1 TTL：返回键的剩余生存时间 TTL 返回以秒为单位的键的剩余生存时间，对长期有效的键使用会返回 -1。\n格式：TTL key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; EXPIRE user:1:name 100 (integer) 1 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) 93 127.0.0.1:6379\u0026gt; SET user:1:name xiaoming (integer) 1 127.0.0.1:6379\u0026gt; TTL user:1:name (integer) -1 PTTL：返回键的剩余生存时间 PTTL 与 TTL 类似，不同之外在于返回的剩余生存时间的单位为微秒。\n格式：PTTL key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; PTTL user:1:name (integer) -1 127.0.0.1:6379\u0026gt; EXPIRE user:1:name 100 (integer) 1 127.0.0.1:6379\u0026gt; PTTL user:1:name (integer) 93978 RENAME：修改键名 RENAME 可用于修改键名。\n格式：RENAME key newkey\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; RENAME user:1:name user:2:name OK 127.0.0.1:6379\u0026gt; GET user:2:name \u0026#34;xiaoming\u0026#34; RENAMENX：修改键名 RENAMENX 命令只有在给定的新键名不存在时，才会起作用。\n格式：RENAMENX key newkey\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; KEYS user:newname* (empty array) 127.0.0.1:6379\u0026gt; RENAMENX user:1:name user:newname:1:name (integer) 1 127.0.0.1:6379\u0026gt; GET user:1:name (nil) 127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; RENAMENX user:1:name user:1:name (integer) 0 # 新键名不变，但执行不成功 DEL：删除一个或多个键 DEL 用于删除一个或多个键，返回值为删除键的个数。\n格式：DEL key [key ...]\n127.0.0.1:6379\u0026gt; DEL config:logLevel config:pagination (integer) 1 # config:pagination 此时并不存在，故返回值为 1 RANDOMKEY：随机返回一个键 格式：RANDOMKEY key\n127.0.0.1:6379\u0026gt; RANDOMKEY \u0026#34;student:weights\u0026#34; DUMP：序列化给定的键 DUMP 可以序列化指定的键并返回序列化的值。\n格式：DUMP key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; DUMP user:1:name \u0026#34;\\x00\\bxiaoming\\t\\x00\\xe6u\\x97\\x84\\x19\\x1c\\x01\\x81\u0026#34; TYPE：获取指定键对应值的类型 TYPE 用于获取指定键对应值的类型，返回值包括 string | hash | list | set | zset | stream\n格式：TYPE key\n127.0.0.1:6379\u0026gt; SET user:1:name xiaoming OK 127.0.0.1:6379\u0026gt; TYPE user:1:name string DBSIZE：返回数据库中 key 的数量 格式：DBSIZE\n127.0.0.1:6379\u0026gt; DBSIZE (integer) 26 ","date":"2022-03-27","img":"/images/redis-key.jpeg","permalink":"/doc-redis-commands/key-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"键相关"},{"categories":["数据库"],"content":"Redis 是开源的、高性能的数据结构存储系统，在框架设计中常常被当作缓存服务器。不同于传统的关系型数据库（如 MySQL、PostgreSQL），Redis 将数据以键值对的方式存储于内存并且支持数据持久化。尽管 Redis 采用了单线程模型来处理请求，但其通过 I/O 多路复用技术做到了应用级别的异步，运行的性能也十分良好。\n根据操作对象的不同，可将 Redis 中的命令分成以下几类：\n键相关命令 字符串值相关命令 列表值相关命令 集合值相关命令 有序集合值相关命令 流类型值相关命令 集群相关命令 服务相关命令 介绍完命令后，本文还会通过以下几个示例更一步说明命令的用法：\n列表模拟栈和队 ","date":"2022-03-27","img":"/images/redis.png","permalink":"/doc-redis-commands/introduction/","series":["Redis 命令手册"],"tags":["Redis"],"title":"介绍"},{"categories":["数据库"],"content":"Redis 服务器中与 stream 相关的命令。\nXADD：向 stream 添加消息 XADD 可以向 stream 添加消息，返回实体 entry 的 ID。\n格式：XADD key *|ID field value [field value ...]\n127.0.0.1:6379\u0026gt; XADD chat:1:messages * msg \u0026#34;hello world\u0026#34; date 2020 \u0026#34;1648184286632-0\u0026#34; 127.0.0.1:6379\u0026gt; XADD chat:2:messages 1 msg \u0026#34;hello world\u0026#34; date 2020 \u0026#34;1-0\u0026#34; XRANGE：返回 stream 记录的列表 XRANGE 用于获取指定 ID 范围内的 entry，其中 - 和 + 为特征 ID，分别表示最小 ID 和最大 ID。\n格式：XRANGE key start stop [COUNT count]\n127.0.0.1:6379\u0026gt; XADD chat:1:messages * msg \u0026#34;hello GO\u0026#34; date 2021 \u0026#34;1648184498673-0\u0026#34; 127.0.0.1:6379\u0026gt; XADD chat:1:messages * msg \u0026#34;hello TypeScript\u0026#34; date 2022 \u0026#34;1648184539697-0\u0026#34; 127.0.0.1:6379\u0026gt; XRANGE chat:1:messages - + 1) 1) \u0026#34;1648184286632-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello world\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2020\u0026#34; 2) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; 3) 1) \u0026#34;1648184539697-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello TypeScript\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2022\u0026#34; 127.0.0.1:6379\u0026gt; XRANGE chat:1:messages 1648184286632-0 1648184286632-1 1) 1) \u0026#34;1648184286632-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello world\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2020\u0026#34; 127.0.0.1:6379\u0026gt; XRANGE chat:1:messages 1648184286632-0 1648184498673-1 1) 1) \u0026#34;1648184286632-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello world\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2020\u0026#34; 2) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; XREVRANGE XREVRANGE 与 XRANGE 用途相近，但该命令会以倒序的方式返回 entry。\n格式：XREVRANGE key end start [COUNT count]\n127.0.0.1:6379\u0026gt; XREVRANGE chat:1:messages 1648184498673-1 1648184286632-0 1) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; 2) 1) \u0026#34;1648184286632-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello world\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2020\u0026#34; 127.0.0.1:6379\u0026gt; XREVRANGE chat:1:messages 1648184498673-1 1648184286632-0 COUNT 1 1) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; XTRIM：裁剪 stream 格式：XTRIM key MAXLEN|MINID [=|~] threshold [LIMIT count]\nMAXLEN：用于保留最近的 entry\nMINID：用于裁剪低于某一 ID 的 entry\n127.0.0.1:6379\u0026gt; XTRIM chat:1:messages MAXLEN 2 (integer) 1 127.0.0.1:6379\u0026gt; XRANGE chat:1:messages - + 1) 1) \u0026#34;1648184498673-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello GO\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2021\u0026#34; 2) 1) \u0026#34;1648184539697-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello TypeScript\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2022\u0026#34; # 此时最早加入的 entry 已经被裁剪，stream 中保留两条 entry 127.0.0.1:6379\u0026gt; XTRIM chat:1:messages MINID 1648184498674 (integer) 1 # ID 低于 1648184498674 的 entry 会被删除 XDEL：删除 stream 中 entry 格式：XDEL key ID [ID ...]\n127.0.0.1:6379\u0026gt; XRANGE chat:1:messages - + 1) 1) \u0026#34;1648184539697-0\u0026#34; 2) 1) \u0026#34;msg\u0026#34; 2) \u0026#34;hello TypeScript\u0026#34; 3) \u0026#34;date\u0026#34; 4) \u0026#34;2022\u0026#34; 127.0.0.1:6379\u0026gt; XDEL chat:1:messages 1648184539697-0 (integer) 1 XLEN：返回 stream 中 entry 的数目 格式：XLEN key\n127.0.0.1:6379\u0026gt; XLEN chat:1:messages (integer) 0 127.0.0.1:6379\u0026gt; DEL chat:1:messages (integer) 1 XREAD：从一个或多个 stream 中读取数据 格式：XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] id [id ...]\nXREAD 可以以阻塞或非阻塞的方式读取 stream 的数据（指定 BLOCK）。在获取 stream 记录时，需要指定记录的 ID。\n127.0.0.1:6379\u0026gt; XRANGE api-request-log - + 1) 1) \u0026#34;1650702336219-0\u0026#34; 2) 1) \u0026#34;remote_addr\u0026#34; 2) \u0026#34;[::1]:54058\u0026#34; 3) \u0026#34;url\u0026#34; 4) \u0026#34;/api/users\u0026#34; 5) \u0026#34;access_time\u0026#34; 6) \u0026#34;1650702336\u0026#34; 7) \u0026#34;time_executed\u0026#34; 8) \u0026#34;0\u0026#34; 9) \u0026#34;body_bytes_sent\u0026#34; 10) \u0026#34;96\u0026#34; 2) 1) \u0026#34;1650702505299-0\u0026#34; 2) 1) \u0026#34;remote_addr\u0026#34; 2) \u0026#34;[::1]:54112\u0026#34; 3) \u0026#34;url\u0026#34; 4) \u0026#34;/api/users\u0026#34; 5) \u0026#34;access_time\u0026#34; 6) \u0026#34;1650702505\u0026#34; 7) \u0026#34;time_executed\u0026#34; 8) \u0026#34;0\u0026#34; 9) \u0026#34;body_bytes_sent\u0026#34; 10) \u0026#34;96\u0026#34; 127.0.0.1:6379\u0026gt; XREAD COUNT 1 BLOCK 1000 STREAMS api-request-log 1650702336219-0 1) 1) \u0026#34;api-request-log\u0026#34; 2) 1) 1) \u0026#34;1650702505299-0\u0026#34; 2) 1) \u0026#34;remote_addr\u0026#34; 2) \u0026#34;[::1]:54112\u0026#34; 3) \u0026#34;url\u0026#34; 4) \u0026#34;/api/users\u0026#34; 5) \u0026#34;access_time\u0026#34; 6) \u0026#34;1650702505\u0026#34; 7) \u0026#34;time_executed\u0026#34; 8) \u0026#34;0\u0026#34; 9) \u0026#34;body_bytes_sent\u0026#34; 10) \u0026#34;96\u0026#34; ","date":"2022-03-27","img":"/images/redis-stream.png","permalink":"/doc-redis-commands/stream-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"流相关"},{"categories":["数据库"],"content":"Redis 服务器中与有序集合相关的命令。\nZADD：添加元素 ZADD 用于将一个或多个带分数的元素添加到有序集合中，返回成功添加到有序集合的元素个数。\n当添加元素已在有序集合中时，更新元素的分数使其在有序集合中保持正确的位置。\n格式：ZADD key score member [score member ...]\n127.0.0.1:6379\u0026gt; ZADD student:weights 63.2 xiaoming 67.5 xiaolei (integer) 2 127.0.0.1:6379\u0026gt; ZADD student:weights 64.2 xiaoming (integer) 0 ZSCORE：获取元素的分数 格式：ZSCORE key member\n127.0.0.1:6379\u0026gt; ZSCORE student:weights xiaoming \u0026#34;64.200000000000003\u0026#34; 127.0.0.1:6379\u0026gt; ZSCORE student:weights xiaolei \u0026#34;67.5\u0026#34; ZRANGE：获取指定位置区间上的元素 ZRANGE 可以获取指定位置区间上的元素，包括区间的两端。\n格式：ZRANGE key min max\n127.0.0.1:6379\u0026gt; ZADD student:weights 81.5 xiaopang (integer) 1 127.0.0.1:6379\u0026gt; ZRANGE student:weights 1 2 1) \u0026#34;xiaolei\u0026#34; 2) \u0026#34;xiaopang\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGE student:weights 2 2 1) \u0026#34;xiaopang\u0026#34; ZRANGEBYSCORE：获取指定分数区间上的元素 ZRANGEBYSCORE 可指定分数区间获取元素。\n+inf 表示正无穷，-inf 表示负无穷。\n格式：ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]\n127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights 65 85 WITHSCORES 1) \u0026#34;xiaolei\u0026#34; 2) \u0026#34;67.5\u0026#34; 3) \u0026#34;xiaopang\u0026#34; 4) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights 65 85 WITHSCORES LIMIT 1 1 1) \u0026#34;xiaopang\u0026#34; 2) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights 65 85 WITHSCORES LIMIT 1 2 1) \u0026#34;xiaopang\u0026#34; 2) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights 65 85 WITHSCORES LIMIT 0 2 1) \u0026#34;xiaolei\u0026#34; 2) \u0026#34;67.5\u0026#34; 3) \u0026#34;xiaopang\u0026#34; 4) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaoming\u0026#34; 2) \u0026#34;64.200000000000003\u0026#34; 3) \u0026#34;xiaolei\u0026#34; 4) \u0026#34;67.5\u0026#34; 5) \u0026#34;xiaopang\u0026#34; 6) \u0026#34;81.5\u0026#34; ZINCRBY：增加某个元素的分数 ZINCRBY 的返回值为修改后的分数。\n格式：ZINCRBY key increment member\n127.0.0.1:6379\u0026gt; ZINCRBY student:weights 0.5 xiaoming \u0026#34;64.700000000000003\u0026#34; 127.0.0.1:6379\u0026gt; ZINCRBY student:weights -0.5 xiaoming \u0026#34;64.200000000000003\u0026#34; ZCARD：获取集合中元素的个数 格式：ZCARD key\n127.0.0.1:6379\u0026gt; ZCARD student:weights (integer) 3 ZCOUNT：获取指定分数范围内的元素个数 格式：ZCOUNT key min max\n127.0.0.1:6379\u0026gt; ZCOUNT student:weights 65 85 (integer) 2 ZREM：删除一个或多个元素 ZREM 返回删除成功的元素个数。\n格式：ZREM key member [member ...]\n127.0.0.1:6379\u0026gt; ZREM student:weights xiaoming xiaolei (integer) 2 127.0.0.1:6379\u0026gt; ZREM student:weights notaname (integer) 0 ZREMRANGEBYRANK：通过指定位置区间删除集合元素 格式：ZREMRANGEBYRANK key start stop\n127.0.0.1:6379\u0026gt; ZADD student:weights 63.2 xiaoming 67.5 xiaolei (integer) 2 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaoming\u0026#34; 2) \u0026#34;63.200000000000003\u0026#34; 3) \u0026#34;xiaolei\u0026#34; 4) \u0026#34;67.5\u0026#34; 5) \u0026#34;xiaopang\u0026#34; 6) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZREMRANGEBYRANK student:weights 0 1 (integer) 2 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaopang\u0026#34; 2) \u0026#34;81.5\u0026#34; ZREMRANGEBYSCORE：通过指定分数区间删除集合元素 格式：ZREMRANGEBYSCORE key min max\n127.0.0.1:6379\u0026gt; ZADD student:weights 63.2 xiaoming 67.5 xiaolei 81.5 xiaopang (integer) 3 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaoming\u0026#34; 2) \u0026#34;63.200000000000003\u0026#34; 3) \u0026#34;xiaolei\u0026#34; 4) \u0026#34;67.5\u0026#34; 5) \u0026#34;xiaopang\u0026#34; 6) \u0026#34;81.5\u0026#34; 127.0.0.1:6379\u0026gt; ZREMRANGEBYSCORE student:weights 80 85 (integer) 1 127.0.0.1:6379\u0026gt; ZRANGEBYSCORE student:weights -inf +inf WITHSCORES 1) \u0026#34;xiaoming\u0026#34; 2) \u0026#34;63.200000000000003\u0026#34; 3) \u0026#34;xiaolei\u0026#34; 4) \u0026#34;67.5\u0026#34; ZRANK：获取元素的排序 格式：ZRANK key member\n127.0.0.1:6379\u0026gt; ZRANK student:weights xiaolei (integer) 1 127.0.0.1:6379\u0026gt; ZRANK student:weights notaname (nil) ZREVRANK：降序获取元素的排序 格式：ZREVRANK key member\n127.0.0.1:6379\u0026gt; ZREVRANK student:weights xiaolei (integer) 0 ","date":"2022-03-27","img":"/images/redis-zset.png","permalink":"/doc-redis-commands/zset-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"有序集合相关"},{"categories":["数据库"],"content":"Redis 服务器中与列表值相关的命令。\nLPUSH：向列表左端添加元素 LPUSH 返回添加元素后列表的长度。\n格式：LPUSH key element [element ...]\n127.0.0.1:6379\u0026gt; LPUSH colors green yellow red blue gray (integer) 5 # 此时列表为 [gray blue yellow red green] LPUSHX：向列表左端添加元素 LPUSHX 与 LPUSH 类似，但只有在 key 存在的情况，操作才有效。\n格式：LPUSHX key element [element ...]\n127.0.0.1:6379\u0026gt; KEYS colors (empty array) 127.0.0.1:6379\u0026gt; LPUSHX colors red green blue (integer) 0 RPUSH：向列表右端添加元素 RPUSH 返回添加元素后列表的长度。\n格式：RPUSH key element [element ...]\n127.0.0.1:6379\u0026gt; RPUSH colors lightgreen lightyellow lightred lightblue (integer) 9 # 此时列表为 [gray blue yellow red green # lightgreen lightyellow lightred lightblue] RPUSHX：向列表右端添加元素 RPUSHX 与 RPUSH 类似，但只能存在的键有效。\n格式：RPUSHX key element [element ...]\n127.0.0.1:6379\u0026gt; KEYS colors (empty array) 127.0.0.1:6379\u0026gt; RPUSHX colors red green blue (integer) 0 127.0.0.1:6379\u0026gt; KEYS colors (empty array) LPOP：从列表左端弹出元素 LPOP 返回弹出的元素。\n格式：LPOP key [count]\n127.0.0.1:6379\u0026gt; LPOP colors 2 1) \u0026#34;gray\u0026#34; 2) \u0026#34;blue\u0026#34; # 此时列表为 [yellow red green # lightgreen lightyellow lightred lightblue] RPOP：从列表右端弹出元素 RPOP 返回弹出的元素。\n格式：RPOP key [count]\n127.0.0.1:6379\u0026gt; RPOP colors 2 1) \u0026#34;lightblue\u0026#34; 2) \u0026#34;lightred\u0026#34; # 此时列表为 [yellow red green # lightgreen lightyellow] LLEN：获取列表中元素的个数 格式：LLEN key\n127.0.0.1:6379\u0026gt; LLEN colors (integer) 5 LRANGE：获取列表指定区间上的元素 LRANGE 指定的区间包括两端。\n格式：LRANGE key start stop\n127.0.0.1:6379\u0026gt; LRANGE colors 2 -1 1) \u0026#34;green\u0026#34; 2) \u0026#34;lightgreen\u0026#34; 3) \u0026#34;lightyellow\u0026#34; LREM：删除列表中前 count 个指定的元素 格式：LREM key count element\n127.0.0.1:6379\u0026gt; LPUSH colors yellow yellow yellow (integer) 8 # 此时列表为 [yellow yellow yellow yellow red green # lightgreen lightyellow] 127.0.0.1:6379\u0026gt; LREM colors 3 yellow (integer) 3 # 此时列表为 [yellow red green # lightgreen lightyellow] LINDEX：获取指定位置上的元素 格式：LINDEX key index\n127.0.0.1:6379\u0026gt; LINDEX colors 2 \u0026#34;green\u0026#34; LSET：设置列表中指定位置上元素的值 格式：LSET key index element\n127.0.0.1:6379\u0026gt; LSET colors 0 blue OK # 此时列表为 [blue red green # lightgreen lightyellow] LTRIM：对列表进行裁剪 LTRIM 裁剪列表并保存到原有列表中。\n格式：LTRIM key start stop\n127.0.0.1:6379\u0026gt; LTRIM colors 0 2 OK # 列表只保留了前 3 个元素 127.0.0.1:6379\u0026gt; LRANGE colors 0 9 1) \u0026#34;blue\u0026#34; 2) \u0026#34;yellow\u0026#34; 3) \u0026#34;green\u0026#34; LINSERT：向列表插入元素 LINSERT 用于在列表元素前或后插入指定元素。\n格式：LINSERT key BEFORE|AFTER pivot element\n127.0.0.1:6379\u0026gt; LINSERT colors BEFORE blue red (integer) 4 127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;blue\u0026#34; 3) \u0026#34;yellow\u0026#34; 4) \u0026#34;green\u0026#34; RPOPLPUSH：操作两个列表，对元素进行弹出再推入 RPOPLPUSH 返回值为第 1 个列表弹出的元素。\n格式：RPOPLPUSH source destination\n127.0.0.1:6379\u0026gt; RPOPLPUSH colors other:colors \u0026#34;green\u0026#34; 127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;blue\u0026#34; 3) \u0026#34;yellow\u0026#34; 127.0.0.1:6379\u0026gt; LRANGE other:colors 0 -1 1) \u0026#34;green\u0026#34; BLPOP：阻塞式从列表左端弹出元素 BLPOP 同样用于从列表左端弹出元素，但是当列表为空，该命令会阻塞列表直到超时或列表有元素可弹出，超时时间单位为秒。\n格式：BLPOP key [key ...] timeout\n127.0.0.1:6379\u0026gt; BLPOP mock:list 2 (nil) (2.06s) BRPOP：阻塞式从列表右端弹出元素 BRPOP 同样用于从列表右端弹出元素，但是当列表为空，该命令会阻塞列表直到超时或列表有元素可弹出，超时时间单位为秒。\n格式：BRPOP key [key ...] timeout\n127.0.0.1:6379\u0026gt; BRPOP mock:list 2` (nil) (2.05s) RPUSHX：向已存在的列表右端添加元素 RPUSHX 用于将一个或多个元素添加到已存在列表，若列表不存在，则操作无效。\n格式：RPUSHX key element [element ...]\n127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;blue\u0026#34; 3) \u0026#34;yellow\u0026#34; 127.0.0.1:6379\u0026gt; RPUSHX colors green (integer) 4 127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;blue\u0026#34; 3) \u0026#34;yellow\u0026#34; 4) \u0026#34;green\u0026#34; 127.0.0.1:6379\u0026gt; RPUSHX not:exists:colors green (integer) 0 BRPOPLPUSH：操作两个列表，对元素进行弹出再推入 BRPOPLPUSH 与 RPOPLPUSH 类似，但如果列表中没有元素会阻塞直到等待超时或有元素弹出，超时时间的单位为秒。\n格式：BRPOPLPUSH source destination timeout\n127.0.0.1:6379\u0026gt; RPUSH colors red green yellow (integer) 3 127.0.0.1:6379\u0026gt; BRPOPLPUSH colors dest:colors 10 \u0026#34;yellow\u0026#34; 127.0.0.1:6379\u0026gt; LRANGE colors 0 -1 1) \u0026#34;red\u0026#34; 2) \u0026#34;green\u0026#34; 127.0.0.1:6379\u0026gt; LRANGE dest:colors 0 -1 1) \u0026#34;yellow\u0026#34; ","date":"2022-03-27","img":"/images/redis-list.png","permalink":"/doc-redis-commands/list-related/","series":["Redis 命令手册"],"tags":["Redis"],"title":"列表值相关"},{"categories":null,"content":"","date":"0001-01-01","img":"","permalink":"/offline/","series":null,"tags":null,"title":"Offline"}]